{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1fCaWRcM4nWd"
   },
   "source": [
    "## Fake News Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EMd17UZ9Thnm"
   },
   "source": [
    "## Abstract\n",
    "\n",
    "Fake news and hoaxes have been there since before the advent of the Internet. The widely accepted definition of Internet fake news is fictitious articles deliberately fabricated to deceive readers. Nowadays, social media admins and news outlets publish fake news to increase readership or as a part of psychological warfare. With the outbreak of one of the greatest Pandemic in the history of earth, we use twitter to show our feelings, emotions and what we feel about the current situations. The media gives us live updates of how the world is dealing with the COVID-19 pandemic. What is happening at the hospitals, how the doctors, nurses and the health workers are helping to fight the disease, how scientists are working day and night in order to create a vaccination to end the pandemic.\n",
    "\n",
    "The situation is volatile, and it is no surprise that one can easily feel frightened/ panicked in such situations. It is the human tendency to believe what we see, hear and read although most of it being just rumors created by unauthenticated and unvalidated sources. As a result of this, we get more anxious and nervous when we encounter such articles.\n",
    "\n",
    "To address this issue, we will be designing a classifier that will accurately classify between the real news and fake news.\n",
    "In our research project, we aim to analyze the news article from the kaggle datasets.  Tweets/articles extracted from twitter related to coronavirus are also used to test the models accuracy . We first extract only the required features from the dataset like title, text and label. After extracting we clean the text data by getting rid of extra whitespaces/alphanumeric characters and null values. Moreover, we stemm the words and convert all letters to lowercase alongside calculating the length of the text article. After doing so, we obliterate stopwords in the text so that the text contains only the more meaningful words that could help us classify between real and fake news. We then vectorize the words using TF-IDF and CountVectorizer retrieving at most 10,000 features after vectorizing.\n",
    "\n",
    "As a baseline model, we first try to classify the cleaned dataset using the Naïve Bayes classifier with which we get an accuracy score of 65%. We then use Deep Learning to improve on this accuracy using the <b>Long Short Term Memory (LSTM)</b> algorithm with which we attain an accuracy of 94% after hyper-parameter tuning. We also classify using <b>H2O’s AutoML Gradient Boosting Estimator</b> to achieve an accuracy of 81%.\n",
    "\n",
    "The results of this project will classify between real and reel news which can be very helpful to stop the spread of panic, especially during a pandemic.\n",
    "\n",
    "\n",
    "## Dataset Details\n",
    "\n",
    "We have taken 3 datasets for the model. The details of the dataset as the following:-\n",
    "1. https://www.kaggle.com/c/fake-news/data\n",
    "2. https://drive.google.com/file/d/1er9NJTLUA3qnRuyhfzuN0XUsoIC4a-_q/view\n",
    "3. https://www.kaggle.com/clmentbisaillon/fake-and-real-news-dataset\n",
    "\n",
    "All the dataset contains different columns, but they have 3 columns in common which are our prime focus. The columns are :- \n",
    "a. Text - Contains the actual text qhich we will be using to train the model and predict the fake or real news and test the accuracy\n",
    "b. Title - Contains the source of the data which we will use to validate the source of the text\n",
    "c. Label - The actual label of the text. Consists of values 0 and 1 indicating Real and Fake news\n",
    "\n",
    "<b>Tweets from twitter are used for testing purpose </b>\n",
    "\n",
    "To get the data from Twitter we are using the API from Twitter Developer account. We are ingesting 500 tweets with the Coronavirus hashtag and from a date range of 10 days.\n",
    "\n",
    "To run the Jupyter notebook following specifications must be followed\n",
    "\n",
    "## Specification\n",
    "Hardware specs: -\n",
    "\n",
    "1. RAM - 12 GB\n",
    "2. Memory - 256 GB\n",
    "\n",
    "For Google Colab - Google account and GPU support\n",
    "\n",
    "NLP - installing nltk libraries - Details in the notebook<br>\n",
    "\n",
    "TensorFlow - Keras and Tensorflow installed in the system<br>\n",
    "\n",
    "H20 - For H20 specific Java and JDK kits must be installed along with H2O, details in the notebook<br>\n",
    "\n",
    "Twitter Developer Account - Activated with Secret token. Details in notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gXUZKfxcThnn"
   },
   "source": [
    "### Importing the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CW-Qa9Gd9PQ4"
   },
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "\n",
    "# Machine learning Algorithms\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "6PaplN7yT2Dj",
    "outputId": "2324adda-1828-4dda-a0b9-df5d76890d0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Run this only when running in google colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yx0AncbTUByj"
   },
   "outputs": [],
   "source": [
    "# For running in google Colab\n",
    "dataset1_path = '/content/drive/My Drive/fake-news/train.csv'\n",
    "dataset2_path = '/content/drive/My Drive/fake-news (1)/fake.csv'\n",
    "dataset3_path = '/content/drive/My Drive/news.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zT2BlkWV5RMz"
   },
   "outputs": [],
   "source": [
    "# To run in local System - Jupyter Notebook\n",
    "dataset1_path = r'..\\Data\\fake-news\\train.csv'\n",
    "dataset2_path = r'..\\Data\\fake-news (1)\\fake.csv'\n",
    "dataset3_path = r'..\\Data\\news\\news.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "ZqHqyURC72T0",
    "outputId": "672f13b8-c3fe-47eb-f7a4-fc20b40a256b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title              author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
       "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
       "\n",
       "                                                text  label  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1  Ever get the feeling your life circles the rou...      0  \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1  \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...      1  \n",
       "4  Print \\nAn Iranian woman has been sentenced to...      1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1 = pd.read_csv(dataset1_path, index_col=None)\n",
    "dataset1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 568
    },
    "colab_type": "code",
    "id": "vqJJbg-274Pe",
    "outputId": "9d451c8b-8bbd-41f9-a24f-c3d43e9a65d4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuid</th>\n",
       "      <th>ord_in_thread</th>\n",
       "      <th>author</th>\n",
       "      <th>published</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>language</th>\n",
       "      <th>crawled</th>\n",
       "      <th>site_url</th>\n",
       "      <th>country</th>\n",
       "      <th>domain_rank</th>\n",
       "      <th>thread_title</th>\n",
       "      <th>spam_score</th>\n",
       "      <th>main_img_url</th>\n",
       "      <th>replies_count</th>\n",
       "      <th>participants_count</th>\n",
       "      <th>likes</th>\n",
       "      <th>comments</th>\n",
       "      <th>shares</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6a175f46bcd24d39b3e962ad0f29936721db70db</td>\n",
       "      <td>0</td>\n",
       "      <td>Barracuda Brigade</td>\n",
       "      <td>2016-10-26T21:41:00.000+03:00</td>\n",
       "      <td>Muslims BUSTED: They Stole Millions In Gov’t B...</td>\n",
       "      <td>Print They should pay all the back all the mon...</td>\n",
       "      <td>english</td>\n",
       "      <td>2016-10-27T01:49:27.168+03:00</td>\n",
       "      <td>100percentfedup.com</td>\n",
       "      <td>US</td>\n",
       "      <td>25689.0</td>\n",
       "      <td>Muslims BUSTED: They Stole Millions In Gov’t B...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>http://bb4sp.com/wp-content/uploads/2016/10/Fu...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2bdc29d12605ef9cf3f09f9875040a7113be5d5b</td>\n",
       "      <td>0</td>\n",
       "      <td>reasoning with facts</td>\n",
       "      <td>2016-10-29T08:47:11.259+03:00</td>\n",
       "      <td>Re: Why Did Attorney General Loretta Lynch Ple...</td>\n",
       "      <td>Why Did Attorney General Loretta Lynch Plead T...</td>\n",
       "      <td>english</td>\n",
       "      <td>2016-10-29T08:47:11.259+03:00</td>\n",
       "      <td>100percentfedup.com</td>\n",
       "      <td>US</td>\n",
       "      <td>25689.0</td>\n",
       "      <td>Re: Why Did Attorney General Loretta Lynch Ple...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>http://bb4sp.com/wp-content/uploads/2016/10/Fu...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c70e149fdd53de5e61c29281100b9de0ed268bc3</td>\n",
       "      <td>0</td>\n",
       "      <td>Barracuda Brigade</td>\n",
       "      <td>2016-10-31T01:41:49.479+02:00</td>\n",
       "      <td>BREAKING: Weiner Cooperating With FBI On Hilla...</td>\n",
       "      <td>Red State : \\nFox News Sunday reported this mo...</td>\n",
       "      <td>english</td>\n",
       "      <td>2016-10-31T01:41:49.479+02:00</td>\n",
       "      <td>100percentfedup.com</td>\n",
       "      <td>US</td>\n",
       "      <td>25689.0</td>\n",
       "      <td>BREAKING: Weiner Cooperating With FBI On Hilla...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>http://bb4sp.com/wp-content/uploads/2016/10/Fu...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7cf7c15731ac2a116dd7f629bd57ea468ed70284</td>\n",
       "      <td>0</td>\n",
       "      <td>Fed Up</td>\n",
       "      <td>2016-11-01T05:22:00.000+02:00</td>\n",
       "      <td>PIN DROP SPEECH BY FATHER OF DAUGHTER Kidnappe...</td>\n",
       "      <td>Email Kayla Mueller was a prisoner and torture...</td>\n",
       "      <td>english</td>\n",
       "      <td>2016-11-01T15:46:26.304+02:00</td>\n",
       "      <td>100percentfedup.com</td>\n",
       "      <td>US</td>\n",
       "      <td>25689.0</td>\n",
       "      <td>PIN DROP SPEECH BY FATHER OF DAUGHTER Kidnappe...</td>\n",
       "      <td>0.068</td>\n",
       "      <td>http://100percentfedup.com/wp-content/uploads/...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0206b54719c7e241ffe0ad4315b808290dbe6c0f</td>\n",
       "      <td>0</td>\n",
       "      <td>Fed Up</td>\n",
       "      <td>2016-11-01T21:56:00.000+02:00</td>\n",
       "      <td>FANTASTIC! TRUMP'S 7 POINT PLAN To Reform Heal...</td>\n",
       "      <td>Email HEALTHCARE REFORM TO MAKE AMERICA GREAT ...</td>\n",
       "      <td>english</td>\n",
       "      <td>2016-11-01T23:59:42.266+02:00</td>\n",
       "      <td>100percentfedup.com</td>\n",
       "      <td>US</td>\n",
       "      <td>25689.0</td>\n",
       "      <td>FANTASTIC! TRUMP'S 7 POINT PLAN To Reform Heal...</td>\n",
       "      <td>0.865</td>\n",
       "      <td>http://100percentfedup.com/wp-content/uploads/...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bias</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       uuid  ord_in_thread  \\\n",
       "0  6a175f46bcd24d39b3e962ad0f29936721db70db              0   \n",
       "1  2bdc29d12605ef9cf3f09f9875040a7113be5d5b              0   \n",
       "2  c70e149fdd53de5e61c29281100b9de0ed268bc3              0   \n",
       "3  7cf7c15731ac2a116dd7f629bd57ea468ed70284              0   \n",
       "4  0206b54719c7e241ffe0ad4315b808290dbe6c0f              0   \n",
       "\n",
       "                 author                      published  \\\n",
       "0     Barracuda Brigade  2016-10-26T21:41:00.000+03:00   \n",
       "1  reasoning with facts  2016-10-29T08:47:11.259+03:00   \n",
       "2     Barracuda Brigade  2016-10-31T01:41:49.479+02:00   \n",
       "3                Fed Up  2016-11-01T05:22:00.000+02:00   \n",
       "4                Fed Up  2016-11-01T21:56:00.000+02:00   \n",
       "\n",
       "                                               title  \\\n",
       "0  Muslims BUSTED: They Stole Millions In Gov’t B...   \n",
       "1  Re: Why Did Attorney General Loretta Lynch Ple...   \n",
       "2  BREAKING: Weiner Cooperating With FBI On Hilla...   \n",
       "3  PIN DROP SPEECH BY FATHER OF DAUGHTER Kidnappe...   \n",
       "4  FANTASTIC! TRUMP'S 7 POINT PLAN To Reform Heal...   \n",
       "\n",
       "                                                text language  \\\n",
       "0  Print They should pay all the back all the mon...  english   \n",
       "1  Why Did Attorney General Loretta Lynch Plead T...  english   \n",
       "2  Red State : \\nFox News Sunday reported this mo...  english   \n",
       "3  Email Kayla Mueller was a prisoner and torture...  english   \n",
       "4  Email HEALTHCARE REFORM TO MAKE AMERICA GREAT ...  english   \n",
       "\n",
       "                         crawled             site_url country  domain_rank  \\\n",
       "0  2016-10-27T01:49:27.168+03:00  100percentfedup.com      US      25689.0   \n",
       "1  2016-10-29T08:47:11.259+03:00  100percentfedup.com      US      25689.0   \n",
       "2  2016-10-31T01:41:49.479+02:00  100percentfedup.com      US      25689.0   \n",
       "3  2016-11-01T15:46:26.304+02:00  100percentfedup.com      US      25689.0   \n",
       "4  2016-11-01T23:59:42.266+02:00  100percentfedup.com      US      25689.0   \n",
       "\n",
       "                                        thread_title  spam_score  \\\n",
       "0  Muslims BUSTED: They Stole Millions In Gov’t B...       0.000   \n",
       "1  Re: Why Did Attorney General Loretta Lynch Ple...       0.000   \n",
       "2  BREAKING: Weiner Cooperating With FBI On Hilla...       0.000   \n",
       "3  PIN DROP SPEECH BY FATHER OF DAUGHTER Kidnappe...       0.068   \n",
       "4  FANTASTIC! TRUMP'S 7 POINT PLAN To Reform Heal...       0.865   \n",
       "\n",
       "                                        main_img_url  replies_count  \\\n",
       "0  http://bb4sp.com/wp-content/uploads/2016/10/Fu...              0   \n",
       "1  http://bb4sp.com/wp-content/uploads/2016/10/Fu...              0   \n",
       "2  http://bb4sp.com/wp-content/uploads/2016/10/Fu...              0   \n",
       "3  http://100percentfedup.com/wp-content/uploads/...              0   \n",
       "4  http://100percentfedup.com/wp-content/uploads/...              0   \n",
       "\n",
       "   participants_count  likes  comments  shares  type  \n",
       "0                   1      0         0       0  bias  \n",
       "1                   1      0         0       0  bias  \n",
       "2                   1      0         0       0  bias  \n",
       "3                   0      0         0       0  bias  \n",
       "4                   0      0         0       0  bias  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2 = pd.read_csv(dataset2_path, index_col=None)\n",
    "dataset2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "YQLG2igO_3Hx",
    "outputId": "bb084880-d5fc-498f-8e88-c73f925085d9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0        8476                       You Can Smell Hillary’s Fear   \n",
       "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3       10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4         875   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text label  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4  It's primary day in New York and front-runners...  REAL  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset3 = pd.read_csv(dataset3_path, index_col=None)\n",
    "dataset3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9UFqDPmGANuw"
   },
   "outputs": [],
   "source": [
    "req_columns = ['title','text','label']\n",
    "dataset1 = dataset1[req_columns]\n",
    "dataset3 = dataset3[req_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "tVH80BblBvw4",
    "outputId": "b848de37-27f6-47b3-e43e-31e15d66b064"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Muslims BUSTED: They Stole Millions In Gov’t B...</td>\n",
       "      <td>Print They should pay all the back all the mon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Re: Why Did Attorney General Loretta Lynch Ple...</td>\n",
       "      <td>Why Did Attorney General Loretta Lynch Plead T...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BREAKING: Weiner Cooperating With FBI On Hilla...</td>\n",
       "      <td>Red State : \\nFox News Sunday reported this mo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PIN DROP SPEECH BY FATHER OF DAUGHTER Kidnappe...</td>\n",
       "      <td>Email Kayla Mueller was a prisoner and torture...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FANTASTIC! TRUMP'S 7 POINT PLAN To Reform Heal...</td>\n",
       "      <td>Email HEALTHCARE REFORM TO MAKE AMERICA GREAT ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Muslims BUSTED: They Stole Millions In Gov’t B...   \n",
       "1  Re: Why Did Attorney General Loretta Lynch Ple...   \n",
       "2  BREAKING: Weiner Cooperating With FBI On Hilla...   \n",
       "3  PIN DROP SPEECH BY FATHER OF DAUGHTER Kidnappe...   \n",
       "4  FANTASTIC! TRUMP'S 7 POINT PLAN To Reform Heal...   \n",
       "\n",
       "                                                text  label  \n",
       "0  Print They should pay all the back all the mon...      0  \n",
       "1  Why Did Attorney General Loretta Lynch Plead T...      0  \n",
       "2  Red State : \\nFox News Sunday reported this mo...      0  \n",
       "3  Email Kayla Mueller was a prisoner and torture...      0  \n",
       "4  Email HEALTHCARE REFORM TO MAKE AMERICA GREAT ...      1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2['label']=dataset2['spam_score'].apply(lambda x: 1 if x >0.5 else 0)\n",
    "dataset2 = dataset2[req_columns]\n",
    "dataset2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gSatulwZCXG_"
   },
   "outputs": [],
   "source": [
    "dataset3['label']=dataset3['label'].apply(lambda x: 1 if x == 'FAKE' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "colab_type": "code",
    "id": "FAg5H_VaCbkz",
    "outputId": "2b51f848-4bd5-489d-8e91-81c2a8fc58ed"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40129</th>\n",
       "      <td>State Department says it can't find emails fro...</td>\n",
       "      <td>The State Department told the Republican Natio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40130</th>\n",
       "      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n",
       "      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40131</th>\n",
       "      <td>Anti-Trump Protesters Are Tools of the Oligarc...</td>\n",
       "      <td>Anti-Trump Protesters Are Tools of the Oligar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40132</th>\n",
       "      <td>In Ethiopia, Obama seeks progress on peace, se...</td>\n",
       "      <td>ADDIS ABABA, Ethiopia —President Obama convene...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40133</th>\n",
       "      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n",
       "      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40134 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0      House Dem Aide: We Didn’t Even See Comey’s Let...   \n",
       "1      FLYNN: Hillary Clinton, Big Woman on Campus - ...   \n",
       "2                      Why the Truth Might Get You Fired   \n",
       "3      15 Civilians Killed In Single US Airstrike Hav...   \n",
       "4      Iranian woman jailed for fictional unpublished...   \n",
       "...                                                  ...   \n",
       "40129  State Department says it can't find emails fro...   \n",
       "40130  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...   \n",
       "40131  Anti-Trump Protesters Are Tools of the Oligarc...   \n",
       "40132  In Ethiopia, Obama seeks progress on peace, se...   \n",
       "40133  Jeb Bush Is Suddenly Attacking Trump. Here's W...   \n",
       "\n",
       "                                                    text  label  \n",
       "0      House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1      Ever get the feeling your life circles the rou...      0  \n",
       "2      Why the Truth Might Get You Fired October 29, ...      1  \n",
       "3      Videos 15 Civilians Killed In Single US Airstr...      1  \n",
       "4      Print \\nAn Iranian woman has been sentenced to...      1  \n",
       "...                                                  ...    ...  \n",
       "40129  The State Department told the Republican Natio...      0  \n",
       "40130  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...      1  \n",
       "40131   Anti-Trump Protesters Are Tools of the Oligar...      1  \n",
       "40132  ADDIS ABABA, Ethiopia —President Obama convene...      0  \n",
       "40133  Jeb Bush Is Suddenly Attacking Trump. Here's W...      0  \n",
       "\n",
       "[40134 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_df2 = dataset1.append(dataset2, ignore_index=True)\n",
    "df1_df2_df3 = df1_df2.append(dataset3, ignore_index = True)\n",
    "\n",
    "final_dataset = df1_df2_df3.copy()\n",
    "\n",
    "final_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the Dataset\n",
    "We have read the datasets. Now we have to clean the data set. \n",
    "<br><br>\n",
    "<b>\n",
    "Cleaning is required because: -\n",
    "</b>\n",
    "\n",
    "1. The text data is extremely messy. \n",
    "2. Lots of noise in the data that needs to be removed\n",
    "3. Many empty strings\n",
    "4. NLP techniques does not recognise bad strings because when we will tokenize or vectorize it will not be performing good work on the bad data.</b>\n",
    "\n",
    "<b>\n",
    "So Cleaning of data is the first step before natural language processing. It consists of the following substeps:-\n",
    "</b><br>\n",
    "\n",
    "1. Checking missing values<br>\n",
    "2. Removing records whose length is less than 40<br>\n",
    "3. Removing empty texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "SaIH7BhPDx4q",
    "outputId": "83833e6f-0d1c-4d43-b180-b15d4d36db43"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title    1238\n",
       "text       85\n",
       "label       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wc5hy0n6EHiv"
   },
   "source": [
    "#### Of the 40134 records, only 85 have missing values, which is 0.2% of the total value, so we can drop these rows. The title is also having missing value which is something we are not concerned about because we are only concerned about the text column which we will clean and based on that we will classify the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "5GIQmuWuEwCG",
    "outputId": "453cad31-f315-4041-a9db-ab03380655e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title    0\n",
       "text     0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataset[['title']] = final_dataset[['title']].fillna(value = 'Missing')\n",
    "final_dataset = final_dataset.dropna()\n",
    "final_dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "x8chcqyHE4YO",
    "outputId": "6c3ee4e6-92bb-44b0-ff5e-3acaccd9f788"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40049, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Checking the length of the text and adding a column to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "id": "yQo0aFG8E7No",
    "outputId": "4d4fc3e0-8c3b-420d-aba0-946f2c1d1b18"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\WindowsApplication\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "      <td>4930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "      <td>4160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>7692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "      <td>3237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "      <td>938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...   \n",
       "1  FLYNN: Hillary Clinton, Big Woman on Campus - ...   \n",
       "2                  Why the Truth Might Get You Fired   \n",
       "3  15 Civilians Killed In Single US Airstrike Hav...   \n",
       "4  Iranian woman jailed for fictional unpublished...   \n",
       "\n",
       "                                                text  label  length  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1    4930  \n",
       "1  Ever get the feeling your life circles the rou...      0    4160  \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1    7692  \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...      1    3237  \n",
       "4  Print \\nAn Iranian woman has been sentenced to...      1     938  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataset['length'] = final_dataset['text'].apply(lambda x: len(x))\n",
    "final_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "eX2xstl7Idy5",
    "outputId": "3b598578-0d27-45d3-e968-faf88c84206f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max 142961\n",
      "Min 1\n"
     ]
    }
   ],
   "source": [
    "#Checking the maximum and the minimum length\n",
    "max_length = final_dataset['length'].max()\n",
    "min_length = final_dataset['length'].min()\n",
    "print('Max', max_length)\n",
    "print('Min', min_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Removing the records in the text column whose length is less than 40. 40 is kept as a standard cut off because any article having less than 40 words will not give us an actual picture that whether the article is a real or fake and most of them are incomplete articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "colab_type": "code",
    "id": "JBnBKonyJAGG",
    "outputId": "f8a74b92-6345-44dd-e288-f1079f8e10b4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Huma’s Weiner Dogs Hillary</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>Mohamad Khweis: Another “Virginia Man” (Palest...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>Trump family already ‘sworn to secrecy’ about ...</td>\n",
       "      <td>Guest   Guest</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Missing</td>\n",
       "      <td>They got the heater turned up on high.</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>A Connecticut Reader Reports Record Voter Regi...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39498</th>\n",
       "      <td>A Fifth Clinton Presidency? Hill, No!</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39571</th>\n",
       "      <td>Huma’s Weiner Dogs Hillary</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39863</th>\n",
       "      <td>Radio Derb: Peak White Guilt, PC Now To The LE...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39974</th>\n",
       "      <td>Hillary’s High Crimes &amp; Misdemeanors Threaten ...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40127</th>\n",
       "      <td>Radio Derb Is On The Air–Leonardo And Brazil’s...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>444 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "82                            Huma’s Weiner Dogs Hillary   \n",
       "169    Mohamad Khweis: Another “Virginia Man” (Palest...   \n",
       "173    Trump family already ‘sworn to secrecy’ about ...   \n",
       "196                                              Missing   \n",
       "295    A Connecticut Reader Reports Record Voter Regi...   \n",
       "...                                                  ...   \n",
       "39498              A Fifth Clinton Presidency? Hill, No!   \n",
       "39571                         Huma’s Weiner Dogs Hillary   \n",
       "39863  Radio Derb: Peak White Guilt, PC Now To The LE...   \n",
       "39974  Hillary’s High Crimes & Misdemeanors Threaten ...   \n",
       "40127  Radio Derb Is On The Air–Leonardo And Brazil’s...   \n",
       "\n",
       "                                         text  label  length  \n",
       "82                                                 1       1  \n",
       "169                                                1       1  \n",
       "173                           Guest   Guest        1      17  \n",
       "196    They got the heater turned up on high.      1      38  \n",
       "295                                                1       1  \n",
       "...                                       ...    ...     ...  \n",
       "39498                                              1       1  \n",
       "39571                                              1       1  \n",
       "39863                                              1       1  \n",
       "39974                                              1       1  \n",
       "40127                                              1       1  \n",
       "\n",
       "[444 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets see the text fields which has length less than 40\n",
    "\n",
    "df_potential_discard = final_dataset[final_dataset['length']<40]\n",
    "df_potential_discard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uFhO2C2eJ30w"
   },
   "source": [
    "#### They are mostly empty text, so before removing them we can trim the text and again run the same check to see if the texts are still empty or not and also some text has length of 50000 which is again outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "colab_type": "code",
    "id": "Ly3dkmEBJqMJ",
    "outputId": "89de95a5-454d-4f9a-f42e-e2416ba022c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max 142961\n",
      "Min 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\WindowsApplication\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "D:\\WindowsApplication\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "final_dataset['text'] =  final_dataset['text'].apply(lambda x : x.strip())\n",
    "#Checking the length of the text\n",
    "final_dataset['length'] = final_dataset['text'].apply(lambda x: len(x))\n",
    "max_length = final_dataset['length'].max()\n",
    "min_length = final_dataset['length'].min()\n",
    "print('Max', max_length)\n",
    "print('Min', min_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "colab_type": "code",
    "id": "axWRz2ieLuQc",
    "outputId": "cbec4a5c-338b-40c2-fe73-3168ca629507"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "      <td>4930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "      <td>4160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>7692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "      <td>3237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "      <td>938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40129</th>\n",
       "      <td>State Department says it can't find emails fro...</td>\n",
       "      <td>The State Department told the Republican Natio...</td>\n",
       "      <td>0</td>\n",
       "      <td>4076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40130</th>\n",
       "      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n",
       "      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n",
       "      <td>1</td>\n",
       "      <td>14323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40131</th>\n",
       "      <td>Anti-Trump Protesters Are Tools of the Oligarc...</td>\n",
       "      <td>Anti-Trump Protesters Are Tools of the Oligarc...</td>\n",
       "      <td>1</td>\n",
       "      <td>11973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40132</th>\n",
       "      <td>In Ethiopia, Obama seeks progress on peace, se...</td>\n",
       "      <td>ADDIS ABABA, Ethiopia —President Obama convene...</td>\n",
       "      <td>0</td>\n",
       "      <td>6991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40133</th>\n",
       "      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n",
       "      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n",
       "      <td>0</td>\n",
       "      <td>4818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39601 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0      House Dem Aide: We Didn’t Even See Comey’s Let...   \n",
       "1      FLYNN: Hillary Clinton, Big Woman on Campus - ...   \n",
       "2                      Why the Truth Might Get You Fired   \n",
       "3      15 Civilians Killed In Single US Airstrike Hav...   \n",
       "4      Iranian woman jailed for fictional unpublished...   \n",
       "...                                                  ...   \n",
       "40129  State Department says it can't find emails fro...   \n",
       "40130  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...   \n",
       "40131  Anti-Trump Protesters Are Tools of the Oligarc...   \n",
       "40132  In Ethiopia, Obama seeks progress on peace, se...   \n",
       "40133  Jeb Bush Is Suddenly Attacking Trump. Here's W...   \n",
       "\n",
       "                                                    text  label  length  \n",
       "0      House Dem Aide: We Didn’t Even See Comey’s Let...      1    4930  \n",
       "1      Ever get the feeling your life circles the rou...      0    4160  \n",
       "2      Why the Truth Might Get You Fired October 29, ...      1    7692  \n",
       "3      Videos 15 Civilians Killed In Single US Airstr...      1    3237  \n",
       "4      Print \\nAn Iranian woman has been sentenced to...      1     938  \n",
       "...                                                  ...    ...     ...  \n",
       "40129  The State Department told the Republican Natio...      0    4076  \n",
       "40130  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...      1   14323  \n",
       "40131  Anti-Trump Protesters Are Tools of the Oligarc...      1   11973  \n",
       "40132  ADDIS ABABA, Ethiopia —President Obama convene...      0    6991  \n",
       "40133  Jeb Bush Is Suddenly Attacking Trump. Here's W...      0    4818  \n",
       "\n",
       "[39601 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping the outliers\n",
    "final_dataset = final_dataset.drop(final_dataset['text'][final_dataset['length'] < 40].index, axis = 0)\n",
    "final_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the Final Dataset as pickle\n",
    "\n",
    "Pickle is a container in which we can store any model, dataset or text data.<br><br>\n",
    "Pickle is the standard way of serializing objects in Python. You can use the pickle operation to serialize your machine learning algorithms and save the serialized format to a file. Later you can load this file to deserialize your model and use it to make new predictions.<br><br>\n",
    "We are saving our dataset in pickle for future reference, if in case one would want to work, they can import this file and start executing Natural Language Processing on the final dataset and can avoid the cleaning and merging steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R8j-RS6FCpEx"
   },
   "outputs": [],
   "source": [
    "final_dataset.to_csv('..\\Data\\Cleaned_Final_Data\\cleaned_dataset.csv')\n",
    "#Save as pickel\n",
    "import pickle\n",
    "final_dataset_pkl_filename = r'..\\Data\\Pickle_Files\\final_dataset.pickel'\n",
    "final_dataset_pkl = open(final_dataset_pkl_filename, 'wb')\n",
    "pickle.dump(final_dataset, final_dataset_pkl)\n",
    "final_dataset_pkl.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Y0Td_3ZitjH"
   },
   "source": [
    "## Preprocessing the texts \n",
    "\n",
    "Data preprocessing is a data mining technique that involves transforming raw data into an understandable format. Real-world data is often incomplete, inconsistent, and/or lacking in certain behaviors or trends, and is likely to contain many errors. Data preprocessing is a proven method of resolving such issues. Data preprocessing prepares raw data for further processing.\n",
    "<br><br><b>\n",
    "Pre processing steps includes the following: -</b>\n",
    "\n",
    "1. Replace all the digits with white space\n",
    "2. Converting to lower case \n",
    "3. Stemming the words in the texts\n",
    "4. Taking max 10000 features and vectorizing by<br>\n",
    "  a. TFIDF <br>\n",
    "  b. CountVectorizer\n",
    "  \n",
    "<br>\n",
    "We are importing <b>NLP libraries</b> for text analysis. For checking the stopwords from the text we are downloading nltk <b>STOPWORDS</b>.\n",
    "For <b>TfIdf</b> and <b>CountVectorizer</b>, we are using sklearn's feature extraction library to import them. Moreover, we import <b>word_tokenize</b> from nltk library which will be used to tokenize the text data before vectorizing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "5ugVnwofMbhf",
    "outputId": "faf1bac1-283a-4828-ba56-f2135b56e57d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\anura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\anura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Natural Language Processing libraries\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "nltk.download('stopwords')\n",
    "from nltk import word_tokenize\n",
    "STOPWORDS = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X87W1iCsK6Gw"
   },
   "outputs": [],
   "source": [
    "final_dataset.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yYBnZJpUThpS",
    "outputId": "dffef037-9ad4-4d63-c501-48a117f54c25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    House Dem Aide: We Didn’t Even See Comey’s Let...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(final_dataset[0:1]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming\n",
    "Much of natural language machine learning is about sentiment of the text. Stemming is a process where words are reduced to a root by removing inflection through dropping unnecessary characters, usually a suffix. There are several stemming models, including Porter and Snowball.<b> The results can be used to identify relationships and commonalities across large datasets</b>.\n",
    "Using this method we will get stemmed data to feed the machine learning model through which the model can learn from root words and identify the relationships between words\n",
    "<br><br>\n",
    "<b>We are using Porter Stemmer to stem the text data for our dataset</b><br>\n",
    "The Porter stemming algorithm (or 'Porter stemmer') is a process for removing the commoner morphological and inflexional endings from words in English. Its main use is as part of a <b>term normalisation</b> process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "3iqvjU13KWO6",
    "outputId": "d4b8c53b-cd9e-402c-dba7-e95e046e8b47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2h 6min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ps = PorterStemmer()\n",
    "corpus = []\n",
    "for i in range(0, len(final_dataset)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', final_dataset['text'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    \n",
    "    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "A5d8SoibRSQJ",
    "outputId": "f12ba1c6-aa86-432a-f09d-f143495033f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hous dem aid even see comey letter jason chaffetz tweet darrel lucu octob subscrib jason chaffetz stump american fork utah imag courtesi michael jolley avail creativ common licens apolog keith olbermann doubt worst person world week fbi director jame comey accord hous democrat aid look like also know second worst person well turn comey sent infam letter announc fbi look email may relat hillari clinton email server rank democrat relev committe hear comey found via tweet one republican committe chairmen know comey notifi republican chairmen democrat rank member hous intellig judiciari oversight committe agenc review email recent discov order see contain classifi inform long letter went oversight committe chairman jason chaffetz set polit world ablaz tweet fbi dir inform fbi learn exist email appear pertin investig case reopen jason chaffetz jasoninthehous octob cours know case comey actual say review email light unrel case know anthoni weiner sext teenag appar littl thing fact matter chaffetz utah republican alreadi vow initi raft investig hillari win least two year worth possibl entir term worth appar chaffetz thought fbi alreadi work result tweet briefli roil nation cooler head realiz dud accord senior hous democrat aid misread letter may least chaffetz sin aid told shareblu boss democrat even know comey letter time found check twitter democrat rank member relev committe receiv comey letter republican chairmen fact democrat rank member receiv chairman oversight govern reform committe jason chaffetz tweet made public let see got right fbi director tell chaffetz gop committe chairmen major develop potenti polit explos investig neither chaffetz colleagu courtesi let democrat counterpart know instead accord aid made find twitter alreadi talk daili ko comey provid advanc notic letter chaffetz republican give time turn spin machin may make good theater noth far even suggest case noth far suggest comey anyth grossli incompet tone deaf suggest howev chaffetz act way make dan burton darrel issa look like model respons bipartisanship even decenc notifi rank member elijah cum someth explos trampl basic standard fair know grant like chaffetz answer sit ridicul republican district anchor provo orem cook partisan vote index r gave mitt romney punish percent vote moreov republican hous leadership given full support chaffetz plan fish expedit mean turn hot light textbook exampl hous becom republican control also second worst person world darrel lucu darrel someth graduat univers north carolina consid journalist old school attempt turn member religi right colleg succeed turn religi right worst nightmar charismat christian unapologet liber desir stand scare silenc increas surviv abus three year marriag may know daili ko christian dem nc follow twitter darrelllucu connect facebook click buy darrel mello yello connect'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>We are saving our corpus after stemming in pickle for future reference, if in case one would want to work, they can import this file and start executing nlp techniques like vectorizing and analysis on the corpus and can avoid cleaning and stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oHAajzMij8cb"
   },
   "outputs": [],
   "source": [
    "# Saving the Corpus in pickel\n",
    "Corpus_pkl_filename = r'..\\Data\\Pickle_Files\\corpus.pickel'\n",
    "corpus_pkl = open(Corpus_pkl_filename, 'wb')\n",
    "pickle.dump(corpus, corpus_pkl)\n",
    "corpus_pkl.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is used to vectorize the text passed. We are creating this function to remove the redundancy of writing the same code. When we want to vectorize the text using TfIdf, we pass <b>vector = 'TfIDF'</b> and when we want to vectorize using CountVectorizer, we pass <b>vector = 'count'</b> as the input\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wr9eJ7ouThp8"
   },
   "outputs": [],
   "source": [
    "def nlp_technique(vector):\n",
    "    X = ''\n",
    "    vectorizer = ''\n",
    "    if vector == 'TfIDF':\n",
    "        vectorizer=TfidfVectorizer(max_features=10000,ngram_range=(1,3))\n",
    "        X=vectorizer.fit_transform(corpus).toarray()\n",
    "    if vector == 'count':\n",
    "        vectorizer = CountVectorizer(max_features=10000,ngram_range=(1,3))\n",
    "        X = vectorizer.fit_transform(corpus).toarray()\n",
    "    return X, vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-Feetw3TThqI"
   },
   "source": [
    "##### This Function is used to create the confusion matrix by which we can see the true positives, false negatives, true negative and false positive. These values can be used to calculate accuracy, F1 score and Precision. \n",
    "(For further explanation refer the evaluation part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rCEPqTtgThqL"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    See full source and example: \n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "    \n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This function is used to fit any classification model and calculate the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TyT4WasZThqX"
   },
   "outputs": [],
   "source": [
    "def build_model(classifier, X_train, y_train):\n",
    "    classifier.fit(X_train, y_train)\n",
    "    pred = classifier.predict(X_test)\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    print(\"accuracy:   %0.3f\" % score)\n",
    "    cm = metrics.confusion_matrix(y_test, pred)\n",
    "    plot_confusion_matrix(cm, classes=['FAKE', 'REAL'])\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J__ptup5Thqg"
   },
   "source": [
    "### TF- IDF\n",
    "Tf-idf stands for term frequency-inverse document frequency, and the tf-idf weight is a weight often used in information retrieval and text mining. This weight is a statistical measure used to evaluate how important a word is to a document in a collection or corpus. The importance increases proportionally to the number of times a word appears in the document but is offset by the frequency of the word in the corpus.\n",
    "\n",
    "TF: Term Frequency, which measures how frequently a term occurs in a document. Since every document is different in length, it is possible that a term would appear much more times in long documents than shorter ones. Thus, the term frequency is often divided by the document length (aka. the total number of terms in the document) as a way of normalization:\n",
    "\n",
    "TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document).\n",
    "\n",
    "IDF: Inverse Document Frequency, which measures how important a term is. While computing TF, all terms are considered equally important. However it is known that certain terms, such as \"is\", \"of\", and \"that\", may appear a lot of times but have little importance. Thus we need to weigh down the frequent terms while scale up the rare ones, by computing the following:\n",
    "\n",
    "IDF(t) = log_e(Total number of documents / Number of documents with term t in it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wQEjjyGdh7WI",
    "outputId": "888d8115-f8f4-44f7-dcdb-d095de55bb84"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aaron',\n",
       " 'abandon',\n",
       " 'abbott',\n",
       " 'abc',\n",
       " 'abc news',\n",
       " 'abduct',\n",
       " 'abdullah',\n",
       " 'abe',\n",
       " 'abedin',\n",
       " 'abid',\n",
       " 'abil',\n",
       " 'abl',\n",
       " 'abl get',\n",
       " 'abnorm',\n",
       " 'aboard',\n",
       " 'abolish',\n",
       " 'aborigin',\n",
       " 'abort',\n",
       " 'abort right',\n",
       " 'abraham']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TFidf Vectorizer\n",
    "X_TfIDF, vectorizer = nlp_technique('TfIDF')\n",
    "vectorizer.get_feature_names()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "colab_type": "code",
    "id": "vgQBOXNCnKX5",
    "outputId": "3439d376-438f-49a7-dccf-9d9d674dd664"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'analyzer': 'word',\n",
       " 'binary': False,\n",
       " 'decode_error': 'strict',\n",
       " 'dtype': numpy.int64,\n",
       " 'encoding': 'utf-8',\n",
       " 'input': 'content',\n",
       " 'lowercase': True,\n",
       " 'max_df': 1.0,\n",
       " 'max_features': 10000,\n",
       " 'min_df': 1,\n",
       " 'ngram_range': (1, 3),\n",
       " 'norm': 'l2',\n",
       " 'preprocessor': None,\n",
       " 'smooth_idf': True,\n",
       " 'stop_words': None,\n",
       " 'strip_accents': None,\n",
       " 'sublinear_tf': False,\n",
       " 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'tokenizer': None,\n",
       " 'use_idf': True,\n",
       " 'vocabulary': None}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E5KAjR4wl2R6"
   },
   "outputs": [],
   "source": [
    "y=final_dataset['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sxo77-HVnvQa",
    "outputId": "b20680a5-1a72-4027-c4b8-3d170a58c010"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaron</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abbott</th>\n",
       "      <th>abc</th>\n",
       "      <th>abc news</th>\n",
       "      <th>abduct</th>\n",
       "      <th>abdullah</th>\n",
       "      <th>abe</th>\n",
       "      <th>abedin</th>\n",
       "      <th>abid</th>\n",
       "      <th>...</th>\n",
       "      <th>zika viru</th>\n",
       "      <th>zionism</th>\n",
       "      <th>zionist</th>\n",
       "      <th>zombi</th>\n",
       "      <th>zone</th>\n",
       "      <th>zone syria</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zu</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>zulu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aaron  abandon  abbott  abc  abc news  abduct  abdullah  abe  abedin  abid  \\\n",
       "0    0.0      0.0     0.0  0.0       0.0     0.0       0.0  0.0     0.0   0.0   \n",
       "1    0.0      0.0     0.0  0.0       0.0     0.0       0.0  0.0     0.0   0.0   \n",
       "2    0.0      0.0     0.0  0.0       0.0     0.0       0.0  0.0     0.0   0.0   \n",
       "3    0.0      0.0     0.0  0.0       0.0     0.0       0.0  0.0     0.0   0.0   \n",
       "4    0.0      0.0     0.0  0.0       0.0     0.0       0.0  0.0     0.0   0.0   \n",
       "\n",
       "   ...  zika viru  zionism  zionist  zombi  zone  zone syria  zoo   zu  \\\n",
       "0  ...        0.0      0.0      0.0    0.0   0.0         0.0  0.0  0.0   \n",
       "1  ...        0.0      0.0      0.0    0.0   0.0         0.0  0.0  0.0   \n",
       "2  ...        0.0      0.0      0.0    0.0   0.0         0.0  0.0  0.0   \n",
       "3  ...        0.0      0.0      0.0    0.0   0.0         0.0  0.0  0.0   \n",
       "4  ...        0.0      0.0      0.0    0.0   0.0         0.0  0.0  0.0   \n",
       "\n",
       "   zuckerberg  zulu  \n",
       "0         0.0   0.0  \n",
       "1         0.0   0.0  \n",
       "2         0.0   0.0  \n",
       "3         0.0   0.0  \n",
       "4         0.0   0.0  \n",
       "\n",
       "[5 rows x 10000 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visual_df = pd.DataFrame(X_TfIDF, columns=vectorizer.get_feature_names())\n",
    "visual_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hiNi9Wnfn_fk"
   },
   "outputs": [],
   "source": [
    "# USed to Pickel the X variable \n",
    "# X_var_pkl_filename = r'..\\Data\\Pickle_Files\\X_var_TFIDF.pickel'\n",
    "# X_var_pkl = open(X_var_pkl_filename, 'wb')\n",
    "# pickle.dump(X, X_var_pkl)\n",
    "# X_var_pkl.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0RiOnwzqThrw"
   },
   "source": [
    "### Naive Bayes Algorithm\n",
    "Naive Bayes classification makes use of Bayes theorem to determine how probable it is that an item is a member of a category. In our use we will use it to determine if a news article belongs to the real or fake category.<br><br>\n",
    "To run a Naive Bayes classifier in Scikit Learn, the categories must be numeric, so I assigned the label “1” to all fake news and the label “0” to all real news<br><br>\n",
    "A Naive Bayes classifier needs to be able to calculate how many times each word appears in each document and how many times it appears in each category.Basically a matrix format where each row represents a document and each column represents a word.  Eg .[0,1,1,0,.....] [0,0,1,1….]<br><br>\n",
    "To get our news articles in a matrix format, we can use Scikit Learn’s CountVectorizer. CountVectorizer creates a vector of word counts for each article to form a matrix. Each index corresponds to a word and every word appearing in the article is represented.<br><br>\n",
    "We then create a dataframe of the word counts on which we train our Multinomial Naive Bayes Classifier model.<br><br>\n",
    "We have used the confusion matrix as our metric to evaluate the Naive Bayes model\n",
    "<br><br>\n",
    "<b> Train Test Split</b><br>\n",
    "Now we can split the data into train and test using Sklearn's test train split. We split the data into 75% train and 25% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kxpfkJpyThry"
   },
   "outputs": [],
   "source": [
    "## Divide the dataset into Train and Test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_TfIDF, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Baseline multinomial Naive Bayes classifier.</b><br>\n",
    "<br>\n",
    "With the TF-IDF Vectorizer we want to check the accuracy with normal Machine Learning model. We are using Naive Bayes to classify the text to predict if it is a Fake News or Real News\n",
    "<br>\n",
    "<br>\n",
    "After prediction we are printing the confusion matrix.\n",
    "We are using Confusion matrix as a performance indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ke9xTYXBThr5",
    "outputId": "95a5587c-22c1-42be-b721-ce240e4df048"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.650\n",
      "Confusion matrix, without normalization\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier=MultinomialNB()\n",
    "y_pred = build_model(classifier, X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance\n",
    "\n",
    "Model is trained with the vectorized words using TfIDF and evaluated against the test data\n",
    "\n",
    "We are measuring the accuracy score of the model as the performance indicator.\n",
    "\n",
    "The accuracy of the Baseline Multinomial Naive Bayes model is <b>65%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RDoKbAGTThr8",
    "outputId": "557b4110-2d70-49f6-b4f4-d0f13225cfd8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\WindowsApplication\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.571\n",
      "Confusion matrix, without normalization\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVcAAAEmCAYAAADWT9N8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deZwU1bn/8c93BhhABEEWEdzFBUmi4r7v4r7vRpMYMcYsxmiixsTkJiTc5F5jFDXRmGgWo+QmqMGoUdS4/HABRRFFwDUogqAgKNsMz++PqsF2hO4e6Z6u7vm+fdVruk+frnpqWp45ferUOYoIzMystOoqHYCZWS1ycjUzKwMnVzOzMnByNTMrAydXM7MycHI1MysDJ1dbLUldJP1D0gJJf12D/Zwm6V+ljK1SJO0p6aVKx2HZJ49zrX6STgUuALYCFgKTgBER8ega7vfzwNeB3SKicY0DzThJAQyKiBmVjsWqn1uuVU7SBcCVwE+BfsCGwLXAUSXY/UbAtPaQWIshqUOlY7AqEhHeqnQDegCLgBPy1GkgSb5vpduVQEP62j7ATODbwBxgFvDF9LUfAcuA5ekxzgJ+CPwpZ98bAwF0SJ9/AXiFpPX8KnBaTvmjOe/bDXgKWJD+3C3ntYeAHwOPpfv5F9B7NefWHP93cuI/GjgUmAa8C1yaU38nYDwwP607CuiUvvZwei4fpOd7Us7+vwu8DfyxuSx9z2bpMbZPn68PzAX2qfT/G94qv7nlWt12BToDY/LU+R6wC7At8DmSBHNZzuvrkSTpASQJ9BpJPSPicpLW8G0R0S0ibswXiKS1gKuAQyJibZIEOmkV9XoBd6V11wWuAO6StG5OtVOBLwJ9gU7AhXkOvR7J72AA8APgBuB0YCiwJ/ADSZumdZuAbwG9SX53+wNfBYiIvdI6n0vP97ac/fciacUPzz1wRLxMknj/LKkr8Hvgpoh4KE+81k44uVa3dYG5kf9r+2nAf0XEnIh4h6RF+vmc15enry+PiH+StNq2/JTxrACGSOoSEbMiYsoq6hwGTI+IP0ZEY0T8BZgKHJFT5/cRMS0iFgOjSf4wrM5ykv7l5cCtJInzVxGxMD3+FOCzABExMSIeT4/7GvAbYO8izunyiFiaxvMxEXEDMB14AuhP8sfMzMm1ys0DehfoC1wfeD3n+etp2cp9tEjOHwLdWhtIRHxA8lX6K8AsSXdJ2qqIeJpjGpDz/O1WxDMvIprSx83Jb3bO64ub3y9pC0ljJb0t6X2SlnnvPPsGeCcilhSocwMwBLg6IpYWqGvthJNrdRsPLCHpZ1ydt0i+0jbbMC37ND4AuuY8Xy/3xYi4NyIOJGnBTSVJOoXiaY7pzU8ZU2tcRxLXoIjoDlwKqMB78g6nkdSNpB/7RuCHabeHmZNrNYuIBST9jNdIOlpSV0kdJR0i6edptb8Al0nqI6l3Wv9Pn/KQk4C9JG0oqQdwSfMLkvpJOjLte11K0r3QtIp9/BPYQtKpkjpIOgkYDIz9lDG1xtrA+8CitFV9bovXZwObfuJd+f0KmBgRXybpS/71GkdpNcHJtcpFxBUkY1wvA94B/gN8Dbg9rfITYALwHDAZeDot+zTHug+4Ld3XRD6eEOtIRh28RXIFfW/Si0Ut9jEPODytO4/kSv/hETH308TUSheSXCxbSNKqvq3F6z8EbpY0X9KJhXYm6ShgGElXCCSfw/aSTitZxFa1fBOBmVkZuOVqZlYGTq5mZmXg5GpmVgZOrmZmZVCzE1GoQ5dQp7UrHYa1wtaDBlY6BGult/7zBu+9O7fQWOFWqe++UUTjJ26G+4RY/M69ETGslMcupdpNrp3WpmHLgqNpLENGjx1Z6RCslU48dK/ClVopGhcX9W93yaRrCt1dV1E1m1zNrFoJVP09lk6uZpYtAurqKx3FGnNyNbPsUUm7cSvCydXMMsbdAmZm5eGWq5lZiQm3XM3MSk9uuZqZlUUNjBao/ra3mdWY9IJWoa2YPUmvSZosaZKkCWlZL0n3SZqe/uyZU/8SSTMkvSTp4Jzyoel+Zki6SirctHZyNbNsEUm3QKGtePtGxLYRsUP6/GJgXEQMAsalz5E0GDgZ2IZkEvRrJTU3oa8jWf13ULoVvO3WydXMsqdELdfVOAq4OX18Mx+tQXcUcGu60u+rwAxgJ0n9ge4RMT6S1QX+QP516wAnVzPLnKK7BXpLmpCzDV/FzgL4l6SJOa/3i4hZAOnPvmn5AJJlkprNTMsGpI9bluflC1pmlj11RX3tn5vzVX91do+ItyT1Be6TNDVP3VUdNPKU5+XkambZUsK5BSLirfTnHEljgJ2A2ZL6R8Ss9Cv/nLT6TGCDnLcPJFlwc2b6uGV5Xu4WMLOMKc1oAUlrSVq7+TFwEPA8cCdwZlrtTOCO9PGdwMmSGiRtQnLh6sm062ChpF3SUQJn5LxntdxyNbPsKc1NBP2AMemoqQ7ALRFxj6SngNGSzgLeAE4AiIgpkkYDLwCNwHkR0ZTu61zgJqALcHe65eXkambZU4LbXyPiFeBzqyifB+y/mveMAEasonwCMKQ1x3dyNbNsaf041kxycjWz7PHELWZmpaaamFvAydXMssfdAmZmJeb5XM3MysHLvJiZlYe7BczMysAXtMzMSkzuFjAzKw93C5iZlV4Rq6hknpOrmWVKssqLk6uZWWmJVU9PXWWcXM0sY0RdnS9omZmVnLsFzMzKwMnVzKzU3OdqZlZ6Qm65mpmVg5OrmVkZeLSAmVmpuc/VzKw83C1gZlZivqBlZlYmTq5mZuVQ/bnVydXMMkYeLWBmVhbuFjAzKzFf0DIzK5fqz61Orlkw9a4fsfCDpTStWEFj0wr2OO3n/PT8ozl0ryEsW97EqzPnMvzyP7Fg0WI6dqhn1GWnsP3gDVkRK7jw53/jkYnTAbhj1FdZr093OtTX89gzL3P+z25jxYqo8NnVpsu+fS4P338PvXr34fZxTwLwPz/+Hv++/246dOzEBhttwk+uuI7uPdZh/nvz+Nbwz/P8s09z9Amn8b0R/7tyP/+8/a/ccPX/gETffv0ZefUN9OzVu1KnlQ2qjW6B6u81rhHDhv+KXU4eyR6n/RyAcY9PZegJP2Wnk37G9NfncNGXDgLgS8fuDsCOJ/6Uw78yipEXHLPyf8TTv/s7dj5pJEOPH0Gfnt047sDtK3My7cDRJ5zGr/805mNlu+61H2PGPcmY+x9n400357ejkiTaqaEzX7/oMi78/oiP1W9sbGTk5d/hd3+9izH3P84WW2/DLb+/vs3OIcskFdyyzsk1o8Y9PpWmphUAPDn5VQb0WweArTZdjweffAmAd95bxIKFixk6eEMAFn6wBIAOHero2KGeCLday2WHXfagxzo9P1a2+97706FD8mXws9vvyOxZbwHQtetabL/TbjQ0NHysfkQQESz+8EMigkWLFtK333ptcwIZpzoV3LLOyTUDIoJ/XPs1Hvvzd1a2THOdcdSu3PvYCwBMnvYmR+zzGerr69ho/XXZbvAGDFzvo3/kd15zHm+MG8miD5fy9/ufabNzsI8bc9sf2WPfA/PW6dixI9//6ZUcc8Au7Dt0EK9Mn8qxp5zZRhFmm1uueUhqkjQpZ9s457VfSXpTUl1O2RckjUof10m6WdLvlHhN0uScfV1VrrgrYb8v/pLdTv1vjv7atZxz0p7svv1mK1/7zlkH09S0glv/+RQAN98xnjdnz+exP3+HX1x0HI8/+yqNTU0r6x953jVscuClNHTqwD47btnm52Lwm6t+QX19Bw4/9qS89ZYvX85tf/wtf73nUR6cOJ0tthqysiuhPSsmsVZDci3nBa3FEbFty8I0oR4D/AfYC3ioxesCfg10BL4YEZH+IveNiLlljLdiZr2zAEi+5t/5wHPsuM3GPPb0y5x2xM4cutcQDjnno78lTU0r+M7//n3l8wdvuoAZb7zzsf0tXdbI2H9P5oh9PsMDT0xtm5MwAO746595+P67+e1tYwsmgKlTngNgw403BeDgI47hxmt+WfYYq0E1JM9CKtEtsC/wPHAdcMoqXv8VsC5wRkSsaMvAKqFr505069qw8vEBu27FlJff4sDdtubbXziA48//DYuXLF9Zv0vnjnTt3AmA/XbeisamFUx95W3W6tKJ9Xp3B6C+vo5huw/mpddmt/0JtWOPPngfN177S67+/W106dK1YP1+663Py9On8u685I/j+EceZNNBW5Q7zKpQyparpHpJz0gamz7vJek+SdPTnz1z6l4iaYaklyQdnFM+NP32PEPSVSoigHK2XLtImpQ+fjUijkkfnwL8BbgD+KmkjhHRnD1OBV4E9omIxhb7e1BS8/ffmyPiE3/iJQ0HhgPQsVvpzqSM+q67NrddcTYAHerrue3uCdz3/17k+Tsup6FTB8Ze9zUAnpz8Gt8YcSt9eq7NP649jxUrgrfemc9Zl90MwFpdGvi/K8+hU8cO1NfX8e+npnHD/z1asfOqdRed90WeGv8I89+dx/47bMlXv30pvx11BcuWLeXsU44Ckotal4/8FQAH7bINixYuZPnyZTxw71iuv+UONttiK8791iWcedwwOnToyPoDN2DEL39dydPKjBJfsPomSV7pnj6/GBgXESMlXZw+/66kwcDJwDbA+sD9kraIiCaSxuBw4HHgn8Aw4O6851CuK8qSFkVEtxZlnYDXgC0jYqGkvwM3RsRdkr4AnA5sBZwUEY/lvO81YIfWdAvUde0bDVueuOYnYm1mwtiRlQ7BWunEQ/diyrNPlzQTNqw3KAaeVviyyitXHDoxInbIV0fSQOBmYARwQUQcLuklkgbcLEn9gYciYktJlwBExM/S994L/JAkZz0YEVul5aek7z8n37HbultgGNADmJwmzD34eNfAVOBE4DZJ27RxbGaWAQKkwluRrgS+A+R2MfaLiFkA6c++afkAkmtBzWamZQPSxy3L82rr5HoK8OWI2DgiNgY2AQ6StLKDKiL+H/AV4C5JG7ZxfGZWcUWPFugtaULONvxje5EOB+ZExMSiD/xJkac8rza7/TVNoAcDK5vSEfGBpEeBI3LrRsRYSX2AeyTtmRbn9rk+FxFntEXcZtb2imyZzi3QLbA7cKSkQ4HOQHdJfwJmS+qf0y0wJ60/E9gg5/0DgbfS8oGrKM+rbMm1ZX9rRHwI9FpFvWNznt6UU/574Pfp041LH6GZZVUphmJFxCXAJen+9gEujIjTJf0COBMYmf68I33LncAtkq4guaA1CHgyIpokLZS0C/AEcAZwdaHje+IWM8sUCerryzrOdSQwWtJZwBvACQARMUXSaOAFoBE4Lx0pAHAuSeOvC8kogbwjBcDJ1cwyqNT3EETEQ6Q3LEXEPGD/1dQbQTKyoGX5BGBIa47p5GpmmVMLd2g5uZpZtrRuqFVmObmaWaYk41yrP7s6uZpZxlTHrFeFOLmaWebUVcFk2IU4uZpZtrjP1cys9NznamZWJjWQW51czSx73HI1MyuDGsitTq5mli2SRwuYmZWBx7mamZVFDeRWJ1czyx63XM3MSs03EZiZlZ6Aurq2Xt6v9JxczSxz3HI1MysD97mamZWa+1zNzEpPHudqZlYeNZBbnVzNLHvqffurmVlpSTV+QUtS93xvjIj3Sx+OmRnUQMM1b8t1ChAkY3qbNT8PYMMyxmVm7VhNt1wjYoO2DMTMrFkN5FaKusdM0smSLk0fD5Q0tLxhmVl7JdLhWAX+y7qCyVXSKGBf4PNp0YfAr8sZlJm1YxL1dYW3rCtmtMBuEbG9pGcAIuJdSZ3KHJeZtWO10C1QTHJdLqmO5CIWktYFVpQ1KjNrtwTU1UB2LabP9Rrgb0AfST8CHgX+u6xRmVm7JhXesq5gyzUi/iBpInBAWnRCRDxf3rDMrD2r6aFYLdQDy0m6Bqp/Flszy6xqaZkWUsxoge8BfwHWBwYCt0i6pNyBmVn7VS8V3LKumJbr6cDQiPgQQNIIYCLws3IGZmbtV3vpFni9Rb0OwCvlCcfM2rtktEClo1hzq+0WkPRLSVeQ3DQwRdJvJd0ATAbmt1WAZtbOKJksu9BWeDfqLOlJSc9KmpKOdkJSL0n3SZqe/uyZ855LJM2Q9JKkg3PKh0qanL52lYoIIF/LtXlEwBTgrpzyxwuelZnZGihRr8BSYL+IWCSpI/CopLuBY4FxETFS0sXAxcB3JQ0GTga2IbnGdL+kLSKiCbgOGE6S//4JDAPuznfwfBO33Ljm52Zm1nql6HONiAAWpU87plsARwH7pOU3Aw8B303Lb42IpcCrkmYAO0l6DegeEePT2P4AHM2nTa7NJG0GjAAGA51zAt+imBM0M2sNUfRKBL0lTch5fn1EXP+xfUn1JBfgNweuiYgnJPWLiFkAETFLUt+0+gA+/s18Zlq2PH3csjyvYi5o3QT8BPgf4BDgi/j2VzMroyLbrXMjYod8FdKv9NtKWgcYI2lIKw/bck7r3PK8irkhoGtE3JsG+nJEXEYyS5aZWclJydwChbbWiIj5JF//hwGzJfVPjqX+wJy02kwgdx7rgcBbafnAVZTnVUxyXZpeGXtZ0lckHQH0LfQmM7NPqxRzC0jqk7ZYkdSF5Bb+qcCdwJlptTOBO9LHdwInS2qQtAkwCHgy7UJYKGmXNBeekfOe1SqmW+BbQDfgGyR9rz2ALxXxPjOzT6VENxH0B25O+13rgNERMVbSeGC0pLOAN4ATACJiiqTRwAtAI3Be2q0AcC5JF2kXkgtZeS9mQXETtzyRPlzIRxNmm5mVhSjNZNgR8Ryw3SrK5wH7r+Y9I0gakS3LJwD5+ms/Id/qr2PI02kbEce25kBmZkWpkYlb8rVcR7VZFGXQc70+HHbh2ZUOw1phs37dKh2CtVLnDuWZJK+m5xaIiHFtGYiZWbNamNe02PlczczahKjxlquZWaXUwqxYRSdXSQ3pPbdmZmUjFX37a6YVsxLBTpImA9PT55+TdHXZIzOzdqtOhbesK6bf+CrgcGAeQEQ8i29/NbMyahervwJ1EfF6iw7mptVVNjNbE8lKBFWQPQsoJrn+R9JOQKS3kX0dmFbesMysPWsvQ7HOJeka2BCYDdyflpmZlUUNNFyLmltgDsnSB2ZmZSeVZm6BSitmJYIbWMUcAxExvCwRmVm7VwO5tahugftzHncGjgH+U55wzKy9azcXtCLittznkv4I3Fe2iMys3auB3Pqpbn/dBNio1IGYmQFQJTcJFFJMn+t7fNTnWge8S7LOt5lZWajYJQozLG9yTdeL+RzwZlq0Il0L3MysLASUaZrYNpX3FNJEOiYimtLNidXMyk5SwS3rivn78KSk7cseiZkZzaMFqn/ilnxraHWIiEZgD+BsSS8DH5Cce0SEE66ZlV6VTMxSSL4+1yeB7YGj2ygWMzOg9se5CiAiXm6jWMzMVnYLVLt8ybWPpAtW92JEXFGGeMys3RP1Nd5yrQe6QQ0MODOzqpEsUFjpKNZcvuQ6KyL+q80iMTODdnGHVg2cnplVo1q/oLV/m0VhZpaq+W6BiHi3LQMxM2vWLibLNjNrS6L9rKFlZtZ2RFXMHVCIk6uZZU71p1YnVzPLmHazzIuZWVur/tTq5GpmmSPqamC0QC1clDOzGtI8WqDQVnA/0gaSHpT0oqQpkr6ZlveSdJ+k6enPnjnvuUTSDEkvSTo4p3yopMnpa1epiCtuTq5mljklWomgEfh2RGwN7AKcJ2kwyRqA4yJiEDAufU762snANsAw4FpJ9em+rgOGA4PSbVihgzu5mlnmqIitkIiYFRFPp48XAi8CA4CjgJvTajfz0ZzVRwG3RsTSiHgVmAHsJKk/0D0ixqdLXf2BIua5dp+rmWVL8eNce0uakPP8+oi4fpW7lDYGtgOeAPpFxCxIErCkvmm1AcDjOW+bmZYtTx+3LM/LydXMMqUVd2jNjYgdCu5P6gb8DTg/It7Pk7hX9ULkKc/LydXMMqdU41wldSRJrH+OiL+nxbMl9U9brf2BOWn5TGCDnLcPBN5Kyweuojwv97maWeZIhbfC+5CAG4EXW6yccidwZvr4TOCOnPKTJTVI2oTkwtWTaRfCQkm7pPs8I+c9q+WWq5llStItUJKW6+7A54HJkialZZcCI4HRks4C3gBOAIiIKZJGAy+QjDQ4LyKa0vedC9wEdAHuTre8nFzNLHNK0SsQEY+y+oEFq5yvOiJGACNWUT4BGNKa4zu5mlnGCNXADbBOrmaWOTUwb4uTq5lli0TNL61tZlYRNZBbnVzNLHvc52prrGOduPTAzelYL+oknnpjPmMmz2atTvWct8dG9F6rE3M/WMaoR1/nw2VNbLNeN07ctj8d6kVjU3DrM7N4cfYiAHbeaB2O2KYvdRLPvvU+tz0zq8Jn1z4sWbKEA/bdi2VLl9LY1Mgxxx7P9y//EQDXjrqaX183ig4dOjDskMP46cifM2/ePE496XgmTniK08/4AldeNarCZ5AtyWTZlY5izTm5VtjyFcHIcS+ztHEF9YLLDtqc595ayA4b9uCFtxcx9oU5HD64L4cP7svoSbNYtLSJX/77VeYvbmRAj85ctN+mnD/mBbp1qufk7frzg7unsXBpE8N33YDB/brxQpp4rXwaGhq4574H6NatG8uXL2e/vffgoIMPYcmSxYz9xx089fRzNDQ0MGdOciNQ586d+cEPf8wLU55nypTnKxx9NtVCy9V3aGXA0sYVQLKccH2dCGD7gd155JVkdfNHXnmXoRt0B+D19xYzf3EjAG8uWEKnetGhTvTp1om331/KwqXJmOfn317Ejhv2aPuTaYck0a1bNwCWL19O4/LlSOL631zHhd+5mIaGBgD69k3mB1lrrbXYfY896Ny5c8VizrpS3KFVaU6uGSDBjw/ZglHHbcPzsxbxyrwP6d65IwuWJEl0wZJGujd88kvGjhv04PV3F9O4Ipi9aBn9ezTQe62O1AmGDuxOr64d2/pU2q2mpiZ2HrotG67fl/0OOJCddt6ZGdOm8dijj7Dnbjtz4H57M+GppyodZlUQyWiBQlvWla1bQFITMDk9xqvA5yNifjr114vASznVr4iIP6Tv2w54GhgWEffm7G9RRHQrV7yVFAHfv3saXTvW8Y29NmFAj8ItmgE9Gjhxu/784oFXAPhwWRM3Pfkm5+2xEREwfe4H9OnWUO7QLVVfX88TEycxf/58Tjr+GKY8/zyNTY289957PPzY40x46ilOP/VEXpz2Sk0sG11evomgkMURsS2ApJuB8/jotrKXm19bhVOAR9Of966mTk36cPkKps5ZxGfXX5v3lyynR+cOLFjSSI/OHXh/aePKej27dOSbe23C9ePfYM6iZSvLJ735PpPefB+AfTbvxYqCk6JZqa2zzjrstfc+/Otf9zBgwECOPuZYJLHjTjtRV1fH3Llz6dOnT6XDzLYq+dpfSFt1C4yniMll0xlnjge+ABwkqeY7pdZuqKdrx+Rj6FgvtlmvG7PeX8IzM99nz017AbDnpr14emaSNLt2rOPb+27C6EmzmP7Ohy32lfyt7Nqpnv0H9ebfM+a14Zm0X++88w7z588HYPHixTww7n623HIrjjjyaB568AEApk+bxrJly+jdu3clQ60apViJoNLKPlogXYNmf5Kpv5ptljNLDcDXI+IRkllsXo2IlyU9BBwK/J0iSRpOss4Na63bf01DbxPrdOnI8F03REqGnzzx+gImvbmQGe98yHl7bsRem/Vi3ofLGPXI6wAcsGVv+q3diaOG9OOoIf0A+PkDr7BwaSOn77A+G/bsAsDtk2fz9sJlqz2ulc7bs2Zx9pfOpKmpiRWxguOOP5FDDzucZcuWcc6Xv8TQbYfQqWMnfvu7m1d2CWy5+cYsfP99li1bxj/uvJ2x//wXWw8eXOEzyYZkKFY1pM/8lCwJU4Ydf9TnujEwETgoIprSPtexEfGJGWYkXQNMiogbJB1J0k97Qvpaq/pc1910mzjsx7es+YlYm7n+pM9VOgRrpd133oGJEyeUNBNu/Znt4ve3P1iw3q6b95xYzEoElVLOboHmPteNgE4kfa6rlbZwjwN+IOk14GrgEElrlzFGM8sgFfFf1pW9zzUiFgDfAC5Ml1xYnQOAZyNig4jYOCI2IlmeoeAqi2ZWWzzOtUgR8QzwLMma4JD2ueZs3yAZHTCmxVv/BpyaPu4qaWbOdkFbxG5mbc8XtPJo2T8aEUfkPO1S5D7uJFnXhojwDQ9m7UU1ZM8CPLeAmWVK0jKt/uzq5Gpm2SLPimVmVh5OrmZmpVYdQ60KcXI1s8yphqFWhTi5mlmmVMtQq0KcXM0se2oguzq5mlnm1MLELU6uZpY51Z9anVzNLGtqpNPVydXMMsdDsczMSkx4KJaZWVnUQG51cjWz7KmFFXKdXM0sc2ogtzq5mln21EBudXI1swyqgezq2f3NLFOaJ8suxQKFkn4naY6k53PKekm6T9L09GfPnNcukTRD0kuSDs4pHyppcvraVSqiU9jJ1cyyJZ0su9BWpJuAYS3KLgbGRcQgYFz6HEmDSdb52yZ9z7XpqtQA1wHDgUHp1nKfn+DkambZU6IVCiPiYeDdFsVHATenj2/moxWmjwJujYilEfEqMAPYSVJ/oHtEjI+IAP5AEatSu8/VzDKm6K/9vSVNyHl+fURcX8T7+kXELICImCWpb1o+AHg8p97MtGx5+rhleV5OrmaWOUUOxZobETuU8rCrKIs85Xm5W8DMMqWYHoE1HEwwO/2qT/pzTlo+E9ggp95A4K20fOAqyvNycjWz7Clvdr0TODN9fCZwR075yZIaJG1CcuHqybQLYaGkXdJRAmfkvGe13C1gZplTqsmyJf0F2Iekf3YmcDkwEhgt6SzgDeAEgIiYImk08ALQCJwXEU3prs4lGXnQBbg73fJycjWzzCnVPQQRccpqXtp/NfVHACNWUT4BGNKaYzu5mlm2yHMLmJmVSfVnVydXM8sUT5ZtZlYmNZBbnVzNLHu8tLaZWTlUf251cjWz7KmB3OrkambZIg/FMjMrj2Inw84yJ1czy57qz61OrmaWPa1YaSCznFzNLGOKXyMry5xczSxTauUOLc/namZWBm65mlnm1ELL1cnVzDLHfa5mZtvv0SYAAAigSURBVCUmebSAmVl5OLmamZWeuwXMzMrAF7TMzMqgBnKrk6uZZY9qoOnq5GpmmVIrd2gpIiodQ1lIegd4vdJxlEFvYG6lg7BWqeXPbKOI6FPKHUq6h+R3VsjciBhWymOXUs0m11olaUJE7FDpOKx4/szaJ88tYGZWBk6uZmZl4ORafa6vdADWav7M2iH3uZqZlYFbrmZmZeDkamZWBk6uVU7SupWOwcw+ycm1ikk6CLhSUk/Vwv2C7YA/p/bDybVKpYn1F8CNEfEevpW5WqwLIMn/9mqcP+AqJGkYSWI9JyIekrQBcKmkYm4ZtApQoi/wuqQjI2KFE2xt84dbnXYGukbE45L6AGOAORFRq/evV71IzAG+CPxe0qHNCVZSfaXjs9LzV8kqIml3YO+I+JGkTSWNJ/kD+ZuIuCGn3gYR8Z+KBWqrFRGjJS0DbpV0SkTc1dyClXREUiXGVjZKKwW3XKtAztfHg4AeABFxJvAw0LNFYj0NuErS2m0eqH2CpGGSvi9p1+ayiLidpAV7q6TD0xbsOcCvgamVitVKyy3X6tADeA9YAqz8ChkR35XUR9KDEbGvpOOAbwFnRMTCCsVqH7c38BVgmKQpwCjg1Yj4Wzpy4CZJY4GdgEMjYkYFY7UScss14yRtAvxM0qbAbGDttLwLQER8CXhF0izgUpLE+kKl4rVPuBO4HzgO+BA4GfijpE0j4v+AE4EjgVMj4tnKhWml5pZr9nUG5gDnAH2AmWl5g6Ql6YWSsyRdCPzTibXyJG0FLI2IVyNivKQG4PyIOF/SqcDFQDdJM4FfAetFxLJKxmyl54lbqoCkIcAw4GvAhiStoe2At4DlwELg6IhYXrEgDQBJhwLfBz7f/BVf0iDgbOAlkm8XXyb57HYDHoqIVysUrpWRW64ZJGkfks/m4YhYFhHPS1oOdAW2Bm4CJgNrAd1JhmE5sVaYpINJEusPI2KGpG5AkCzxshFwHnBIRDyc1p8Wbt3ULLdcM0ZSD+AuYBPgSqApIq5IX9sMOAnoD/wxIp6sWKD2MZI+AzwLHBARD6Sf1W+ACyLiOUmfJfmjeHxEvFLBUK2N+IJWxkTEAmAssAyYDhwq6SZJR5P0vV5DMnLgREmdfa96ZeX8/l8juZnjREkbk0yQfW+aWOsi4jngEWBf3zTQPji5ZoSk9XL+of4vcDewMCIOADoBV5CMa907/fnTiFjir5UV1wkgHfp2GtANeBm4PSJ+kSbWFZK2JekeuCcimioXrrUVJ9cMkHQYyUWq3ukNAyJppW6XDsHahWTQ+ZXAscAzEfFupeK1RDp5zq2Sfijp2IhYQjKq4xZgV4A0sZ4FXAXcEBFvVi5ia0vuc62wdBKW7wEjIuIeSZ0iYlk6GctEkpbQic23RErqGhEfVjBkY+Xn9iPgD0BfYH3g5xExPb077lqSi1n/IrmJ4CsR8Xyl4rW25+RaQZJ6kXxVPDYibk8vgvwAuCgi5kgaDnw2Ir7WnHQrGrABH/vcjoqIf0gaCIwArouIx9M6nYDbSG5Z3tHjj9sfdwtUUPrV/gjgB+nV5OtJvvLPSas8C+wvaQsn1uzI+dxGSuoeETNJbvAYKelKSd8mGSZ3FrC5E2v75HGuFZbOitQETAIujYgrJdVHRFNEPCHplkrHaJ+Ufm4rgImS7iG5sHUN0IvkJoGtSYZhuW+8nXK3QEZIOhC4Gtg5IhZIaoiIpZWOy/KTdABJv2r/iJidltUBvTy/bvvmboGMiIj7SGa0elJSLyfW6hAR9wOHAQ9I6peWrXBiNXcLZEhE3J1eCLlf0g6kE9hXOi7LL+dzu1vSDhGxotIxWeW5WyCDJHWLiEWVjsNax5+b5XJyNTMrA/e5mpmVgZOrmVkZOLmamZWBk6uZWRk4ubZTkpokTZL0vKS/Suq6BvvaJ13BFElHSro4T911JH31Uxzjh+k6YUWVt6hzk6TjW3GsjSV5khVbI06u7dfiiNg2IoaQTMz9ldwXlWj1/x8RcWdEjMxTZR2g1cnVrNo4uRokM+RvnrbYXpR0LfA0sIGkgySNl/R02sLtBsmUe5KmSnqUZI5Z0vIvSBqVPu4naYykZ9NtN2AksFnaav5FWu8iSU9Jek7Sj3L29T1JL0m6H9iy0ElIOjvdz7OS/taiNX6ApEckTZN0eFq/XtIvco59zpr+Is2aObm2c5I6AIeQLHgISRL7Q0RsB3wAXEayLtT2wATgAkmdgRtIZobaE1hvNbu/Cvh3RHwO2B6YQrKs9Mtpq/midMLpQcBOwLbAUEl7SRoKnEyyyu2xwI5FnM7fI2LH9HgvksxK1WxjklUcDgN+nZ7DWcCCiNgx3f/ZkjYp4jhmBfn21/ari6RJ6eNHgBtJJnx+vXlOUpIVEAYDj6Ur0HQCxgNbAa9GxHQASX8Chq/iGPsBZwCkS5sskNSzRZ2D0u2Z9Hk3kmS7NjCmeWJwSXcWcU5DJP2EpOuhG3Bvzmuj09tSp0t6JT2Hg4DP5vTH9kiPPa2IY5nl5eTafi2OiG1zC9IE+kFuEXBfRJzSot62JLPsl4KAn0XEb1oc4/xPcYybgKMj4llJXwD2yXmt5b4iPfbXIyI3CaNkgUGzNeJuAcvncWB3SZtDssSMpC2AqcAm6coJAKes5v3jgHPT99ZL6g4sJGmVNrsX+FJOX+4ASX1JFmE8RlKXdNmUI4qId21glqSOJIsF5jpBUl0a86bAS+mxz03rI2kLSWsVcRyzgtxytdWKiHfSFuBfJDWkxZdFxDQlS9DcJWku8CgwZBW7+CZwvZIF+pqAcyNivKTH0qFOd6f9rlsD49OW8yLg9Ih4WtJtJJOIv07SdVHI94En0vqT+XgSfwn4N9CPZD2rJZJ+S9IX+7SSg78DHF3cb8csP0/cYmZWBu4WMDMrAydXM7MycHI1MysDJ1czszJwcjUzKwMnVzOzMnByNTMrg/8PL4NgwefmDGgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "linear_clf = PassiveAggressiveClassifier(n_iter=50)\n",
    "pred_pas = build_model(linear_clf, X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance\n",
    "\n",
    "Model is trained with the vectorized words using TfIDF and evaluated against the test data\n",
    "\n",
    "We are measuring the accuracy score of the model as the performance indicator.\n",
    "\n",
    "The accuracy of the Baseline Passive aggressive classifier model is <b>57%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KTMmSlLgThsA"
   },
   "source": [
    "### CountVectorizer\n",
    "The CountVectorizer provides a simple way to both tokenize a collection of text documents and build a vocabulary of known words, but also to encode new documents using that vocabulary.\n",
    "\n",
    "You can use it as follows:\n",
    "\n",
    "1. Create an instance of the CountVectorizer class.\n",
    "2. Call the fit() function in order to learn a vocabulary from one or more documents.\n",
    "3. Call the transform() function on one or more documents as needed to encode each as a vector.\n",
    "An encoded vector is returned with a length of the entire vocabulary and an integer count for the number of times each word appeared in the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2pm_wMZTThsB"
   },
   "outputs": [],
   "source": [
    "## Count Vectorizer\n",
    "X_Count, vectorizer = nlp_technique('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e4GNjl0TThsF",
    "outputId": "fcce4bf1-a762-49dd-8737-639560a47bad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aa',\n",
       " 'aaron',\n",
       " 'aaron klein',\n",
       " 'ab',\n",
       " 'abadi',\n",
       " 'abandon',\n",
       " 'abba',\n",
       " 'abbott',\n",
       " 'abc',\n",
       " 'abc news',\n",
       " 'abd',\n",
       " 'abdel',\n",
       " 'abduct',\n",
       " 'abdul',\n",
       " 'abdullah',\n",
       " 'abe',\n",
       " 'abedin',\n",
       " 'abedin email',\n",
       " 'aber',\n",
       " 'abet']"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lchHPBv7ThsI",
    "outputId": "71d418e0-de7b-42d9-995d-0a63305c4298"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'analyzer': 'word',\n",
       " 'binary': False,\n",
       " 'decode_error': 'strict',\n",
       " 'dtype': numpy.int64,\n",
       " 'encoding': 'utf-8',\n",
       " 'input': 'content',\n",
       " 'lowercase': True,\n",
       " 'max_df': 1.0,\n",
       " 'max_features': 15000,\n",
       " 'min_df': 1,\n",
       " 'ngram_range': (1, 3),\n",
       " 'preprocessor': None,\n",
       " 'stop_words': None,\n",
       " 'strip_accents': None,\n",
       " 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'tokenizer': None,\n",
       " 'vocabulary': None}"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jLQFhdLhThsN"
   },
   "outputs": [],
   "source": [
    "y=final_dataset['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ulp1LAoHThsQ",
    "outputId": "c350297c-47ef-4252-e471-a305d6adad45"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aaron klein</th>\n",
       "      <th>ab</th>\n",
       "      <th>abadi</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abba</th>\n",
       "      <th>abbott</th>\n",
       "      <th>abc</th>\n",
       "      <th>abc news</th>\n",
       "      <th>...</th>\n",
       "      <th>zionism</th>\n",
       "      <th>zionist</th>\n",
       "      <th>zip</th>\n",
       "      <th>zombi</th>\n",
       "      <th>zone</th>\n",
       "      <th>zone syria</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zu</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>zulu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 15000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aa  aaron  aaron klein  ab  abadi  abandon  abba  abbott  abc  abc news  \\\n",
       "0   0      0            0   0      0        0     0       0    0         0   \n",
       "1   0      0            0   0      0        0     0       0    0         0   \n",
       "2   0      0            0   0      0        0     0       0    0         0   \n",
       "3   0      0            0   0      0        0     0       0    0         0   \n",
       "4   0      0            0   0      0        0     0       0    0         0   \n",
       "\n",
       "   ...  zionism  zionist  zip  zombi  zone  zone syria  zoo  zu  zuckerberg  \\\n",
       "0  ...        0        0    0      0     0           0    0   0           0   \n",
       "1  ...        0        0    0      0     0           0    0   0           0   \n",
       "2  ...        0        0    0      0     0           0    0   0           0   \n",
       "3  ...        0        0    0      0     0           0    0   0           0   \n",
       "4  ...        0        0    0      0     0           0    0   0           0   \n",
       "\n",
       "   zulu  \n",
       "0     0  \n",
       "1     0  \n",
       "2     0  \n",
       "3     0  \n",
       "4     0  \n",
       "\n",
       "[5 rows x 15000 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visual_df = pd.DataFrame(X_Count, columns=vectorizer.get_feature_names())\n",
    "visual_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Baseline multinomial Naive Bayes classifier.</b><br>\n",
    "<br>\n",
    "With the Count Vectorizer we want to check the accuracy with normal Machine Learning model. We are using Naive Bayes to classify the text to predict if it is a Fake News or Real News\n",
    "<br>\n",
    "<br>\n",
    "After prediction we are printing the confusion matrix.\n",
    "We are using Confusion matrix as a performance indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m342v5-2ThsV"
   },
   "outputs": [],
   "source": [
    "## Divide the dataset into Train and Test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_Count, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fNG-LTIfThsY",
    "outputId": "1ff108fd-97ab-49d3-f439-567e987fa2e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.657\n",
      "Confusion matrix, without normalization\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVcAAAEmCAYAAADWT9N8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deZxU1Zn/8c+3aXZoERBlU1AxLrhi0CwmGjc0GjUZHVyiURMTRxOzaNTEMToZEo1Z1MRldIxLkokyP9e4xKjRMRqUoFEBVwwYWQTBBUTW5vn9cU9j0TRVhVR13e7+vn3dV1ede+69p2h5OHXuuc9RRGBmZpVVV+sGmJm1Rw6uZmZV4OBqZlYFDq5mZlXg4GpmVgUOrmZmVeDgauskqbukP0h6V9L/bsB5jpX0p0q2rVYk7SXppVq3w/JPnufa9kk6Bvg2sC2wCHgGGBcRj23geb8IfB34eESs3OCG5pykAEZExLRat8XaPvdc2zhJ3wYuBX4EbApsDlwJHFaB028BvNwRAms5JNXXug3WhkSEtza6ARsB7wFHFqnTlSz4zk7bpUDXtG9vYCbwHWAeMAc4Me27EFgOrEjXOBm4APhtwbmHAQHUp/dfAv5B1nueDhxbUP5YwXEfB/4GvJt+frxg3yPAD4HH03n+BPRfx2drav93C9p/OHAw8DLwFvC9gvqjgQnAO6nur4Auad+j6bMsTp/3XwvOfzbwBvCbprJ0zFbpGrul94OA+cDetf5/w1vtN/dc27aPAd2A24vU+T6wJ7ALsDNZgDmvYP9mZEF6MFkAvULSxhHxA7Le8C0R0SsirivWEEk9gcuBgyKiN1kAfaaFen2Be1LdfsDPgXsk9SuodgxwIjAA6AKcWeTSm5H9GQwGzgeuBY4DRgF7AedL2jLVbQS+BfQn+7PbF/g3gIj4VKqzc/q8txScvy9ZL/6UwgtHxKtkgfd3knoA1wM3RMQjRdprHYSDa9vWD5gfxb+2Hwv8R0TMi4g3yXqkXyzYvyLtXxER95L12j7yIduzChgpqXtEzImIqS3U+SzwSkT8JiJWRsTvgReBQwvqXB8RL0fEEmA82T8M67KCbHx5BXAzWeC8LCIWpetPBXYCiIinIuKJdN0ZwH8Bny7jM/0gIpal9qwhIq4FXgGeBAaS/WNm5uDaxi0A+pcYCxwEvFbw/rVUtvoczYLz+0Cv9W1IRCwm+yr9NWCOpHskbVtGe5raNLjg/Rvr0Z4FEdGYXjcFv7kF+5c0HS9pG0l3S3pD0kKynnn/IucGeDMilpaocy0wEvhlRCwrUdc6CAfXtm0CsJRsnHFdZpN9pW2yeSr7MBYDPQreb1a4MyLuj4j9yXpwL5IFnVLtaWrTrA/ZpvVxFVm7RkREA/A9QCWOKTqdRlIvsnHs64AL0rCHmYNrWxYR75KNM14h6XBJPSR1lnSQpJ+kar8HzpO0iaT+qf5vP+QlnwE+JWlzSRsB5zbtkLSppM+lsddlZMMLjS2c415gG0nHSKqX9K/A9sDdH7JN66M3sBB4L/WqT222fy6w5VpHFXcZ8FREfJlsLPnqDW6ltQsOrm1cRPycbI7recCbwOvA6cAdqcp/ApOA54DJwNOp7MNc6wHglnSup1gzINaRzTqYTXYH/dOkm0XNzrEAOCTVXUB2p/+QiJj/Ydq0ns4ku1m2iKxXfUuz/RcAN0p6R9JRpU4m6TBgDNlQCGS/h90kHVuxFlub5YcIzMyqwD1XM7MqcHA1M6sCB1czsypwcDUzq4J2m4hC9d1DXXrXuhm2HvoPGlDrJth6WjRvFksWvl1qrvB66dSwRcTKtR6GW0ssefP+iBhTqp6kTmQzZmZFxCFpLvItZLkxZgBHRcTbqe65ZI+BNwLfiIj7U/ko4AagO9l0wjOixGyA9htcu/Sm60dKzqaxHDnq/NNq3QRbT+PPOrLi54yVS8r6u7v0mStKPV3X5AzgBaAhvT8HeCgiLpJ0Tnp/tqTtgbHADmRPEj4oaZv0BOBVZLklniALrmOA+4pd1MMCZpYzAtWV3so5kzSELJ/FfxcUHwbcmF7fyAdPOB4G3JzySEwHpgGjJQ0EGiJiQuqt3kTxpyKBdtxzNbM2SkBdp3Jq9pc0qeD9NRFxTbM6l5I9qFI4RrhpRMwBiIg5kprGowaT9UybzExlK9Lr5uVFObiaWf6orGHc+RGx+7pPoUOAeRHxlKS9y7lqC2VRpLwoB1czyxmV/bW/hE8An5N0MFnO3wZJvwXmShqYeq0DyRKtQ9YjHVpw/BCyx7lnptfNy4vymKuZ5Y9UeishIs6NiCERMYzsRtWfI+I44C7ghFTtBODO9PouYKykrpKGAyOAiWkIYZGkPSUJOL7gmHVyz9XM8kVUque6LhcB4yWdDPwTOBIgIqZKGg88D6wETivIFXwqH0zFuo8SMwXAwdXMcqe8nun6SEvvPJJeLyBb4qeleuOAcS2UTyJLiF42B1czy5/yZgvkmoOrmeVMxW5o1ZSDq5nli6j4sEAtOLiaWf6452pmVmkeFjAzq446DwuYmVVW+bkFcs3B1cxyxsMCZmbV4dkCZmZV4J6rmVmFlZmYJe8cXM0sf9xzNTOrNHm2gJlZVXhYwMyswqqfz7VVOLiaWc54nquZWXV4WMDMrAp8Q8vMrMLkYQEzs+rwsICZWeXJwdXMrLKyVV4cXM3MKktpa+McXM0sZ0RdnW9omZlVnIcFzMyqoD0E17bf9zaz9kVlbqVOI3WTNFHSs5KmSrowlV8gaZakZ9J2cMEx50qaJuklSQcWlI+SNDntu1xlRH/3XM0sV4Qq1XNdBnwmIt6T1Bl4TNJ9ad8vIuKna1xX2h4YC+wADAIelLRNRDQCVwGnAE8A9wJjgPsowj1XM8sdSSW3UiLzXnrbOW1R5JDDgJsjYllETAemAaMlDQQaImJCRARwE3B4qes7uJpZ7tTV1ZXcgP6SJhVspzQ/j6ROkp4B5gEPRMSTadfpkp6T9GtJG6eywcDrBYfPTGWD0+vm5cU/w3p/ajOzaip/zHV+ROxesF3T/FQR0RgRuwBDyHqhI8m+4m8F7ALMAX5WcOW1TlGkvCgHVzPLnUoMCxSKiHeAR4AxETE3Bd1VwLXA6FRtJjC04LAhwOxUPqSF8qIcXM0sV5puaG1ocJW0iaQ+6XV3YD/gxTSG2uQIYEp6fRcwVlJXScOBEcDEiJgDLJK0Z5olcDxwZ6nre7aAmeVOhWYLDARulNSJrCM5PiLulvQbSbuQfbWfAXwVICKmShoPPA+sBE5LMwUATgVuALqTzRIoOlMAHFzNLI8qEFsj4jlg1xbKv1jkmHHAuBbKJwEj1+f6Dq5mli/CuQXMzKqhPTz+6uBqZrlSwSe0asrB1czyp+3HVgfXvKirE4//7rvMnvcuXzjjajZu6MFvLj6JLQb15bXZb3Hcd6/jnUVL2H2HLfjVvx8NZMsMjbv6Xu56+Lk1zvW/l36V4YP7sfuRP6rFR2n3+nSv5/hRg2joVk8EPD7jbR559e3V+/fdui9H7LgpZ9/zMouXN7L7kAb2G9Fv9f5BG3Xl4oenM3/xCr611xZrnPdvry/k1slzW/Xz5I48LGAVdPox+/DS9Ln07tkNgDNP3J9HJr7ET69/gDNP3J8zTzyA8y6/k6mvzuYTx/6ExsZVbNa/gSdvOZd7Hp1CY+MqAA77zM4sfn9ZLT9Ku7dqFdw2eR4z311K1/o6zt5nGC/OW8wbi5bTp3s92w7oyVvvr1hdf9LMhUyauRCAQQ1dOWXPIcx6N/sdXfTw9NX1vrv3MJ6ZvbBVP0tetYfg2vZvybUDgwf0Ycwnd+D62/+6uuyQvXfit3/IHoP+7R+e5NB9dgJgydIVqwNp1y6dyfJIZHp278I3jvsMF/33H1ux9R3PwmUrmfnuUgCWrVyVBdVunQH4wo6bcseUeWv8XgqNGtLAUzPXDqCb9OxM7671vLpgSfUa3oaoTiW3vHPPNQcuOesLfP+yO+jVo9vqsgH9evPG/Owv4RvzF7JJ396r93105BZcfcFxbD6wLyefd+PqYPuDfzuEy37zEO8vWd66H6AD69ujM0M26saMt5ew42a9eGfJSmYtXPc3h90GN3DNEzPXKh81ZCOenuVeaxP3XIuQ1FiQjPYZScMK9l2WktXWFZR9SdKv0us6STemjDWSNCMlqm061+XVandrO2ivkcx7axF/f+H10pWTv015jVH/Mo5PHvcTzjrpALp2qWenbQaz5dBN1hp/terp0kl8efRgbp08l8YIDvxIf+554c111t9i426saFzFnEVrB99RQxpWDx10dOU8+toWgm81e65LUjaaNaSAegRZaq9PkSVTKNwv4Gqy3IsnRkSkP8h9ImJ+FdtbEx/bZUsO+fSOjPnkDnTt0pmGnt349X8ez7wFi9isfwNvzF/IZv0bePOtRWsd+9L0uSxespwdth7EqB02Z7ftN+fFey6kvlMdm/Ttzf3XnsGBX7msBp+q/asTfGWPIUyauZBnZy9iUENX+vXszLmfGQ5An+6dOXuf4VzyyHQWLcueoFxXAB3c0JVOdfD6O0tb9TPkWVsInqXUYlhgH7JECbcAR9MsuAKXAf2Af01Za9q18395F+f/8i4A9ho1gm8evy8nnXcTP/rm4Rx36B789PoHOO7QPbj7kaxHusWgfsyc+zaNjavYfODGbDNsU16bvYCnn/8n1/7vYwBsPrAvt13+NQfWKjp2t4G8sWg5f572FgCzFy7j3HtfWb3/wgO24iePzGDx8iywCth1cAOXPvraWucaNbSBSa+711rIwbW47ilJLcD0iDgivT4a+D1ZVpkfSeocEU23Vo8BXgD2joiVzc73sKSmJAo3RsQvml8wJcvNEuZ27lW5T1IDP73+AX578UmccPjHeH3O2xz73esA+PiuW3LmiQewYmUjq1YFZ/zoFha8s7jGre1YtuzXnT0278Osd5dyzj5ZT/Wu5+fx/Nx1/x627t+Dd5asZEHBLIImuw1u4Kq/lj8s1BG0hRtWpWhddzU3+MTSexHRq1lZF7IsNB+JiEWSbgOui4h7JH0JOA7YlqzX+njBcTOA3ddnWKCux4Do+pGjNvyDWKs5+fzTat0EW0/jzzqSedOmVDQSdt1sRAw5tvRtlX/8/OCnImL3Sl67klp7KtYYYCNgcgqYnyTryTZ5ETgKuEXSDq3cNjPLAZE9IFNqy7vWDq5HA1+OiGERMQwYDhwgqUdThYj4K/A14B5Jm7dy+8ys5jxbYL2kAHogKTEtQEQslvQYcGhh3ZTQdhPgj5L2SsWFY67PRcTxrdFuM2t9bSB2llS14Np8vDUi3gf6tlDv8wVvbygovx64Pr0dVvkWmlletYWeaSl+QsvMckWCTp0cXM3MKq4ddFwdXM0sfzwsYGZWaW1kqlUpDq5mlivZPNe2H10dXM0sZ9rGPNZSHFzNLHfq2kFuAQdXM8sXj7mamVVeexlz9RpaZpY7lUjcIqmbpImSnpU0VdKFqbyvpAckvZJ+blxwzLmSpkl6SdKBBeWj0moo0yRdrjKiv4OrmeVOhRK3LAM+ExE7A7sAYyTtCZwDPBQRI4CH0nskbQ+MBXYgy+B3paRO6VxXkeWKHpG2MaUu7uBqZrlTiZ5rZN5LbzunLYDDgBtT+Y3A4en1YcDNEbEsIqYD04DRkgYCDRExIbIE2DcVHLNODq5mlitSNlug1Ab0lzSpYDtl7XOpU1oRZR7wQEQ8CWwaEXMA0s8BqfpgsrX9msxMZYPT6+blRfmGlpnlTNlf++eXWokgIhqBXST1AW6XNLLohVs4RZHyotxzNbPcqfRKBBHxDtliqGOAuemrPunnvFRtJjC04LAhwOxUPqSF8qIcXM0sdypxQ0vSJqnHiqTuwH5kS0ndBZyQqp1AtlgqqXyspK6ShpPduJqYhg4WSdozzRI4vuCYdfKwgJnlS+UeIhgI3Jju+NcB49MqJxOA8ZJOBv4JHAkQEVMljQeeB1YCp6VhBYBTyZL5dwfuS1tRDq5mlisC6uo2/Et1RDwH7NpC+QJg33UcMw4Y10L5JKDYeO1aHFzNLHfawQNaDq5mlj/t4fFXB1czyxcnbjEzqzw5n6uZWXW0g9jq4Gpm+dPJybLNzCorewKrHQdXSQ3FDoyIhZVvjpkZtIOOa9Ge61TWTlrQ9D6AzavYLjPrwNp1zzUihq5rn5lZNbWD2Fpe4hZJYyV9L70eImlUdZtlZh2VSNOxSvyXdyWDq6RfAfsAX0xF7wNXV7NRZtaBSXSqK73lXTmzBT4eEbtJ+jtARLwlqUuV22VmHVh7GBYoJ7iukFRHyrwtqR+wqqqtMrMOS0BdO4iu5Yy5XgHcCmySlqZ9DLi4qq0ysw6t0isR1ELJnmtE3CTpKbIs3gBHRsSU6jbLzDqydj0Vq5lOwAqyoQEvDWNmVdNWeqallDNb4PvA74FBZAtz/Y+kc6vdMDPruDpJJbe8K6fnehwwKiLeB5A0DngK+HE1G2ZmHVdHGRZ4rVm9euAf1WmOmXV02WyBWrdiwxVL3PILsjHW94Gpku5P7w8gmzFgZlZ5ZS6dnXfFeq5NMwKmAvcUlD9RveaYmbWPG1rFErdc15oNMTNr0t57rgBI2opsHe/tgW5N5RGxTRXbZWYdlGgfKxGUM2f1BuB6ss98EDAeuLmKbTKzDk5lbHlXTnDtERH3A0TEqxFxHlmWLDOzipOy3AKltrwrJ7guUzYA8qqkr0k6FBhQ5XaZWQdWidwCkoZKeljSC5KmSjojlV8gaZakZ9J2cMEx50qaJuklSQcWlI+SNDntu1xlDAqXM8/1W0Av4BtkY68bASeVcZyZ2YdSoRtaK4HvRMTTknoDT0l6IO37RUT8tNk1twfGAjuQPZH6oKRtIqIRuAo4hWy21L3AGOC+YhcvJ3HLk+nlIj5ImG1mVhWiMsmwI2IOMCe9XiTpBWBwkUMOA26OiGXAdEnTgNGSZgANETEBQNJNwOF82OAq6XZSDtd1NPzzxU5sZvahlJ+4pb+kSQXvr4mIa1o8pTQM2BV4EvgEcLqk44FJZL3bt8kCb+E8/pmpbEV63by8qGI911+VOjjPdt1ucx5/sk1/hA7nzD+8UOsmWE6UOSwwPyJ2L+NcvchyUn8zIhZKugr4IVnn8YfAz8iGOlu6aPMVsAvLiyr2EMFDpQ42M6uGSuU1ldSZLLD+LiJuA4iIuQX7rwXuTm9nAoWrXg8BZqfyIS2UF+XcrGaWKyLruZbaSp4nq3Qd8EJE/LygfGBBtSP44FH/u4CxkrpKGg6MACamsdtFkvZM5zweuLPU9ctNlm1m1moq9IDWJ8huwk+W9Ewq+x5wtKRdyL7azwC+ChARUyWNB54nm2lwWpopAHAq2QNV3cluZBW9mQXrEVwldU130czMqkaqzOOvEfEYLY+X3lvkmHFkU06bl08CRq7P9ctZiWC0pMnAK+n9zpJ+uT4XMTNbH3UqveVdOWOulwOHAAsAIuJZ/PirmVVRh1j9FaiLiNeaDSA3rquymdmGyFYiaAPRs4RyguvrkkYDIakT8HXg5eo2y8w6svYwjamc4Hoq2dDA5sBc4MFUZmZWFe2g41pWboF5ZMkMzMyqTqpMboFaK2clgmtp4VGviDilKi0ysw6vHcTWsoYFHix43Y3siYbXq9McM+voOswNrYi4pfC9pN8AD6yjupnZBmsHsfVDPf46HNii0g0xMwOgjTwkUEo5Y65v88GYax3wFnBONRtlZh2b2sQShMUVDa4pA8zOwKxUtCoiSuYxNDP7sATUt4OJrkU/Qgqkt0dEY9ocWM2s6iqRcrDWyvn3YaKk3areEjMzmmYLtP3ELcXW0KqPiJXAJ4GvSHoVWEz22SMiHHDNrPLaSGKWUoqNuU4EdiNb5dDMrNW093muAoiIV1upLWZmq4cF2rpiwXUTSd9e187CNWnMzCpHdGrnPddOQC9aXibBzKwqsgUKa92KDVcsuM6JiP9otZaYmUGHeEKrHXw8M2uL2vsNrX1brRVmZkm7HxaIiLdasyFmZk06RLJsM7PWJDrOGlpmZq1HtIncAaU4uJpZ7rT90No+et9m1o40LfNSait5HmmopIclvSBpqqQzUnlfSQ9IeiX93LjgmHMlTZP0kqQDC8pHSZqc9l2uMrrWDq5mljsqYyvDSuA7EbEdsCdwmqTtyZL9PxQRI4CH0nvSvrHADsAY4EpJndK5rgJOAUakbUypizu4mlnOiLq60lspETEnIp5OrxcBLwCDgcOAG1O1G/kgOdVhwM0RsSwipgPTgNGSBgINETEh5bS+iTISWnnM1cxyZT1mC/SXNKng/TURcU2L55SGAbsCTwKbRsQcyAKwpAGp2mDgiYLDZqayFel18/KiHFzNLHfKnC0wPyJ2L+NcvYBbgW9GxMIi525pRxQpL8rDAmaWOxUac0VSZ7LA+ruIuC0Vz01f9Uk/56XymcDQgsOHALNT+ZAWyotycDWzfFFl1tBKd/SvA15oliL1LuCE9PoE4M6C8rGSukoaTnbjamIaQlgkac90zuMLjlknDwuYWa5U8AmtTwBfBCZLeiaVfQ+4CBgv6WTgn8CRABExVdJ44HmymQanRURjOu5U4AagO3Bf2opycDWz3KlEVqyIeIx1jyC0mJgqIsYB41oonwSMXJ/rO7iaWe60g6dfHVzNLF+yYYG2H10dXM0sd9xzNTOrOCH3XM3MKs89VzOzCpNo90trm5nVRDuIrQ6uZpY/HnO1ivvV5Zdx/a+vJSI48aSv8PUzvsm5Z5/Fvff8gS6duzB8q6245r+vp0+fPvxt4kROP/UUACKC759/AYcdfkSNP0H716d7PcePGkRDt3oi4PEZb/PIq2+v3r/v1n05YsdNOfuel1m8PHvAZ1BDV47edTO61XciIvjJIzPoVCe+tdcWa5z3b68v5NbJc1v9M+VJliy71q3YcA6uOTJ1yhSu//W1/OWvE+nSpQuf++wYDjr4s+y73/78cNyPqa+v5/vnns0lF/+YcT++mB1GjuTxJydRX1/PnDlz2GPUznz2kEOpr/evtZpWrYLbJs9j5rtL6Vpfx9n7DOPFeYt5Y9Fy+nSvZ9sBPXnr/RWr69cJTth9EDdNms2shcvo2aUTjauClauCix6evrred/cexjOzF9bgE+VPe+i5OnFLjrz44guMHr0nPXr0oL6+nr0+9WnuvPN29tv/gNUBc/QeezJrZpZasqkewLKlS9vFom5twcJlK5n57lIAlq1clQXVbp0B+MKOm3LHlHlkOZUz2w7oyax3lzFr4TIAFi9vXCtf3SY9O9O7az2vLljSKp8h76TSW945uObIDjuM5LHHHmXBggW8//77/PG+e5n5+utr1Lnphl9z4JiDVr+f+OST7LbzDuy+645cfsXV7rW2sr49OjNko27MeHsJO27Wi3eWrFwdRJsM6NUFgNM+PpSz9xnOfiP6rnWeUUM24ulZ7rVCNizQSSq55V3VgqukRknPSJoi6Q+S+qTyYZKWpH1N2/EFx+0qKQoXB0vl71WrrXmx7Xbb8Z0zz+aQMfvzuc+OYaeddl4jWF7843F0qq9n7DHHri4bvccePP3sVB6b8DcuufjHLF26tBZN75C6dBJfHj2YWyfPpTGCAz/Sn3teeHOtep0ktuzXnRsmzebnj85g50G92WaTHmvUGTWkgUkzHVwzKuu/vKtmz3VJROwSESOBt4DTCva9mvY1bTcV7DsaeCz97HC+dNLJTPjb0zz48KNs3LcvW289AoDf3nQj995zNzfc9LsWv/5vu9129OzZk6lTprR2kzukOsFX9hjCpJkLeXb2Ijbp2YV+PTtz7meGc+EBW9Gne2fO3mc4vbt24p0lK5k2/30WL29kRWMw9Y3FDO3TbfW5Bjd0pVMdvP6O/2EEUj7Xtj8s0FrfIScAO5WqlBLR/guwP/AXSd0iokP9Hzdv3jwGDBjAP//5T+684zYe+csE/nT/H/nZTy/mTw/9Hz16fNDjmTF9OkOGDqW+vp7XXnuNl19+iS2GDatd4zuQY3cbyBuLlvPnaW8BMHvhMs6995XV+y88YCt+8sgMFi9v5Pl577HfNv3o3Ek0rgq27t+Dh9NxAKOGNjDpdfdaC7WB2FlS1YNrWpp2X7KM4E22KkheC/D1iPgLWXLb6RHxqqRHgIOB2yiTpFPIlr9l6Oabb2jTa+Loo77AW28toHN9Zy69/Ao23nhjvnXG6SxbtoxDxuwPZDe1fnnl1fz18cf46SUX0bm+M3V1dVz2yyvp379/jT9B+7dlv+7ssXkfZr27lHP2GQ7AXc/P4/m5i1usv2TFKv48bQHf3Xs4QdZznTr3g1Gu3QY3cNVfX2/x2I4om4rV9sOrCu9qVvTEUiMwGRgGPAUcEBGNaRXGu9NwQfNjrgCeiYhrJX0O+GJEHJn2vRcRvcq9/qhRu8fjT04qXdFy48w/vFDrJth6Gn/WkcybNqWikXC7HXeN6+94uGS9j2298VPlLFBYK1UfcwW2ALqw5pjrWlIP9wvA+ZJmAL8EDpLUu4ptNLMc8g2tMkTEu8A3gDPTSozrsh/wbEQMjYhhEbEF2aqNh1e7jWaWL+3hhlarzHONiL8DzwJjU9FWzaZifYNsdsDtzQ69FTgmve4haWbB9u3WaLuZtb5KLa1dS1W7odV8fDQiDi14273Mc9xFttwtEeEHHsw6irYQPUvw4zxmlitZz7TtR1cHVzPLFzkrlplZdTi4mplVWtuYalWKg6uZ5U5bmGpViu/Am1mulDMNq9zYK+nXkuZJmlJQdoGkWQVTQQ8u2HeupGmSXirMzCdplKTJad/lKiN5soOrmeVP5Sa63gCMaaH8FwVZ+e4FkLQ92Vz8HdIxV6YnRwGuIstbMiJtLZ1zDQ6uZpY7dVLJrRwR8ShZytNyHAbcHBHLImI6MA0YLWkg0BAREyJLxnITZTw56uBqZrlTZse1v6RJBdsp63GJ0yU9l4YNNk5lg4HC9GQzU9ng9Lp5eVEOrmaWL+UPus6PiN0LtmvKvMJVwFbALsAc4GcFV24uipQX5dkCZpY71ZyKFRGr1y6XdC1wd3o7ExhaUHUIMDuVD2mhvCj3XM0sV0R1s2KlMdQmR4PXWXwAAAs2SURBVABNMwnuAsZK6ippONmNq4kRMQdYJGnPNEvgeODOUtdxz9XMcqdS/VZJvwf2JhufnQn8ANhb0i5kX+1nAF8FiIipksYDzwMrgdMiojGd6lSymQfdgfvSVpSDq5nlThnTSMsSES0tdHpdC2VN9ccB41oonwSstXpKMQ6uZpY77eEJLQdXM8uddhBbHVzNLIfaQXR1cDWzXHGybDOzanCybDOzKnFwNTOrNCfLNjOrCk/FMjOrsPVL15pfDq5mlj/tILo6uJpZ7pSbDDvPHFzNLHfafmh1cDWzvNnAlIJ54eBqZjnU9qOrg6uZ5UpTsuy2zsHVzHKnHcRWB1czyx/PFjAzq4a2H1sdXM0sf9pBbHVwNbN82dDVXfPCwdXMcsdZsczMqqHtx1YHVzPLH69EYGZWcU6WbWZWce3lCa26WjfAzKw9cnA1s9xpmo5VbCvvPPq1pHmSphSU9ZX0gKRX0s+NC/adK2mapJckHVhQPkrS5LTvcql0CxxczSx3VMZ/ZboBGNOs7BzgoYgYATyU3iNpe2AssEM65kpJndIxVwGnACPS1vyca3FwNbNckbLZAqW2ckTEo8BbzYoPA25Mr28EDi8ovzkilkXEdGAaMFrSQKAhIiZERAA3FRyzTr6hZWb5U17w7C9pUsH7ayLimjKO2zQi5gBExBxJA1L5YOCJgnozU9mK9Lp5eVEOrmaWO2V+7Z8fEbtX9LJriyLlRXlYwMxyp1I3tNZhbvqqT/o5L5XPBIYW1BsCzE7lQ1ooL8rB1cxyR2VsG+Au4IT0+gTgzoLysZK6ShpOduNqYhpCWCRpzzRL4PiCY9bJwwJmljtlzHQq9zy/B/YmG5+dCfwAuAgYL+lk4J/AkQARMVXSeOB5YCVwWkQ0plOdSjbzoDtwX9qKcnA1s1yp5BNaEXH0Onbtu47644BxLZRPAkauz7WVzSxofyS9CbxW63ZUQX9gfq0bYeulPf/OtoiITSp5Qkl/JPszK2V+RJScb1or7Ta4tleSJlX4DqlVmX9nHZNvaJmZVYGDq5lZFTi4tj3lPIFi+eLfWQfkMVczsypwz9XMrAocXM3MqsDBtY2T1K/WbTCztTm4tmGSDgAulbRxOZnRrfb8e+o4HFzbqBRYLwGui4i38aPMbUU/AEn+u9fO+RfcBkkaQxZYvxoRj0gaCnxPUjmPDFoNKDMAeE3S5yJilQNs++Zfbtu0B9AjIp6QtAlwOzAvItrr8+ttXmTmAScC10s6uCnAFqzTZO2Iv0q2IZI+AXw6Ii6UtKWkCWT/QP5XRFxbUG9oRLxes4baOkXEeEnLgZslHR0R9zT1YCUdmlWJu2vbSqsE91zbgIKvjwcAGwFExAnAo8DGzQLrscDlknq3ekNtLZLGSPp3SR9rKouIO8h6sDdLOiT1YL8KXA28WKu2WmW559o2bAS8DSwFVn+FjIizJW0i6eGI2EfSF4BvAcdHxKIatdXW9Gnga8AYSVOBXwHTI+LWNHPgBkl3A6OBgyNiWg3bahXknmvOpeUmfixpS2Au0DuVdweIiJOAf0iaA3yPLLA+X6v22lruAh4EvgC8D4wFfiNpy4j4f8BRwOeAYyLi2do10yrNPdf860a2gNpXgU34YInfrpKWphslJ0s6E7jXgbX2JG0LLIuI6RExQVJX4JsR8U1JxwDnAL3SsiOXAZtFxPJattkqz4lb2gBJI4ExwOnA5mS9oV3JVqBcASwCDo+IFTVrpAEg6WDg34EvNn3FlzQC+ArwEtm3iy+T/e4+DjwSEdNr1FyrIvdcc0jS3mS/m0cjYnlETJG0AugBbEe2UNpkoCfQQDYNy4G1xiQdSBZYL4iIaZJ6ka1vPx/YAjgNOCgiHk31Xw73btot91xzRtJGwD3AcOBSoDEifp72bQX8KzAQ+E1ETKxZQ20NknYEngX2i4g/p9/VfwHfjojnJO1E9o/iv0TEP2rYVGslvqGVMxHxLnA3sBx4BThY0g2SDicbe72CbObAUZK6+Vn12ir4859B9jDHUZKGkSXIvj8F1rqIeA74C7CPHxroGBxcc0LSZgV/UX9Gti76oojYD+gC/JxsXuun088fRcRSf62suS4AaerbsUAv4FXgjoi4JAXWVZJ2IRse+GNENNauudZaHFxzQNJnyW5S9U8PDIisl7prmoK1J9mk80uBzwN/j4i3atVey6TkOTdLukDS5yNiKdmsjv8BPgaQAuvJwOXAtRExq3YtttbkMdcaS0lYvg+Mi4g/SuoSEctTMpanyHpCRzU9EimpR0S8X8MmG6t/bxcCNwEDgEHATyLilfR03JVkN7P+RPYQwdciYkqt2mutz8G1hiT1Jfuq+PmIuCPdBDkfOCsi5kk6BdgpIk5vCro1bbABa/zeDouIP0gaAowDroqIJ1KdLsAtZI8sf9TzjzseDwvUUPpqfyhwfrqbfA3ZV/55qcqzwL6StnFgzY+C39tFkhoiYibZAx4XSbpU0nfIpsmdDGztwNoxeZ5rjaWsSI3AM8D3IuJSSZ0iojEinpT0P7Vuo60t/d5WAU9J+iPZja0rgL5kDwlsRzYNy2PjHZSHBXJC0v7AL4E9IuJdSV0jYlmt22XFSdqPbFx1YETMTWV1QF/n1+3YPCyQExHxAFlGq4mS+jqwtg0R8SDwWeDPkjZNZascWM3DAjkSEfelGyEPStqdlMC+1u2y4gp+b/dJ2j0iVtW6TVZ7HhbIIUm9IuK9WrfD1o9/b1bIwdXMrAo85mpmVgUOrmZmVeDgamZWBQ6uZmZV4ODaQUlqlPSMpCmS/ldSjw04195pBVMkfU7SOUXq9pH0bx/iGhekdcLKKm9W5wZJ/7Ie1xomyUlWbIM4uHZcSyJil4gYSZaY+2uFO5VZ7/8/IuKuiLioSJU+wHoHV7O2xsHVIMuQv3Xqsb0g6UrgaWCopAMkTZD0dOrh9oIs5Z6kFyU9RpZjllT+JUm/Sq83lXS7pGfT9nHgImCr1Gu+JNU7S9LfJD0n6cKCc31f0kuSHgQ+UupDSPpKOs+zkm5t1hvfT9JfJL0s6ZBUv5OkSwqu/dUN/YM0a+Lg2sFJqgcOIlvwELIgdlNE7AosBs4jWxdqN2AS8G1J3YBryTJD7QVsto7TXw78X0TsDOwGTCVbVvrV1Gs+KyWcHgGMBnYBRkn6lKRRwFiyVW4/D3y0jI9zW0R8NF3vBbKsVE2Gka3i8Fng6vQZTgbejYiPpvN/RdLwMq5jVpIff+24ukt6Jr3+C3AdWcLn15pykpKtgLA98HhagaYLMAHYFpgeEa8ASPotcEoL1/gMcDxAWtrkXUkbN6tzQNr+nt73Igu2vYHbmxKDS7qrjM80UtJ/kg099ALuL9g3Pj2W+oqkf6TPcACwU8F47Ebp2i+XcS2zohxcO64lEbFLYUEKoIsLi4AHIuLoZvV2IcuyXwkCfhwR/9XsGt/8ENe4ATg8Ip6V9CVg74J9zc8V6dpfj4jCIIyyBQbNNoiHBayYJ4BPSNoasiVmJG0DvAgMTysnABy9juMfAk5Nx3aS1AAsIuuVNrkfOKlgLHewpAFkizAeIal7Wjbl0DLa2xuYI6kz2WKBhY6UVJfavCXwUrr2qak+kraR1LOM65iV5J6rrVNEvJl6gL+X1DUVnxcRLytbguYeSfOBx4CRLZziDOAaZQv0NQKnRsQESY+nqU73pXHX7YAJqef8HnBcRDwt6RayJOKvkQ1dlPLvwJOp/mTWDOIvAf8HbEq2ntVSSf9NNhb7tLKLvwkcXt6fjllxTtxiZlYFHhYwM6sCB1czsypwcDUzqwIHVzOzKnBwNTOrAgdXM7MqcHA1M6uC/w8D1YpaCzhJxgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier=MultinomialNB()\n",
    "build_model(classifier, X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance\n",
    "\n",
    "Model is trained with the vectorized words using Count Vectorizer and evaluated against the test data\n",
    "\n",
    "We are measuring the accuracy score of the model as the performance indicator.\n",
    "\n",
    "The accuracy of the Baseline multinomial Naive Bayes model is <b>65.7%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Q4MCqrUThsa",
    "outputId": "d2cbfd13-8bfb-476b-dab7-1fcf214797a5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\WindowsApplication\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.551\n",
      "Confusion matrix, without normalization\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "linear_clf = PassiveAggressiveClassifier(n_iter=50)\n",
    "build_model(linear_clf, X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance\n",
    "\n",
    "Model is trained with the vectorized words using Count Vectorizer and evaluated against the test data\n",
    "\n",
    "We are measuring the accuracy score of the model as the performance indicator.\n",
    "\n",
    "The accuracy of the Baseline Passive aggressive classifier model is <b>55.1%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5vgYFu4R583B"
   },
   "source": [
    "## Long Short Term Memory (LSTM)\n",
    "\n",
    "### Overview\n",
    "Long Short Term Memory networks – usually just called “LSTMs” – are a special kind of RNN, capable of learning long-term dependencies. Unlike standard feedforward neural networks, LSTM has feedback connections. It can not only process single data points like image data, it can also process sequence of data like speech detection and Spam/ Fake News classifier.\n",
    "\n",
    "Since Naive Bayes Classifier and Passive Aggressive Classifier did not yield the expected result, we will use LSTM to try and improve the accuracy.\n",
    "As mentioned above the LSTM works on both feed forwarding and back propagation to learn from the data and can measure the sentiment of a text, so deep neural network can be a better approach to predict real or fake news and this could help in yielding better accuracy\n",
    "<br>\n",
    "<br>\n",
    "### Environment\n",
    "To use the LSTM Model we need to install Tensorflow in the system.\n",
    "We can use <b>!pip install tensorflow</b> and install the tensorflow. Then we are importing different libraries like Tokenizer which is used to tokenize the text data.<b> Pad_sequence</b> is used to evenly shape the features and the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wY-BRZBiThsi"
   },
   "outputs": [],
   "source": [
    "# importing neural network libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, GRU, LSTM, RNN, SpatialDropout1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VF4ml9ixThsn"
   },
   "outputs": [],
   "source": [
    "#### Cleaning the dataset to remove any anomalies\n",
    "final_dataset = dataset1.copy()\n",
    "final_dataset[['title']] = final_dataset[['title']].fillna(value = 'Missing')\n",
    "final_dataset = final_dataset.dropna()\n",
    "final_dataset.isnull().sum()\n",
    "\n",
    "final_dataset['length'] = final_dataset['text'].apply(lambda x: len(x))\n",
    "final_dataset['text'] =  final_dataset['text'].apply(lambda x : x.strip())\n",
    "final_dataset = final_dataset.drop(final_dataset['text'][final_dataset['length'] < 40].index, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before defining the network, we need to tokenize the texts. We are using <b>Tensorflow Tokenize function</b> to tokenize the texts and sequence the text data to get the X variable.<br>\n",
    "X - Predictor Variables<br>\n",
    "Y - Target Variable<br>\n",
    "<br>X will have the tokenized words in sequence<br>\n",
    "<br>\n",
    "Tokenizing the text includes converting the words, letters into counts or numbers. <br>\n",
    "We do not explicitly remove the punctuations.This is taken care by an inbuilt option in Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HXzzN58rThsr"
   },
   "outputs": [],
   "source": [
    "max_features = 5000\n",
    "tokenizer = Tokenizer(num_words = max_features, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower = True, split = ' ')\n",
    "tokenizer.fit_on_texts(texts = final_dataset['text'])\n",
    "X = tokenizer.texts_to_sequences(texts = final_dataset['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "__tpOWjbThsu"
   },
   "outputs": [],
   "source": [
    "# now applying padding to make them even shaped.\n",
    "X = pad_sequences(sequences = X, maxlen = max_features, padding = 'pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G_qEf6e0Ths0"
   },
   "outputs": [],
   "source": [
    "y = final_dataset['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JTaDWaoZThs3"
   },
   "outputs": [],
   "source": [
    "# splitting the data training data for training and Test.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Network\n",
    "The Network in keras is defined as a sequence of layer. The sequential class is the container for these layers.\n",
    "The LSTM recurrent layer comprises of memory units called the LSTM. <br>\n",
    "\n",
    "<b>Embedding Layer</b> - The Embedding layer is defined as the first hidden layer of a network. The following parameters of the embedding layers must be defined\n",
    "1. input_dim: This is the size of the vocabulary in the text data. For example, if the data is integer encoded to values between 0-10, then the size of the vocabulary would be 11 words.\n",
    "2. output_dim: This is the size of the vector space in which words will be embedded. It defines the size of the output vectors from this layer for each word. For example, it could be 32 or 100 or even larger. Test different values for your problem.\n",
    "\n",
    "<b>LSTM Layer</b> - This layer consists of LSTM unit. It is composed of a cell, an input gate, an output gate and a forget gate <br><br>\n",
    "<b>Dropout Layer</b> - Dropout is a regularization technique for reducing overfitting in neural networks by preventing complex co-adaptations on training data. <br><br>\n",
    "<b>Dense Layer</b> - A fully connected layer that often follows LSTM layers and is used for outputting a prediction is called Dense.<br>\n",
    "\n",
    "<b>Steps to define the neural network:</b> -<br>\n",
    "    \n",
    "1. The first step is to create the instance of the sequence class. After defining the sequence class, we create the layer and add those to this sequence class. We are naming the class as lstm_nn_model<br>\n",
    "2. The first layer is the <b>input layer</b>. In this layer we are embedding the input features and the output dimensions to form the first layer for the neural network model.<br>\n",
    "3. The second layer is the <b>hidden LSTM layer</b>. The LSTM unit contains the following<br>\n",
    "    a. Dropout rate is 0.3 - Drop<br>\n",
    "    b. Recurrent dropout rate is 0.2<br>\n",
    "    c. units training = 1<br>\n",
    "4. The third layer is a <b>simple dropout layer</b> which will help in reducing oberfitting by dropping 0.4 features<br>\n",
    "\n",
    "5. The fourth layer is the <b>Dense layer</b> of LSTM units. In this layer we are applying an activation function - <b>tanh</b><br>\n",
    "6. The fifth layer is again a simple <b>dropout layer</b> with 0.5% drop out rate<br>\n",
    "7. The last layer is the <b>output layer</b>. In the output layer we using another activation function <b>Softmax</b> and setting the output neurons to be 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bI_b1LMX06mx",
    "outputId": "495ac08b-861a-4757-d170-2871fde0b38b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer 2nd_layer will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "lstm_model = Sequential(name = 'lstm_nn_model')\n",
    "lstm_model.add(layer = Embedding(input_dim = max_features, output_dim = 120, name = '1st_layer'))\n",
    "lstm_model.add(layer = LSTM(units = 100, dropout = 0.3, recurrent_dropout = 0.2, name = '2nd_layer'))\n",
    "lstm_model.add(layer = Dropout(rate = 0.4, name = '3rd_layer'))\n",
    "lstm_model.add(layer = Dense(units = 120,  activation = 'tanh', name = '4th_layer'))\n",
    "lstm_model.add(layer = Dropout(rate = 0.5, name = '5th_layer'))\n",
    "lstm_model.add(layer = Dense(units = len(set(y)),  activation = 'softmax', name = 'output_layer'))\n",
    "# compiling the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the Network\n",
    "After we define the neural network it should compile.<br>\n",
    "<br>\n",
    "This is an efficiency step. It transforms the simple layer that we define into highly complex efficient series of matrix transforms and in a format which is intended to be executed in GPU or CPU. <br>\n",
    "Compilation requires a number of parameters to be specifically tailored to train the model. Specifically the optimization function and the loss function to evaluate the network which is minimized by the algorithm.<br><br>\n",
    "\n",
    "Perhaps the most commonly used <b>optimization</b> algorithms because of their generally better performance are:\n",
    "\n",
    "1. <b>Stochastic Gradient Descent, or ‘sgd‘</b>, that requires the tuning of a learning rate and momentum.\n",
    "2. <b>ADAM, or ‘adam‘</b>, that requires the tuning of learning rate.\n",
    "3. <b>RMSprop, or ‘rmsprop‘<b>, that requires the tuning of learning rate.\n",
    "\n",
    "Here in our compilation we are using <b>\"Stocastic Gradient Descend\"</b> Optimizer and <b>\"Sparse Categorical Cross entropy\"</b> as the cost function and we are measuring the <b>accuracy</b> after each time the neural network is trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.compile(optimizer = 'sgd', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data \n",
    "We are splitting the data into Test and Validation. We will be using the validation set to calculate the validation accuracy during training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X22-Kg545H5Q"
   },
   "outputs": [],
   "source": [
    "# splitting the data training data for Validation and Test.\n",
    "X_Val, X_test, y_Val, y_test = train_test_split(X_test, y_test, test_size = 0.5, random_state = 101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the Network\n",
    "Once the Network is compiled it is ready to accept the weights on the training dataset. <br><br>\n",
    "Fitting the network requires the training data to be specified, both a matrix of input patterns, X, and matching output patterns, y.<br><br>\n",
    "The network is trained using the LSTM algorithm and optimized according to the optimization algorithm and loss function specified when compiling the model.\n",
    "<br><br>\n",
    "The LSTM algorithm requires that the network be trained for a specified number of epochs or exposures to the training dataset.\n",
    "<br><br>\n",
    "Each epoch can be partitioned into groups of input-output pattern pairs called batches. This defines the number of patterns that the network is exposed to before the weights are updated within an epoch. It is also an efficiency optimization, ensuring that not too many input patterns are loaded into memory at a time.\n",
    "<br><br>\n",
    "We are trainig the model to an epoch of 3. We are also provinding the validation dataset that we created to get the accuracy in the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "HMFxoSqS3vwm",
    "outputId": "ac1fb61f-04b8-44d1-9c2e-1eb972e8dfb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "467/467 [==============================] - 8784s 19s/step - loss: 0.6835 - accuracy: 0.5548 - val_loss: 0.6794 - val_accuracy: 0.5533\n",
      "Epoch 2/3\n",
      "467/467 [==============================] - 8891s 19s/step - loss: 0.6749 - accuracy: 0.5547 - val_loss: 0.6682 - val_accuracy: 0.5533\n",
      "Epoch 3/3\n",
      "467/467 [==============================] - 8955s 19s/step - loss: 0.6585 - accuracy: 0.5776 - val_loss: 0.6444 - val_accuracy: 0.6047\n"
     ]
    }
   ],
   "source": [
    "lstm_model_fit = lstm_model.fit(X_train, y_train, epochs = 3, validation_data=(X_Val, y_Val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Network\n",
    "Once the model is trained we can evaluate the model. <br><br>\n",
    "The network is trained on training data so it do not give clear picture of the accuracy on the training dataset. So we are using the validation dataset to measure the accuracy. The validation dataset is the data that the model has never seen before.So if it performs well then we can say that the model is good.<br><br>\n",
    "After training the model we get an accuracy of 57.76 % after 3 epochs in the training dataset and an accuracy of 60.4 % in the validation data.<br><br>\n",
    "Clearly the accuracy is not good enough. So will train the hyper parameters to find the best parameters keeping the performance metrics as accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XzxarRKnhUFy"
   },
   "source": [
    "### Hyper-Parameter Tuning\n",
    "##### Tuning the network Layers\n",
    "\n",
    "1. The first layer is kept same. As this is the input layer, we are taking all the features and the data as the input<br>\n",
    "2. The Second layer -Dropout is changed to 0.2 i.ee leaving out 20% of the inputs and feeding the neural network\n",
    "3. The third layer - Dropout changed to 50%. To prevent overfitting\n",
    "4. Fourth layer - In this layer we changed the activation function to RELU. Relu would help in solving the problem of Vanishing Gradient.\n",
    "5. Fifth layer - We are keeping this same\n",
    "6. Output layer - The activation is changed to Sigmoid - Which is used for classification. Sigmoid gives 0 or 1 so it is Sigmoid would perform better that Softmax\n",
    "\n",
    "With this we will train our model again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fnx9suwfThs5",
    "outputId": "cf0b4ffb-fad1-4a89-aa01-caad1ab49dc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer 2nd_layer will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "# LSTM Neural Network\n",
    "lstm_model = Sequential(name = 'lstm_nn_model')\n",
    "lstm_model.add(layer = Embedding(input_dim = max_features, output_dim = 120, name = '1st_layer'))\n",
    "lstm_model.add(layer = LSTM(units = 120, dropout = 0.2, recurrent_dropout = 0.2, name = '2nd_layer'))\n",
    "lstm_model.add(layer = Dropout(rate = 0.5, name = '3rd_layer'))\n",
    "lstm_model.add(layer = Dense(units = 120,  activation = 'relu', name = '4th_layer'))\n",
    "lstm_model.add(layer = Dropout(rate = 0.5, name = '5th_layer'))\n",
    "lstm_model.add(layer = Dense(units = len(set(y)),  activation = 'sigmoid', name = 'output_layer'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The compilation function is also tuned. In place of Stochastic Gradient Descend we are using <b>Adam</b> optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the model\n",
    "lstm_model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "id": "YKviqHz9Ths9",
    "outputId": "ab4bc7ec-7266-4acd-8a35-1901560fa4eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "467/467 [==============================] - 8626s 18s/step - loss: 0.3478 - accuracy: 0.8461 - val_loss: 0.3109 - val_accuracy: 0.8554\n",
      "Epoch 2/4\n",
      "467/467 [==============================] - 9120s 20s/step - loss: 0.1920 - accuracy: 0.9324 - val_loss: 0.3575 - val_accuracy: 0.9036\n",
      "Epoch 3/4\n",
      "467/467 [==============================] - 9166s 20s/step - loss: 0.2187 - accuracy: 0.9142 - val_loss: 0.3196 - val_accuracy: 0.8495\n",
      "Epoch 4/4\n",
      "467/467 [==============================] - 8750s 19s/step - loss: 0.1772 - accuracy: 0.9367 - val_loss: 0.1724 - val_accuracy: 0.9459\n"
     ]
    }
   ],
   "source": [
    "lstm_model_fit = lstm_model.fit(X_train, y_train, epochs = 4, validation_data=(X_Val, y_Val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "After tuning the hyper parameters the accuracy of the model came to be 94% in the validation set.\n",
    "\n",
    "<b>Key Points: -</b>\n",
    "1. Dropout rate of 0.2 performed better than 0.3 in the second layer. This is because when we were using 30% it was dropping most of the features.\n",
    "2. Relu activation function instead of tanh\n",
    "3. In the output layer we previously used Softmax which did not perform well whereas Sigmoid generally performs well on text classification and in this model also it did\n",
    "4. The optimizer we changed from SGD to Adam which helped to optimize the layers and correctly measure the cost functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IPeytNb54NeV"
   },
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "lstm_model.save(r'..\\data\\lstm_model_hyper' + \".h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ChbcY1QAhw6t"
   },
   "source": [
    "<b>In the above line, we saved the LSTM model in the path, so that we can use in future to make the predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k7M2h047h23U"
   },
   "source": [
    "## Twitter Data\n",
    "\n",
    "As we mentioned that we will be testing the model for the Coronavirus data scraped from twitter through developer twitter API call.\n",
    "\n",
    "We will be focusing on the tweets which contain 'Coronavirus' hashtags and extract them using the twitter API call.<br><br>\n",
    "Once this is done we create a dataframe using these tweets and then we use the LSTM model to predict the class of the tweet.\n",
    "We save the prediction in a csv file.\n",
    "\n",
    "##### Importing necessary libraries for twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NNdlVaHuh4X2"
   },
   "outputs": [],
   "source": [
    "import tweepy as tw\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>The Security tokens used will be different for different user, so we are hashing the tokens for security purpose\n",
    "\n",
    "When running the notebook please use your respective tokens generated from the twitter developer account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F6w_Xg9xsAEG"
   },
   "outputs": [],
   "source": [
    "API_key =  \"XXXX\"\n",
    "API_secret_key =\"XXXX\"\n",
    "Access_token=\"XXXX\"\n",
    "Access_token_secret=\"XXXX\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "22fcbwjYulGj",
    "outputId": "0edc23d9-30bc-4629-ae80-fa235b74cd2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentication OK\n"
     ]
    }
   ],
   "source": [
    "auth = tw.OAuthHandler(API_key, API_secret_key)\n",
    "auth.set_access_token(Access_token,Access_token_secret)\n",
    "api = tw.API(auth)\n",
    "# test authentication\n",
    "try:\n",
    "    api.verify_credentials()\n",
    "    print(\"Authentication OK\")\n",
    "except:\n",
    "    print(\"Error during authentication\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z2NW8X1ew36Z"
   },
   "outputs": [],
   "source": [
    "api = tw.API(auth, wait_on_rate_limit = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Extracting tweets containing the 'coronavirus' hashtags in them and date range will be from the given date to the present date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TQw05nIPxXij"
   },
   "outputs": [],
   "source": [
    "search_word = \"coronavirus\"\n",
    "date_since = \"2020-04-10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sgC84tXbxjJC"
   },
   "outputs": [],
   "source": [
    "tweets = tw.Cursor(api.search,q=search_word, lang = 'en', since = date_since).items(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "colab_type": "code",
    "id": "Bn2qoq5exw9J",
    "outputId": "f5a15fbc-e90a-4247-db6a-5255ddee18ea"
   },
   "outputs": [],
   "source": [
    "tweet_details = [[tweet.geo, tweet.text, tweet.user.location] for tweet in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "feNUYtpix05c",
    "outputId": "a0b5a83e-3085-42cf-8d25-5e7e2d3f4afb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo</th>\n",
       "      <th>text</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>No intimate scenes after Coronavirus, says a m...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>RT @sadhavi: Govt should allow Bajaj to open h...</td>\n",
       "      <td>New delhi Mumbai via VARANASI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>His story before the end , read only here by @...</td>\n",
       "      <td>ahmedabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>RT @NPR: NEW: Based on the preliminary results...</td>\n",
       "      <td>In My Own World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>RT @maggieNYT: \"Mark Meadows, Mr. Trump’s new ...</td>\n",
       "      <td>Seattle Washington</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    geo  ...                        location\n",
       "0  None  ...                                \n",
       "1  None  ...  New delhi Mumbai via VARANASI \n",
       "2  None  ...                       ahmedabad\n",
       "3  None  ...                 In My Own World\n",
       "4  None  ...              Seattle Washington\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df = pd.DataFrame(data = tweet_details, columns = ['geo','text','location'])\n",
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "P_BpgFIaKLBY",
    "outputId": "8ada22a6-f32a-4422-93fb-f7e6dec1a171"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3)"
      ]
     },
     "execution_count": 91,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Performing the cleaning, tokenizing and nlp operations on the tweet dataset as well "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ljH8BqCtyRHN"
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(\"RT @[\\w]*:\",\"\",text)\n",
    "    text = re.sub(\"@[\\w]*:\",\"\",text)\n",
    "    text = re.sub(\"https?://[A-Za-z0-9./]*\",\"\",text)\n",
    "    text = re.sub(\"\\n\",\"\",text)\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f7mjWENny0kH"
   },
   "outputs": [],
   "source": [
    "tweet_df['text'] = tweet_df['text'].apply(lambda x :clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "x49MZhJezcm9",
    "outputId": "96b5abc0-c05e-41da-f224-1bb620716be4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo</th>\n",
       "      <th>text</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>Many are saying the economy won t comeback un...</td>\n",
       "      <td>The Great Northwest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>We ve raised            Now it s time for the...</td>\n",
       "      <td>Michigan, USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>Journalists and Dissidents Arrested in Corona...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>PoisonedMarine No  but deaths from other dis...</td>\n",
       "      <td>Pingpong, Korea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>Speaking of early action   Kentucky s Democra...</td>\n",
       "      <td>Burque</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    geo                                               text             location\n",
       "0  None   Many are saying the economy won t comeback un...  The Great Northwest\n",
       "1  None   We ve raised            Now it s time for the...        Michigan, USA\n",
       "2  None   Journalists and Dissidents Arrested in Corona...                     \n",
       "3  None    PoisonedMarine No  but deaths from other dis...      Pingpong, Korea\n",
       "4  None   Speaking of early action   Kentucky s Democra...              Burque "
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uUNSJ4mCznL5"
   },
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(texts = tweet_df['text'])\n",
    "test_text = tokenizer.texts_to_sequences(texts = tweet_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jMwH55LT1Zvr"
   },
   "outputs": [],
   "source": [
    "test_text = pad_sequences(sequences = test_text, maxlen = max_features, padding = 'pre')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Importing the tensorflow library and getting the pickled model to predict the class of the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uaiZWOxX1g_i",
    "outputId": "6119477f-541b-453f-b644-7dc6ce1892eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer 2nd_layer will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf \n",
    "model = tf.keras.models.load_model('..\\data\\lstm_model_hyper.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Predicting Class of the tweets and creating a dataframe with the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "4q-kDBGK1oSL",
    "outputId": "28f982db-1934-4061-d736-c78dd297d0b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-61-708187e85a40>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict_classes(test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Saving the predicted dataframe in the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-rIZWU6q2ioM"
   },
   "outputs": [],
   "source": [
    "Prediction_df = pd.DataFrame({'text':tweet_df.text ,'label':pred})\n",
    "Prediction_df.to_csv(r'..\\Data\\prediction.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GiyAFS-w2oLZ"
   },
   "source": [
    "<b>Our LSTM model took hours to execute and was expensive based on the system performance. Hence, we started exploring other possible options through which we wouldn’t have to compromise on the accuracy of the model but at the same time go easy on the system. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TRrzCxFdVRw6"
   },
   "source": [
    "## Auto- ML -----> H2O\n",
    "\n",
    "H2O was the first thing that occured to our mind. “The goal of H2O is to allow simple horizontal scaling to a given problem in order to produce a solution faster.”- H2O Documentation<br><br>\n",
    "We executed our models using H2O as it is a tool for rapidly turning over models, doing data munging, and building applications in a fast and scalable environment. \n",
    "<br><br>\n",
    "\n",
    "To make h2o run in the system we need to install few dependent java packages and then do a <b>!pip install H2O\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "colab_type": "code",
    "id": "pEQti_KAVT3G",
    "outputId": "ee8d01ff-ec5c-4af9-95d1-6c0c3fcaa101",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "default-jre is already the newest version (2:1.11-68ubuntu1~18.04.1).\n",
      "default-jre set to manually installed.\n",
      "0 upgraded, 0 newly installed, 0 to remove and 25 not upgraded.\n",
      "openjdk version \"11.0.6\" 2020-01-14\n",
      "OpenJDK Runtime Environment (build 11.0.6+10-post-Ubuntu-1ubuntu118.04.1)\n",
      "OpenJDK 64-Bit Server VM (build 11.0.6+10-post-Ubuntu-1ubuntu118.04.1, mixed mode, sharing)\n",
      "Collecting h2o\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/b2/b6f5e8c7fd1efe0f6d2640b34164b10b0e28231b89cc06542a6b3a3903a0/h2o-3.30.0.1.tar.gz (129.5MB)\n",
      "\u001b[K     |████████████████████████████████| 129.5MB 91kB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from h2o) (2.21.0)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from h2o) (0.8.7)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from h2o) (0.16.0)\n",
      "Collecting colorama>=0.3.8\n",
      "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->h2o) (2.8)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->h2o) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->h2o) (2020.4.5.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->h2o) (3.0.4)\n",
      "Building wheels for collected packages: h2o\n",
      "  Building wheel for h2o (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for h2o: filename=h2o-3.30.0.1-py2.py3-none-any.whl size=129557718 sha256=34e39fca37aef1324d557a4c991dff5bfcb845e675ce84e32b7bb9a2828844b0\n",
      "  Stored in directory: /root/.cache/pip/wheels/db/42/63/d118d7218432054da842f5d10bd4f99e978bde0931164e6c7a\n",
      "Successfully built h2o\n",
      "Installing collected packages: colorama, h2o\n",
      "Successfully installed colorama-0.4.3 h2o-3.30.0.1\n"
     ]
    }
   ],
   "source": [
    "! apt-get install default-jre\n",
    "!java -version\n",
    "! pip install h2o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>The H2O dataframe consists of tweets that we extracted from twitter containing the word=’coronavirus’ in it. <br><br>\n",
    "Validated tweets have been marked as “0”.ie. Real and the ones that are not validated have been marked as “1”.ie. Fake.<br><br>\n",
    "We perform NLP actions on the tweet to get rid of stopwords, tokenizing,extra spaces etc. We also convert the words to vectors using “word2vec” to to understand on how it affects the model’s performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m8datjxUWFSp"
   },
   "outputs": [],
   "source": [
    "# final_dataset = pd.read_csv(r'/content/drive/My Drive/Colab Notebooks/final_dataset.csv')\n",
    "df = final_dataset\n",
    "def print_plot(index):\n",
    "    example = df[df.index == index][['text', 'label']].values[0]\n",
    "    if len(example) > 0:\n",
    "        print(example[0])\n",
    "        print('Label:', example[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "SVf3u_VsWN63",
    "outputId": "19ab8fa5-1481-4df3-fa86-c81a624d489c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By Patrick Wood By its very nature, the Internet Corporation for Assigned Names and Numbers (ICANN) is a non-profit organization exclusively run by Technocrats. As...\n",
      "Label: 1\n"
     ]
    }
   ],
   "source": [
    "print_plot(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Buc15dXKZMS-"
   },
   "outputs": [],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text. substitute the matched string in REPLACE_BY_SPACE_RE with space.\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # remove symbols which are in BAD_SYMBOLS_RE from text. substitute the matched string in BAD_SYMBOLS_RE with nothing. \n",
    "    text = text.replace('x', '')\n",
    "#    text = re.sub(r'\\W+', '', text)\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # remove stopwors from text\n",
    "    return text\n",
    "df['text'] = df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IB5hBu_naIa7"
   },
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.replace('\\d+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A_G0nTOXWVQS"
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(\"RT @[\\w]*:\",\"\",text)\n",
    "    text = re.sub(\"@[\\w]*:\",\"\",text)\n",
    "    text = re.sub(\"https?://[A-Za-z0-9./]*\",\"\",text)\n",
    "    text = re.sub(\"\\n\",\"\",text)\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qOQAmPXbW2LJ"
   },
   "outputs": [],
   "source": [
    "final_dataset['text'] = final_dataset['text'].apply(lambda x :clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "Z66QyGZaYOSZ",
    "outputId": "cd11fc8c-c060-4d7b-b8ae-3dd74644df13"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Trump arrives in the Oval Office these days ...</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>My statement on tonight s vote on the supplem...</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>October Boomerang     David Swanson is an auth...</td>\n",
       "      <td>1</td>\n",
       "      <td>8025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Trump at his Whitehouse briefing offered a da...</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Think the world is your oyster  Think again  F...</td>\n",
       "      <td>1</td>\n",
       "      <td>4707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  label  length\n",
       "0           0    Trump arrives in the Oval Office these days ...      0     140\n",
       "1           1   My statement on tonight s vote on the supplem...      0     120\n",
       "2           2  October Boomerang     David Swanson is an auth...      1    8025\n",
       "3           3   Trump at his Whitehouse briefing offered a da...      0     140\n",
       "4           4  Think the world is your oyster  Think again  F...      1    4707"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "0JLnP5wJZwqV",
    "outputId": "8a3fa3d7-650f-44f9-f404-3c2f75c7cac5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>house dem aide didnt even see comeys letter ja...</td>\n",
       "      <td>4930</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ever get feeling life circles roundabout rathe...</td>\n",
       "      <td>4160</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>truth might get fired october   tension intell...</td>\n",
       "      <td>7692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>videos  civilians killed single us airstrike i...</td>\n",
       "      <td>3237</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>print iranian woman sentenced si years prison ...</td>\n",
       "      <td>938</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  length  label\n",
       "0  house dem aide didnt even see comeys letter ja...    4930      1\n",
       "1  ever get feeling life circles roundabout rathe...    4160      0\n",
       "2  truth might get fired october   tension intell...    7692      1\n",
       "3  videos  civilians killed single us airstrike i...    3237      1\n",
       "4  print iranian woman sentenced si years prison ...     938      1"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df= final_dataset.copy()\n",
    "final_dataset_v1 = df[['text','length','label']]\n",
    "final_dataset_v1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "ACcpVWbVcLTT",
    "outputId": "b0653688-0ef1-414b-aaba-7a0a4d95d1f8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text      0\n",
       "length    0\n",
       "label     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataset_v1.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importing necessary H2o and other libraries for the next operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-GaLygtonJM9"
   },
   "outputs": [],
   "source": [
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "import optparse\n",
    "import time\n",
    "import json\n",
    "from distutils.util import strtobool\n",
    "import psutil\n",
    "import random, os, sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>We are initializing virtual memory to the core so that the H2O utilises those memory to run any algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Z0MMfbboauWZ",
    "outputId": "b8c70217-3886-4931-c3e8-21c2eecff79d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "pct_memory=0.5\n",
    "virtual_memory=psutil.virtual_memory()\n",
    "min_mem_size=int(round(int(pct_memory*virtual_memory.available)/1073741824,0))\n",
    "print(min_mem_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 510
    },
    "colab_type": "code",
    "id": "5ERZWrRDawez",
    "outputId": "62306fc6-c22c-4f02-abf2-54f4f2546f0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:14984 ..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: openjdk version \"11.0.6\" 2020-01-14; OpenJDK Runtime Environment (build 11.0.6+10-post-Ubuntu-1ubuntu118.04.1); OpenJDK 64-Bit Server VM (build 11.0.6+10-post-Ubuntu-1ubuntu118.04.1, mixed mode, sharing)\n",
      "  Starting server from /usr/local/lib/python3.6/dist-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /tmp/tmp3o8pf1xs\n",
      "  JVM stdout: /tmp/tmp3o8pf1xs/h2o_unknownUser_started_from_python.out\n",
      "  JVM stderr: /tmp/tmp3o8pf1xs/h2o_unknownUser_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:14984\n",
      "Connecting to H2O server at http://127.0.0.1:14984 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>02 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Etc/UTC</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.30.0.1</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>20 days </td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_unknownUser_qo2qor</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>6 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>2</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>2</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:14984</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O_API_Extensions:</td>\n",
       "<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.6.9 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ------------------------------------------------------------------\n",
       "H2O_cluster_uptime:         02 secs\n",
       "H2O_cluster_timezone:       Etc/UTC\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.30.0.1\n",
       "H2O_cluster_version_age:    20 days\n",
       "H2O_cluster_name:           H2O_from_python_unknownUser_qo2qor\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    6 Gb\n",
       "H2O_cluster_total_cores:    2\n",
       "H2O_cluster_allowed_cores:  2\n",
       "H2O_cluster_status:         accepting new members, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:14984\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "H2O_API_Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4\n",
       "Python_version:             3.6.9 final\n",
       "--------------------------  ------------------------------------------------------------------"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "port_no=random.randint(5555,55555)\n",
    "h2o.init(strict_version_check=False,min_mem_size_GB=min_mem_size,port=port_no) # start h2o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> After cleaning the data we convert the dataframe into H2O frame for H2O models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XC-la1xNa4Ws",
    "outputId": "75f8b2fa-58d2-433e-8d24-aa7665f114e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "df_h2o = h2o.H2OFrame(final_dataset_v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 78
    },
    "colab_type": "code",
    "id": "0BD76jAvbAn4",
    "outputId": "843cb950-2f7c-4cde-b9ee-073ee287d06d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  label</th><th style=\"text-align: right;\">  Count</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">  26008</td></tr>\n",
       "<tr><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">  13593</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_h2o['label'].table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qr5PNSpFhvs4"
   },
   "outputs": [],
   "source": [
    "df_h2o['label']=df_h2o['label'].asnumeric()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>As it is a binary classification algorithm so the target variable needs to be 0 or 1, so we are converting the 'Real' to 0 and 'Fake' to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7q5sxrRGhxA8"
   },
   "outputs": [],
   "source": [
    "df_h2o[\"label\"] = (df_h2o[\"label\"] == 1).ifelse(\"1\", \"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_Mrx5G-WhycL",
    "outputId": "ef6987cf-6bea-4163-955c-9b15e561e2d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39601, 3)"
      ]
     },
     "execution_count": 60,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_h2o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5yes34-ohzoQ",
    "outputId": "0628a396-b0db-448e-b31f-80eb2d205343"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "aml_1 = H2OAutoML(max_models = 10, seed = 1)\n",
    "aml_1.train( y = 'label', training_frame = df_h2o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qF_GKFH2h2PG"
   },
   "outputs": [],
   "source": [
    "# Find the 80th quantile of time in the dataset\n",
    "len_split = df_h2o[\"length\"].quantile(prob = [0.8])[1]\n",
    "df_h2o[\"Train\"] = (df_h2o[\"length\"] < len_split).ifelse(\"Yes\", \"No\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Splitting the dataset into test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oCigkpOih4_F"
   },
   "outputs": [],
   "source": [
    "train = df_h2o[df_h2o[\"Train\"] == \"Yes\"]\n",
    "test = df_h2o[df_h2o[\"Train\"] == \"No\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>\n",
    "After cleaning the dataframe we pass it to the H2OGradientBoostingEstimator algorithm and train it. We also change the hyperparameter values to check how it affects the model’s performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1O_sBA8sh9Hg",
    "outputId": "90dfead5-2f69-449f-8699-7ce23d3b4761"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "from h2o.estimators import H2OGradientBoostingEstimator\n",
    "\n",
    "predictors = ['text','length']\n",
    "response = 'label'\n",
    "\n",
    "gbm_baseline = H2OGradientBoostingEstimator(stopping_metric = \"AUC\", stopping_tolerance = 0.001, \n",
    "                                            score_tree_interval = 10, model_id = \"gbm_baseline.hex\")\n",
    "\n",
    "\n",
    "gbm_baseline.train(x = predictors, y = response, \n",
    "                   training_frame = train, validation_frame = test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of the Model\n",
    "The H20 has a function called model_performance which is used to test the performance of the model.\n",
    "Different metrics can be used to calculate the performance\n",
    "1. AUC score - 0.5\n",
    "2. Mean Per-Class Error: 0.5\n",
    "3. RMSE: 0.45 etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "xKJO5rCOiCBC",
    "outputId": "c916bbde-f399-4668-94ba-40d6f4ee59df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.2091282310026076\n",
      "RMSE: 0.4573054023326289\n",
      "LogLoss: 0.6175758898574257\n",
      "Mean Per-Class Error: 0.5\n",
      "AUC: 0.5\n",
      "AUCPR: 0.2755269468635618\n",
      "Gini: 0.0\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.17797499871796357: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5740.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(5740.0/5740.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2183.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0.0/2183.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7923.0</td>\n",
       "      <td>0.7245</td>\n",
       "      <td>(5740.0/7923.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       1   Error              Rate\n",
       "0      0  0.0  5740.0     1.0   (5740.0/5740.0)\n",
       "1      1  0.0  2183.0     0.0      (0.0/2183.0)\n",
       "2  Total  0.0  7923.0  0.7245   (5740.0/7923.0)"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.177975</td>\n",
       "      <td>0.432021</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.177975</td>\n",
       "      <td>0.655359</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.177975</td>\n",
       "      <td>0.322214</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.177975</td>\n",
       "      <td>0.275527</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.177975</td>\n",
       "      <td>0.275527</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.177975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.177975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.177975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.177975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.177975</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.177975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.177975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.177975</td>\n",
       "      <td>5740.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.177975</td>\n",
       "      <td>2183.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.177975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.177975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.177975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.177975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold        value  idx\n",
       "0                        max f1   0.177975     0.432021  0.0\n",
       "1                        max f2   0.177975     0.655359  0.0\n",
       "2                  max f0point5   0.177975     0.322214  0.0\n",
       "3                  max accuracy   0.177975     0.275527  0.0\n",
       "4                 max precision   0.177975     0.275527  0.0\n",
       "5                    max recall   0.177975     1.000000  0.0\n",
       "6               max specificity   0.177975     0.000000  0.0\n",
       "7              max absolute_mcc   0.177975     0.000000  0.0\n",
       "8    max min_per_class_accuracy   0.177975     0.000000  0.0\n",
       "9   max mean_per_class_accuracy   0.177975     0.500000  0.0\n",
       "10                      max tns   0.177975     0.000000  0.0\n",
       "11                      max fns   0.177975     0.000000  0.0\n",
       "12                      max fps   0.177975  5740.000000  0.0\n",
       "13                      max tps   0.177975  2183.000000  0.0\n",
       "14                      max tnr   0.177975     0.000000  0.0\n",
       "15                      max fnr   0.177975     0.000000  0.0\n",
       "16                      max fpr   0.177975     1.000000  0.0\n",
       "17                      max tpr   0.177975     1.000000  0.0"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 27.55 %, avg score: 17.80 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.177975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.275527</td>\n",
       "      <td>0.177975</td>\n",
       "      <td>0.275527</td>\n",
       "      <td>0.177975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     group  ...  gain  cumulative_gain\n",
       "0        1  ...   0.0              0.0\n",
       "\n",
       "[1 rows x 14 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 65,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf1 = gbm_baseline.model_performance(test)\n",
    "perf1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Plotting the variable importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "colab_type": "code",
    "id": "9CVwT2JWiFkm",
    "outputId": "e2b164cb-9807-45d0-886e-fecba4402725"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gbm_baseline.varimp_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweak the text data\n",
    "The accuracy was not as expected. So before proceeding for any hyper parameters tuning we want to do some natural language processing, so that the training text is free of all the unwanted characters and are tokenized with natural language techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mLE1oFnTiMWJ"
   },
   "source": [
    "### Tokenize Words in Review¶\n",
    "Our first step will be to tokenize the words in the review column. We will do this by creating a function called tokenize. This will split the reviews into words and remove any stop words, small words, or words with numbers in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PIV2TDO9iHhr"
   },
   "outputs": [],
   "source": [
    "def tokenize(sentences, stop_word = STOPWORDS):\n",
    "    tokenized = sentences.tokenize(\"\\\\W+\")\n",
    "    tokenized_lower = tokenized.tolower()\n",
    "    tokenized_filtered = tokenized_lower[(tokenized_lower.nchar() >= 2) | (tokenized_lower.isna()),:]\n",
    "    tokenized_words = tokenized_filtered[tokenized_filtered.grep(\"[0-9]\",invert=True,output_logical=True),:]\n",
    "    tokenized_words = tokenized_words[(tokenized_words.isna()) | (~ tokenized_words.isin(STOPWORDS)),:]\n",
    "    return tokenized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "VX56CiuliOru",
    "outputId": "2b0101ef-749a-432f-edda-26e31d0c5ec2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>C1      </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>house   </td></tr>\n",
       "<tr><td>dem     </td></tr>\n",
       "<tr><td>aide    </td></tr>\n",
       "<tr><td>didnt   </td></tr>\n",
       "<tr><td>even    </td></tr>\n",
       "<tr><td>see     </td></tr>\n",
       "<tr><td>comeys  </td></tr>\n",
       "<tr><td>letter  </td></tr>\n",
       "<tr><td>jason   </td></tr>\n",
       "<tr><td>chaffetz</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 68,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = tokenize(df_h2o[\"text\"])\n",
    "words.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZsqJYKVJiZip"
   },
   "source": [
    "### Train Word2Vec Model\n",
    "Now that we've tokenized our words, we can train a <b>word2vec</b> model. We can use the find_synonms function to sanity check our word2vec model after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YPIAjblQiWh6",
    "outputId": "b22ee42e-7356-4025-e55f-ac121f8b6e70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word2vec Model Build progress: |██████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "from h2o.estimators.word2vec import H2OWord2vecEstimator\n",
    "\n",
    "\n",
    "w2v_model = H2OWord2vecEstimator(vec_size = 100, model_id = \"w2v.hex\")\n",
    "w2v_model.train(training_frame=words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "_rYcsqZNid-4",
    "outputId": "a12d4693-a8c8-4301-b238-8954dd35ba85"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('white', 0.7265527844429016),\n",
       "             ('housethe', 0.655886173248291),\n",
       "             ('vonlembke', 0.6401231288909912),\n",
       "             ('houses', 0.6194923520088196),\n",
       "             ('thenwhite', 0.6031650900840759)])"
      ]
     },
     "execution_count": 70,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.find_synonyms(\"house\", count = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eE_FDpD7iyOP"
   },
   "source": [
    "Now that we have a word embedding for each word in our vocabulary, we will aggregate the words for each review using the transform function. This will give us one aggregated word embedding for each review.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AJeOgLlVivnP"
   },
   "outputs": [],
   "source": [
    "# Calculate a vector for each review\n",
    "df_h2o_vecs = w2v_model.transform(words, aggregate_method = \"AVERAGE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "colab_type": "code",
    "id": "gD6H_ff9i21n",
    "outputId": "716b319e-65eb-4857-cd8e-d9799d75bbec"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">       C1</th><th style=\"text-align: right;\">        C2</th><th style=\"text-align: right;\">        C3</th><th style=\"text-align: right;\">         C4</th><th style=\"text-align: right;\">        C5</th><th style=\"text-align: right;\">        C6</th><th style=\"text-align: right;\">         C7</th><th style=\"text-align: right;\">         C8</th><th style=\"text-align: right;\">       C9</th><th style=\"text-align: right;\">        C10</th><th style=\"text-align: right;\">       C11</th><th style=\"text-align: right;\">         C12</th><th style=\"text-align: right;\">        C13</th><th style=\"text-align: right;\">        C14</th><th style=\"text-align: right;\">      C15</th><th style=\"text-align: right;\">        C16</th><th style=\"text-align: right;\">       C17</th><th style=\"text-align: right;\">       C18</th><th style=\"text-align: right;\">        C19</th><th style=\"text-align: right;\">      C20</th><th style=\"text-align: right;\">       C21</th><th style=\"text-align: right;\">        C22</th><th style=\"text-align: right;\">        C23</th><th style=\"text-align: right;\">        C24</th><th style=\"text-align: right;\">       C25</th><th style=\"text-align: right;\">        C26</th><th style=\"text-align: right;\">        C27</th><th style=\"text-align: right;\">       C28</th><th style=\"text-align: right;\">        C29</th><th style=\"text-align: right;\">       C30</th><th style=\"text-align: right;\">        C31</th><th style=\"text-align: right;\">      C32</th><th style=\"text-align: right;\">      C33</th><th style=\"text-align: right;\">       C34</th><th style=\"text-align: right;\">       C35</th><th style=\"text-align: right;\">        C36</th><th style=\"text-align: right;\">        C37</th><th style=\"text-align: right;\">       C38</th><th style=\"text-align: right;\">        C39</th><th style=\"text-align: right;\">        C40</th><th style=\"text-align: right;\">        C41</th><th style=\"text-align: right;\">       C42</th><th style=\"text-align: right;\">       C43</th><th style=\"text-align: right;\">       C44</th><th style=\"text-align: right;\">      C45</th><th style=\"text-align: right;\">        C46</th><th style=\"text-align: right;\">       C47</th><th style=\"text-align: right;\">      C48</th><th style=\"text-align: right;\">       C49</th><th style=\"text-align: right;\">       C50</th><th style=\"text-align: right;\">       C51</th><th style=\"text-align: right;\">      C52</th><th style=\"text-align: right;\">       C53</th><th style=\"text-align: right;\">       C54</th><th style=\"text-align: right;\">      C55</th><th style=\"text-align: right;\">         C56</th><th style=\"text-align: right;\">        C57</th><th style=\"text-align: right;\">      C58</th><th style=\"text-align: right;\">       C59</th><th style=\"text-align: right;\">       C60</th><th style=\"text-align: right;\">      C61</th><th style=\"text-align: right;\">      C62</th><th style=\"text-align: right;\">        C63</th><th style=\"text-align: right;\">       C64</th><th style=\"text-align: right;\">       C65</th><th style=\"text-align: right;\">        C66</th><th style=\"text-align: right;\">      C67</th><th style=\"text-align: right;\">      C68</th><th style=\"text-align: right;\">     C69</th><th style=\"text-align: right;\">        C70</th><th style=\"text-align: right;\">        C71</th><th style=\"text-align: right;\">       C72</th><th style=\"text-align: right;\">      C73</th><th style=\"text-align: right;\">       C74</th><th style=\"text-align: right;\">       C75</th><th style=\"text-align: right;\">        C76</th><th style=\"text-align: right;\">        C77</th><th style=\"text-align: right;\">         C78</th><th style=\"text-align: right;\">      C79</th><th style=\"text-align: right;\">        C80</th><th style=\"text-align: right;\">       C81</th><th style=\"text-align: right;\">        C82</th><th style=\"text-align: right;\">       C83</th><th style=\"text-align: right;\">        C84</th><th style=\"text-align: right;\">       C85</th><th style=\"text-align: right;\">        C86</th><th style=\"text-align: right;\">       C87</th><th style=\"text-align: right;\">     C88</th><th style=\"text-align: right;\">      C89</th><th style=\"text-align: right;\">       C90</th><th style=\"text-align: right;\">        C91</th><th style=\"text-align: right;\">       C92</th><th style=\"text-align: right;\">        C93</th><th style=\"text-align: right;\">         C94</th><th style=\"text-align: right;\">         C95</th><th style=\"text-align: right;\">       C96</th><th style=\"text-align: right;\">        C97</th><th style=\"text-align: right;\">       C98</th><th style=\"text-align: right;\">        C99</th><th style=\"text-align: right;\">       C100</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">0.0703071</td><td style=\"text-align: right;\">0.044777  </td><td style=\"text-align: right;\">-0.0745844</td><td style=\"text-align: right;\"> 0.0305485 </td><td style=\"text-align: right;\">-0.0714426</td><td style=\"text-align: right;\">-0.0981024</td><td style=\"text-align: right;\">-0.0668217 </td><td style=\"text-align: right;\">-0.0922481 </td><td style=\"text-align: right;\">0.189481 </td><td style=\"text-align: right;\">-0.0495971 </td><td style=\"text-align: right;\"> 0.0948435</td><td style=\"text-align: right;\">-0.0355881  </td><td style=\"text-align: right;\"> 0.0826718 </td><td style=\"text-align: right;\"> 0.0485628 </td><td style=\"text-align: right;\">0.0532505</td><td style=\"text-align: right;\"> 0.139157  </td><td style=\"text-align: right;\">-0.0050665</td><td style=\"text-align: right;\">-0.139091 </td><td style=\"text-align: right;\">-0.00210109</td><td style=\"text-align: right;\">0.0779076</td><td style=\"text-align: right;\">-0.0712074</td><td style=\"text-align: right;\"> 0.0617141 </td><td style=\"text-align: right;\">-0.138916  </td><td style=\"text-align: right;\">-0.0261456 </td><td style=\"text-align: right;\">-0.0184741</td><td style=\"text-align: right;\">-0.0440677 </td><td style=\"text-align: right;\"> 0.0347119 </td><td style=\"text-align: right;\">-0.0448847</td><td style=\"text-align: right;\"> 0.0770162 </td><td style=\"text-align: right;\"> 0.120964 </td><td style=\"text-align: right;\">-0.024981  </td><td style=\"text-align: right;\">0.202617 </td><td style=\"text-align: right;\">0.152761 </td><td style=\"text-align: right;\"> 0.0296153</td><td style=\"text-align: right;\">-0.117787 </td><td style=\"text-align: right;\">-0.00813665</td><td style=\"text-align: right;\"> 0.0564274 </td><td style=\"text-align: right;\">-0.132813 </td><td style=\"text-align: right;\">-0.16575   </td><td style=\"text-align: right;\"> 0.0650866 </td><td style=\"text-align: right;\">-0.0174824 </td><td style=\"text-align: right;\">-0.113845 </td><td style=\"text-align: right;\">-0.0788568</td><td style=\"text-align: right;\">-0.0835391</td><td style=\"text-align: right;\">-0.328269</td><td style=\"text-align: right;\"> 0.0877159 </td><td style=\"text-align: right;\">-0.116371 </td><td style=\"text-align: right;\">0.131089 </td><td style=\"text-align: right;\">-0.0295988</td><td style=\"text-align: right;\">0.195982  </td><td style=\"text-align: right;\">-0.016535 </td><td style=\"text-align: right;\">0.139804 </td><td style=\"text-align: right;\">-0.0532536</td><td style=\"text-align: right;\">-0.0241282</td><td style=\"text-align: right;\">0.189794 </td><td style=\"text-align: right;\">-0.0185551  </td><td style=\"text-align: right;\">-0.00742787</td><td style=\"text-align: right;\">0.165249 </td><td style=\"text-align: right;\">-0.027361 </td><td style=\"text-align: right;\">-0.0198818</td><td style=\"text-align: right;\">0.099034 </td><td style=\"text-align: right;\">0.0404699</td><td style=\"text-align: right;\"> 0.00688874</td><td style=\"text-align: right;\">-0.137087 </td><td style=\"text-align: right;\">-0.124502 </td><td style=\"text-align: right;\"> 0.0224432 </td><td style=\"text-align: right;\">-0.363474</td><td style=\"text-align: right;\">0.102551 </td><td style=\"text-align: right;\">0.146499</td><td style=\"text-align: right;\">-0.12202   </td><td style=\"text-align: right;\">-0.0480035 </td><td style=\"text-align: right;\"> 0.0773919</td><td style=\"text-align: right;\">0.148364 </td><td style=\"text-align: right;\">-0.0421362</td><td style=\"text-align: right;\"> 0.0866486</td><td style=\"text-align: right;\"> 0.00427574</td><td style=\"text-align: right;\"> 0.106636  </td><td style=\"text-align: right;\"> 0.0226183  </td><td style=\"text-align: right;\">0.0528583</td><td style=\"text-align: right;\"> 0.143597  </td><td style=\"text-align: right;\">0.0294002 </td><td style=\"text-align: right;\"> 0.141723  </td><td style=\"text-align: right;\">-0.0581948</td><td style=\"text-align: right;\"> 0.105443  </td><td style=\"text-align: right;\"> 0.0988548</td><td style=\"text-align: right;\"> 0.0837716 </td><td style=\"text-align: right;\"> 0.0406259</td><td style=\"text-align: right;\">0.10223 </td><td style=\"text-align: right;\">0.163312 </td><td style=\"text-align: right;\">0.0249875 </td><td style=\"text-align: right;\">-0.0490668 </td><td style=\"text-align: right;\">-0.160404 </td><td style=\"text-align: right;\">0.000376033</td><td style=\"text-align: right;\">-0.00241394 </td><td style=\"text-align: right;\">-0.0140605  </td><td style=\"text-align: right;\">-0.0713743</td><td style=\"text-align: right;\">-0.0736477 </td><td style=\"text-align: right;\"> 0.0455272</td><td style=\"text-align: right;\">-0.0118661 </td><td style=\"text-align: right;\"> 0.0694605 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">0.109073 </td><td style=\"text-align: right;\">0.0347617 </td><td style=\"text-align: right;\">-0.0176976</td><td style=\"text-align: right;\"> 0.035371  </td><td style=\"text-align: right;\">-0.143572 </td><td style=\"text-align: right;\">-0.156925 </td><td style=\"text-align: right;\"> 0.00388384</td><td style=\"text-align: right;\">-0.0403038 </td><td style=\"text-align: right;\">0.147022 </td><td style=\"text-align: right;\">-0.00674731</td><td style=\"text-align: right;\"> 0.0485051</td><td style=\"text-align: right;\">-0.0600834  </td><td style=\"text-align: right;\"> 0.0173726 </td><td style=\"text-align: right;\">-0.0275589 </td><td style=\"text-align: right;\">0.0754702</td><td style=\"text-align: right;\"> 0.0412573 </td><td style=\"text-align: right;\"> 0.0173652</td><td style=\"text-align: right;\">-0.144251 </td><td style=\"text-align: right;\">-0.0412624 </td><td style=\"text-align: right;\">0.133851 </td><td style=\"text-align: right;\">-0.060218 </td><td style=\"text-align: right;\">-0.0301663 </td><td style=\"text-align: right;\"> 0.0318856 </td><td style=\"text-align: right;\">-0.074363  </td><td style=\"text-align: right;\"> 0.0609279</td><td style=\"text-align: right;\">-0.00306648</td><td style=\"text-align: right;\"> 0.0129788 </td><td style=\"text-align: right;\">-0.0227707</td><td style=\"text-align: right;\"> 0.0829593 </td><td style=\"text-align: right;\"> 0.0422986</td><td style=\"text-align: right;\"> 0.0186487 </td><td style=\"text-align: right;\">0.104267 </td><td style=\"text-align: right;\">0.12092  </td><td style=\"text-align: right;\">-0.0873926</td><td style=\"text-align: right;\">-0.141548 </td><td style=\"text-align: right;\">-0.00328362</td><td style=\"text-align: right;\"> 0.0157961 </td><td style=\"text-align: right;\">-0.0397229</td><td style=\"text-align: right;\">-0.0991677 </td><td style=\"text-align: right;\"> 0.0386402 </td><td style=\"text-align: right;\">-0.00670316</td><td style=\"text-align: right;\">-0.0693524</td><td style=\"text-align: right;\">-0.0286269</td><td style=\"text-align: right;\">-0.109167 </td><td style=\"text-align: right;\">-0.237553</td><td style=\"text-align: right;\">-0.0141683 </td><td style=\"text-align: right;\">-0.122054 </td><td style=\"text-align: right;\">0.0833287</td><td style=\"text-align: right;\">-0.0918959</td><td style=\"text-align: right;\">0.0855024 </td><td style=\"text-align: right;\">-0.0422132</td><td style=\"text-align: right;\">0.155091 </td><td style=\"text-align: right;\">-0.0878637</td><td style=\"text-align: right;\">-0.0260142</td><td style=\"text-align: right;\">0.0735571</td><td style=\"text-align: right;\">-0.00926893 </td><td style=\"text-align: right;\"> 0.0697529 </td><td style=\"text-align: right;\">0.126181 </td><td style=\"text-align: right;\"> 0.0687119</td><td style=\"text-align: right;\"> 0.0252324</td><td style=\"text-align: right;\">0.0835484</td><td style=\"text-align: right;\">0.0776189</td><td style=\"text-align: right;\"> 0.0421968 </td><td style=\"text-align: right;\">-0.10959  </td><td style=\"text-align: right;\">-0.190098 </td><td style=\"text-align: right;\"> 0.00878984</td><td style=\"text-align: right;\">-0.324536</td><td style=\"text-align: right;\">0.0829912</td><td style=\"text-align: right;\">0.186082</td><td style=\"text-align: right;\">-0.108975  </td><td style=\"text-align: right;\">-0.0397635 </td><td style=\"text-align: right;\"> 0.117997 </td><td style=\"text-align: right;\">0.0849542</td><td style=\"text-align: right;\"> 0.0559813</td><td style=\"text-align: right;\">-0.0245813</td><td style=\"text-align: right;\">-0.0599224 </td><td style=\"text-align: right;\"> 0.0072714 </td><td style=\"text-align: right;\">-0.0449841  </td><td style=\"text-align: right;\">0.0869026</td><td style=\"text-align: right;\"> 0.06954   </td><td style=\"text-align: right;\">0.109112  </td><td style=\"text-align: right;\"> 0.0227134 </td><td style=\"text-align: right;\">-0.106694 </td><td style=\"text-align: right;\"> 0.0814946 </td><td style=\"text-align: right;\">-0.020519 </td><td style=\"text-align: right;\"> 0.0347646 </td><td style=\"text-align: right;\"> 0.0498255</td><td style=\"text-align: right;\">0.164636</td><td style=\"text-align: right;\">0.107957 </td><td style=\"text-align: right;\">0.0445038 </td><td style=\"text-align: right;\">-0.0336374 </td><td style=\"text-align: right;\">-0.0819368</td><td style=\"text-align: right;\">0.135835   </td><td style=\"text-align: right;\">-0.0409849  </td><td style=\"text-align: right;\"> 0.000411264</td><td style=\"text-align: right;\">-0.0210597</td><td style=\"text-align: right;\">-0.0160836 </td><td style=\"text-align: right;\">-0.078284 </td><td style=\"text-align: right;\">-0.00243734</td><td style=\"text-align: right;\"> 0.00792439</td></tr>\n",
       "<tr><td style=\"text-align: right;\">0.138116 </td><td style=\"text-align: right;\">0.0530768 </td><td style=\"text-align: right;\"> 0.0877199</td><td style=\"text-align: right;\"> 0.034359  </td><td style=\"text-align: right;\">-0.097176 </td><td style=\"text-align: right;\">-0.0930106</td><td style=\"text-align: right;\"> 0.0569569 </td><td style=\"text-align: right;\">-0.0350469 </td><td style=\"text-align: right;\">0.0526071</td><td style=\"text-align: right;\">-0.0423756 </td><td style=\"text-align: right;\"> 0.024427 </td><td style=\"text-align: right;\">-0.00938841 </td><td style=\"text-align: right;\"> 0.0299075 </td><td style=\"text-align: right;\">-0.026254  </td><td style=\"text-align: right;\">0.059352 </td><td style=\"text-align: right;\"> 0.0866797 </td><td style=\"text-align: right;\">-0.0365671</td><td style=\"text-align: right;\">-0.177813 </td><td style=\"text-align: right;\">-0.0206926 </td><td style=\"text-align: right;\">0.124255 </td><td style=\"text-align: right;\">-0.0519985</td><td style=\"text-align: right;\"> 0.0239268 </td><td style=\"text-align: right;\"> 0.0456558 </td><td style=\"text-align: right;\"> 0.0247828 </td><td style=\"text-align: right;\"> 0.0621522</td><td style=\"text-align: right;\"> 0.00857164</td><td style=\"text-align: right;\">-0.037271  </td><td style=\"text-align: right;\">-0.0657955</td><td style=\"text-align: right;\"> 0.0480458 </td><td style=\"text-align: right;\"> 0.0521874</td><td style=\"text-align: right;\">-0.00519286</td><td style=\"text-align: right;\">0.114496 </td><td style=\"text-align: right;\">0.115452 </td><td style=\"text-align: right;\">-0.0433055</td><td style=\"text-align: right;\">-0.169777 </td><td style=\"text-align: right;\">-0.0104326 </td><td style=\"text-align: right;\">-0.00018044</td><td style=\"text-align: right;\">-0.0889198</td><td style=\"text-align: right;\">-0.0276129 </td><td style=\"text-align: right;\"> 0.0388464 </td><td style=\"text-align: right;\">-0.0424781 </td><td style=\"text-align: right;\">-0.150432 </td><td style=\"text-align: right;\">-0.0782171</td><td style=\"text-align: right;\">-0.0869416</td><td style=\"text-align: right;\">-0.248163</td><td style=\"text-align: right;\"> 0.014713  </td><td style=\"text-align: right;\">-0.159347 </td><td style=\"text-align: right;\">0.130692 </td><td style=\"text-align: right;\"> 0.0406505</td><td style=\"text-align: right;\">0.0246996 </td><td style=\"text-align: right;\">-0.0691404</td><td style=\"text-align: right;\">0.0913118</td><td style=\"text-align: right;\">-0.0665464</td><td style=\"text-align: right;\">-0.0601894</td><td style=\"text-align: right;\">0.0182162</td><td style=\"text-align: right;\"> 0.00986615 </td><td style=\"text-align: right;\">-0.0088962 </td><td style=\"text-align: right;\">0.134284 </td><td style=\"text-align: right;\">-0.0137587</td><td style=\"text-align: right;\"> 0.0412996</td><td style=\"text-align: right;\">0.124655 </td><td style=\"text-align: right;\">0.0180188</td><td style=\"text-align: right;\"> 0.0255874 </td><td style=\"text-align: right;\">-0.125507 </td><td style=\"text-align: right;\">-0.16736  </td><td style=\"text-align: right;\">-0.0038951 </td><td style=\"text-align: right;\">-0.265155</td><td style=\"text-align: right;\">0.166488 </td><td style=\"text-align: right;\">0.258493</td><td style=\"text-align: right;\">-0.203472  </td><td style=\"text-align: right;\">-0.0711819 </td><td style=\"text-align: right;\"> 0.110503 </td><td style=\"text-align: right;\">0.15297  </td><td style=\"text-align: right;\"> 0.0336363</td><td style=\"text-align: right;\">-0.123054 </td><td style=\"text-align: right;\">-0.0463989 </td><td style=\"text-align: right;\"> 0.0668585 </td><td style=\"text-align: right;\">-0.0808554  </td><td style=\"text-align: right;\">0.104949 </td><td style=\"text-align: right;\">-0.00987748</td><td style=\"text-align: right;\">0.0518693 </td><td style=\"text-align: right;\">-0.00789385</td><td style=\"text-align: right;\">-0.108941 </td><td style=\"text-align: right;\"> 0.0162281 </td><td style=\"text-align: right;\">-0.0464501</td><td style=\"text-align: right;\"> 0.0715737 </td><td style=\"text-align: right;\"> 0.039608 </td><td style=\"text-align: right;\">0.142012</td><td style=\"text-align: right;\">0.0528186</td><td style=\"text-align: right;\">0.0636141 </td><td style=\"text-align: right;\">-0.0355842 </td><td style=\"text-align: right;\">-0.133099 </td><td style=\"text-align: right;\">0.0677329  </td><td style=\"text-align: right;\"> 0.0242289  </td><td style=\"text-align: right;\">-0.0614122  </td><td style=\"text-align: right;\">-0.0150937</td><td style=\"text-align: right;\"> 0.0031073 </td><td style=\"text-align: right;\">-0.046582 </td><td style=\"text-align: right;\"> 0.0536096 </td><td style=\"text-align: right;\">-0.0215838 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">0.140947 </td><td style=\"text-align: right;\">0.00712421</td><td style=\"text-align: right;\"> 0.0334936</td><td style=\"text-align: right;\">-0.0843437 </td><td style=\"text-align: right;\">-0.0446588</td><td style=\"text-align: right;\">-0.060759 </td><td style=\"text-align: right;\"> 0.110575  </td><td style=\"text-align: right;\">-0.0939169 </td><td style=\"text-align: right;\">0.095208 </td><td style=\"text-align: right;\">-0.0674785 </td><td style=\"text-align: right;\"> 0.0842193</td><td style=\"text-align: right;\"> 0.00492611 </td><td style=\"text-align: right;\"> 0.103937  </td><td style=\"text-align: right;\"> 0.00126557</td><td style=\"text-align: right;\">0.0186149</td><td style=\"text-align: right;\"> 0.0190158 </td><td style=\"text-align: right;\">-0.0984765</td><td style=\"text-align: right;\">-0.214065 </td><td style=\"text-align: right;\">-0.00882541</td><td style=\"text-align: right;\">0.0933808</td><td style=\"text-align: right;\">-0.136535 </td><td style=\"text-align: right;\">-0.00798242</td><td style=\"text-align: right;\"> 0.0360488 </td><td style=\"text-align: right;\"> 0.029198  </td><td style=\"text-align: right;\"> 0.180252 </td><td style=\"text-align: right;\"> 0.0574367 </td><td style=\"text-align: right;\">-0.106713  </td><td style=\"text-align: right;\">-0.170507 </td><td style=\"text-align: right;\"> 0.0150033 </td><td style=\"text-align: right;\"> 0.0432057</td><td style=\"text-align: right;\"> 0.020954  </td><td style=\"text-align: right;\">0.171736 </td><td style=\"text-align: right;\">0.0673502</td><td style=\"text-align: right;\"> 0.0246961</td><td style=\"text-align: right;\">-0.0542799</td><td style=\"text-align: right;\"> 0.0726603 </td><td style=\"text-align: right;\"> 0.0259393 </td><td style=\"text-align: right;\">-0.185776 </td><td style=\"text-align: right;\">-0.0527286 </td><td style=\"text-align: right;\"> 0.00782687</td><td style=\"text-align: right;\"> 0.0856214 </td><td style=\"text-align: right;\">-0.319836 </td><td style=\"text-align: right;\"> 0.0116708</td><td style=\"text-align: right;\">-0.226908 </td><td style=\"text-align: right;\">-0.192366</td><td style=\"text-align: right;\">-0.0568947 </td><td style=\"text-align: right;\">-0.0783025</td><td style=\"text-align: right;\">0.118505 </td><td style=\"text-align: right;\">-0.0837622</td><td style=\"text-align: right;\">0.00395956</td><td style=\"text-align: right;\">-0.174732 </td><td style=\"text-align: right;\">0.149928 </td><td style=\"text-align: right;\"> 0.0774037</td><td style=\"text-align: right;\">-0.177459 </td><td style=\"text-align: right;\">0.0694959</td><td style=\"text-align: right;\"> 0.00813231 </td><td style=\"text-align: right;\">-0.0446212 </td><td style=\"text-align: right;\">0.113824 </td><td style=\"text-align: right;\">-0.0539651</td><td style=\"text-align: right;\"> 0.0577569</td><td style=\"text-align: right;\">0.0730523</td><td style=\"text-align: right;\">0.0234868</td><td style=\"text-align: right;\"> 0.117565  </td><td style=\"text-align: right;\">-0.172207 </td><td style=\"text-align: right;\"> 0.0405708</td><td style=\"text-align: right;\"> 0.107358  </td><td style=\"text-align: right;\">-0.207191</td><td style=\"text-align: right;\">0.11387  </td><td style=\"text-align: right;\">0.326393</td><td style=\"text-align: right;\">-0.216447  </td><td style=\"text-align: right;\"> 0.00344842</td><td style=\"text-align: right;\"> 0.102789 </td><td style=\"text-align: right;\">0.126799 </td><td style=\"text-align: right;\"> 0.0732317</td><td style=\"text-align: right;\">-0.120575 </td><td style=\"text-align: right;\">-0.090091  </td><td style=\"text-align: right;\">-0.108995  </td><td style=\"text-align: right;\">-0.022211   </td><td style=\"text-align: right;\">0.268529 </td><td style=\"text-align: right;\">-0.0581862 </td><td style=\"text-align: right;\">0.136151  </td><td style=\"text-align: right;\"> 0.00209568</td><td style=\"text-align: right;\">-0.0166651</td><td style=\"text-align: right;\"> 0.0454734 </td><td style=\"text-align: right;\"> 0.0451208</td><td style=\"text-align: right;\">-0.00530661</td><td style=\"text-align: right;\"> 0.0789892</td><td style=\"text-align: right;\">0.194293</td><td style=\"text-align: right;\">0.100972 </td><td style=\"text-align: right;\">0.00383514</td><td style=\"text-align: right;\">-0.10984   </td><td style=\"text-align: right;\">-0.0876846</td><td style=\"text-align: right;\">0.0729718  </td><td style=\"text-align: right;\"> 0.00670741 </td><td style=\"text-align: right;\"> 0.0516636  </td><td style=\"text-align: right;\"> 0.0102298</td><td style=\"text-align: right;\"> 0.0540766 </td><td style=\"text-align: right;\"> 0.0822851</td><td style=\"text-align: right;\"> 0.178053  </td><td style=\"text-align: right;\">-0.11235   </td></tr>\n",
       "<tr><td style=\"text-align: right;\">0.0775482</td><td style=\"text-align: right;\">0.0670681 </td><td style=\"text-align: right;\">-0.118039 </td><td style=\"text-align: right;\">-0.0690619 </td><td style=\"text-align: right;\">-0.149278 </td><td style=\"text-align: right;\">-0.114091 </td><td style=\"text-align: right;\"> 0.0859716 </td><td style=\"text-align: right;\">-0.122552  </td><td style=\"text-align: right;\">0.163025 </td><td style=\"text-align: right;\"> 0.0232515 </td><td style=\"text-align: right;\"> 0.0772998</td><td style=\"text-align: right;\">-0.0301296  </td><td style=\"text-align: right;\"> 0.0603009 </td><td style=\"text-align: right;\">-0.0113856 </td><td style=\"text-align: right;\">0.0021689</td><td style=\"text-align: right;\"> 0.00639274</td><td style=\"text-align: right;\"> 0.020491 </td><td style=\"text-align: right;\">-0.233755 </td><td style=\"text-align: right;\"> 0.034463  </td><td style=\"text-align: right;\">0.0925796</td><td style=\"text-align: right;\">-0.0870652</td><td style=\"text-align: right;\">-0.0132047 </td><td style=\"text-align: right;\"> 0.162421  </td><td style=\"text-align: right;\"> 0.0384825 </td><td style=\"text-align: right;\"> 0.093635 </td><td style=\"text-align: right;\">-0.0361223 </td><td style=\"text-align: right;\"> 0.0436386 </td><td style=\"text-align: right;\">-0.0283991</td><td style=\"text-align: right;\"> 0.00562294</td><td style=\"text-align: right;\"> 0.153338 </td><td style=\"text-align: right;\"> 0.0483229 </td><td style=\"text-align: right;\">0.108622 </td><td style=\"text-align: right;\">0.0419949</td><td style=\"text-align: right;\">-0.0890661</td><td style=\"text-align: right;\">-0.162895 </td><td style=\"text-align: right;\"> 0.0513039 </td><td style=\"text-align: right;\"> 0.00176411</td><td style=\"text-align: right;\">-0.133756 </td><td style=\"text-align: right;\">-0.00415669</td><td style=\"text-align: right;\">-0.0151963 </td><td style=\"text-align: right;\"> 0.0977631 </td><td style=\"text-align: right;\">-0.165256 </td><td style=\"text-align: right;\"> 0.0079504</td><td style=\"text-align: right;\">-0.200873 </td><td style=\"text-align: right;\">-0.276167</td><td style=\"text-align: right;\"> 0.0635103 </td><td style=\"text-align: right;\">-0.121496 </td><td style=\"text-align: right;\">0.0431218</td><td style=\"text-align: right;\">-0.0523819</td><td style=\"text-align: right;\">0.122331  </td><td style=\"text-align: right;\"> 0.0475615</td><td style=\"text-align: right;\">0.135822 </td><td style=\"text-align: right;\"> 0.10002  </td><td style=\"text-align: right;\">-0.167301 </td><td style=\"text-align: right;\">0.0571737</td><td style=\"text-align: right;\"> 0.0419573  </td><td style=\"text-align: right;\">-0.0706827 </td><td style=\"text-align: right;\">0.143735 </td><td style=\"text-align: right;\"> 0.0398154</td><td style=\"text-align: right;\">-0.014689 </td><td style=\"text-align: right;\">0.024905 </td><td style=\"text-align: right;\">0.0443785</td><td style=\"text-align: right;\"> 0.0505555 </td><td style=\"text-align: right;\">-0.133121 </td><td style=\"text-align: right;\">-0.125772 </td><td style=\"text-align: right;\"> 0.0753582 </td><td style=\"text-align: right;\">-0.370168</td><td style=\"text-align: right;\">0.164541 </td><td style=\"text-align: right;\">0.206496</td><td style=\"text-align: right;\">-0.00191678</td><td style=\"text-align: right;\"> 0.0280144 </td><td style=\"text-align: right;\">-0.0870842</td><td style=\"text-align: right;\">0.149136 </td><td style=\"text-align: right;\">-0.0167884</td><td style=\"text-align: right;\">-0.0910067</td><td style=\"text-align: right;\">-0.0257347 </td><td style=\"text-align: right;\">-0.02445   </td><td style=\"text-align: right;\">-0.000503847</td><td style=\"text-align: right;\">0.148558 </td><td style=\"text-align: right;\">-0.0459035 </td><td style=\"text-align: right;\">0.103045  </td><td style=\"text-align: right;\"> 0.0286964 </td><td style=\"text-align: right;\">-0.0920166</td><td style=\"text-align: right;\"> 0.0950327 </td><td style=\"text-align: right;\"> 0.0663399</td><td style=\"text-align: right;\"> 0.047518  </td><td style=\"text-align: right;\"> 0.0504995</td><td style=\"text-align: right;\">0.222099</td><td style=\"text-align: right;\">0.0119018</td><td style=\"text-align: right;\">0.0348491 </td><td style=\"text-align: right;\">-0.138545  </td><td style=\"text-align: right;\">-0.0313843</td><td style=\"text-align: right;\">0.134675   </td><td style=\"text-align: right;\">-0.0382794  </td><td style=\"text-align: right;\">-0.0358505  </td><td style=\"text-align: right;\"> 0.0417004</td><td style=\"text-align: right;\"> 0.120316  </td><td style=\"text-align: right;\">-0.0277394</td><td style=\"text-align: right;\"> 0.028145  </td><td style=\"text-align: right;\"> 0.0165897 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">0.194102 </td><td style=\"text-align: right;\">0.0148582 </td><td style=\"text-align: right;\">-0.0232727</td><td style=\"text-align: right;\">-0.0028116 </td><td style=\"text-align: right;\">-0.0882551</td><td style=\"text-align: right;\">-0.072381 </td><td style=\"text-align: right;\"> 0.00377185</td><td style=\"text-align: right;\">-0.0777366 </td><td style=\"text-align: right;\">0.13798  </td><td style=\"text-align: right;\">-0.0360807 </td><td style=\"text-align: right;\"> 0.0042515</td><td style=\"text-align: right;\">-0.10808    </td><td style=\"text-align: right;\"> 0.0242503 </td><td style=\"text-align: right;\">-0.0279276 </td><td style=\"text-align: right;\">0.117327 </td><td style=\"text-align: right;\"> 0.0606052 </td><td style=\"text-align: right;\"> 0.0354829</td><td style=\"text-align: right;\">-0.156399 </td><td style=\"text-align: right;\">-0.0386063 </td><td style=\"text-align: right;\">0.0619939</td><td style=\"text-align: right;\">-0.0741082</td><td style=\"text-align: right;\"> 0.0534886 </td><td style=\"text-align: right;\"> 0.0521661 </td><td style=\"text-align: right;\">-0.0117152 </td><td style=\"text-align: right;\"> 0.0293921</td><td style=\"text-align: right;\"> 0.0357016 </td><td style=\"text-align: right;\">-0.0906672 </td><td style=\"text-align: right;\">-0.0635913</td><td style=\"text-align: right;\">-0.0110064 </td><td style=\"text-align: right;\"> 0.11076  </td><td style=\"text-align: right;\"> 0.0387231 </td><td style=\"text-align: right;\">0.172252 </td><td style=\"text-align: right;\">0.148122 </td><td style=\"text-align: right;\">-0.075887 </td><td style=\"text-align: right;\">-0.123912 </td><td style=\"text-align: right;\">-0.0633511 </td><td style=\"text-align: right;\"> 0.0111092 </td><td style=\"text-align: right;\">-0.140863 </td><td style=\"text-align: right;\">-0.110441  </td><td style=\"text-align: right;\"> 0.0850511 </td><td style=\"text-align: right;\">-0.048475  </td><td style=\"text-align: right;\"> 0.0145765</td><td style=\"text-align: right;\"> 0.0465484</td><td style=\"text-align: right;\">-0.122725 </td><td style=\"text-align: right;\">-0.307191</td><td style=\"text-align: right;\">-0.0753816 </td><td style=\"text-align: right;\">-0.159734 </td><td style=\"text-align: right;\">0.0484643</td><td style=\"text-align: right;\">-0.108815 </td><td style=\"text-align: right;\">0.0916769 </td><td style=\"text-align: right;\">-0.0214871</td><td style=\"text-align: right;\">0.115719 </td><td style=\"text-align: right;\">-0.0614765</td><td style=\"text-align: right;\">-0.0263719</td><td style=\"text-align: right;\">0.11519  </td><td style=\"text-align: right;\"> 0.00608886 </td><td style=\"text-align: right;\"> 0.092751  </td><td style=\"text-align: right;\">0.10308  </td><td style=\"text-align: right;\"> 0.0653047</td><td style=\"text-align: right;\"> 0.0208919</td><td style=\"text-align: right;\">0.0776629</td><td style=\"text-align: right;\">0.0212227</td><td style=\"text-align: right;\"> 0.119238  </td><td style=\"text-align: right;\">-0.102377 </td><td style=\"text-align: right;\">-0.210085 </td><td style=\"text-align: right;\"> 0.0252581 </td><td style=\"text-align: right;\">-0.330523</td><td style=\"text-align: right;\">0.0774017</td><td style=\"text-align: right;\">0.139122</td><td style=\"text-align: right;\">-0.0743243 </td><td style=\"text-align: right;\"> 0.100489  </td><td style=\"text-align: right;\"> 0.188673 </td><td style=\"text-align: right;\">0.0761802</td><td style=\"text-align: right;\"> 0.0237497</td><td style=\"text-align: right;\">-0.064185 </td><td style=\"text-align: right;\">-0.0558857 </td><td style=\"text-align: right;\">-0.00915165</td><td style=\"text-align: right;\">-0.0649253  </td><td style=\"text-align: right;\">0.132728 </td><td style=\"text-align: right;\"> 0.0688073 </td><td style=\"text-align: right;\">0.0378124 </td><td style=\"text-align: right;\">-0.0163721 </td><td style=\"text-align: right;\">-0.108147 </td><td style=\"text-align: right;\"> 0.0480036 </td><td style=\"text-align: right;\"> 0.0195498</td><td style=\"text-align: right;\"> 0.047212  </td><td style=\"text-align: right;\"> 0.0362191</td><td style=\"text-align: right;\">0.198252</td><td style=\"text-align: right;\">0.043468 </td><td style=\"text-align: right;\">0.00191999</td><td style=\"text-align: right;\"> 0.0510404 </td><td style=\"text-align: right;\">-0.0119655</td><td style=\"text-align: right;\">0.124524   </td><td style=\"text-align: right;\"> 0.000845331</td><td style=\"text-align: right;\">-0.023167   </td><td style=\"text-align: right;\">-0.101472 </td><td style=\"text-align: right;\"> 0.00234045</td><td style=\"text-align: right;\">-0.0881936</td><td style=\"text-align: right;\"> 0.0760685 </td><td style=\"text-align: right;\">-0.0400581 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">0.176354 </td><td style=\"text-align: right;\">0.0130875 </td><td style=\"text-align: right;\">-0.0511308</td><td style=\"text-align: right;\">-0.0279227 </td><td style=\"text-align: right;\">-0.164406 </td><td style=\"text-align: right;\">-0.163126 </td><td style=\"text-align: right;\"> 0.0145091 </td><td style=\"text-align: right;\">-0.0228716 </td><td style=\"text-align: right;\">0.194841 </td><td style=\"text-align: right;\"> 0.0101187 </td><td style=\"text-align: right;\">-0.0610345</td><td style=\"text-align: right;\">-0.0715377  </td><td style=\"text-align: right;\">-0.0140543 </td><td style=\"text-align: right;\"> 0.0381489 </td><td style=\"text-align: right;\">0.0176322</td><td style=\"text-align: right;\">-0.0198263 </td><td style=\"text-align: right;\">-0.06212  </td><td style=\"text-align: right;\">-0.170515 </td><td style=\"text-align: right;\">-0.160126  </td><td style=\"text-align: right;\">0.0931629</td><td style=\"text-align: right;\"> 0.0270162</td><td style=\"text-align: right;\"> 0.0731958 </td><td style=\"text-align: right;\">-0.00456385</td><td style=\"text-align: right;\"> 0.00780004</td><td style=\"text-align: right;\"> 0.0602588</td><td style=\"text-align: right;\"> 0.0147618 </td><td style=\"text-align: right;\"> 0.00182121</td><td style=\"text-align: right;\"> 0.0954975</td><td style=\"text-align: right;\"> 0.0240453 </td><td style=\"text-align: right;\"> 0.0111369</td><td style=\"text-align: right;\"> 0.00773314</td><td style=\"text-align: right;\">0.211308 </td><td style=\"text-align: right;\">0.136358 </td><td style=\"text-align: right;\">-0.0676055</td><td style=\"text-align: right;\">-0.0902008</td><td style=\"text-align: right;\">-0.034855  </td><td style=\"text-align: right;\"> 0.00148338</td><td style=\"text-align: right;\">-0.10829  </td><td style=\"text-align: right;\">-0.0322411 </td><td style=\"text-align: right;\"> 0.126678  </td><td style=\"text-align: right;\">-0.0448134 </td><td style=\"text-align: right;\">-0.0322315</td><td style=\"text-align: right;\"> 0.0436413</td><td style=\"text-align: right;\">-0.18882  </td><td style=\"text-align: right;\">-0.29921 </td><td style=\"text-align: right;\">-0.116787  </td><td style=\"text-align: right;\">-0.158004 </td><td style=\"text-align: right;\">0.0746252</td><td style=\"text-align: right;\">-0.111811 </td><td style=\"text-align: right;\">0.0962228 </td><td style=\"text-align: right;\"> 0.0739337</td><td style=\"text-align: right;\">0.159858 </td><td style=\"text-align: right;\">-0.0291317</td><td style=\"text-align: right;\">-0.0164694</td><td style=\"text-align: right;\">0.0249657</td><td style=\"text-align: right;\"> 0.0751233  </td><td style=\"text-align: right;\"> 0.028138  </td><td style=\"text-align: right;\">0.0680269</td><td style=\"text-align: right;\">-0.0118521</td><td style=\"text-align: right;\"> 0.092928 </td><td style=\"text-align: right;\">0.0825621</td><td style=\"text-align: right;\">0.101126 </td><td style=\"text-align: right;\"> 0.109012  </td><td style=\"text-align: right;\">-0.125795 </td><td style=\"text-align: right;\">-0.153681 </td><td style=\"text-align: right;\"> 0.14558   </td><td style=\"text-align: right;\">-0.338022</td><td style=\"text-align: right;\">0.0682396</td><td style=\"text-align: right;\">0.093112</td><td style=\"text-align: right;\">-0.0276775 </td><td style=\"text-align: right;\"> 0.11445   </td><td style=\"text-align: right;\"> 0.0871177</td><td style=\"text-align: right;\">0.0106936</td><td style=\"text-align: right;\"> 0.118801 </td><td style=\"text-align: right;\">-0.0220254</td><td style=\"text-align: right;\">-0.0966831 </td><td style=\"text-align: right;\">-0.194466  </td><td style=\"text-align: right;\"> 0.0554     </td><td style=\"text-align: right;\">0.0594465</td><td style=\"text-align: right;\">-0.00932522</td><td style=\"text-align: right;\">0.197187  </td><td style=\"text-align: right;\"> 0.0209713 </td><td style=\"text-align: right;\">-0.156111 </td><td style=\"text-align: right;\">-0.0224773 </td><td style=\"text-align: right;\">-0.0276533</td><td style=\"text-align: right;\"> 0.0232435 </td><td style=\"text-align: right;\"> 0.0346151</td><td style=\"text-align: right;\">0.147225</td><td style=\"text-align: right;\">0.11882  </td><td style=\"text-align: right;\">0.0881735 </td><td style=\"text-align: right;\">-0.124229  </td><td style=\"text-align: right;\"> 0.0437475</td><td style=\"text-align: right;\">0.138454   </td><td style=\"text-align: right;\"> 0.0986066  </td><td style=\"text-align: right;\"> 0.0426267  </td><td style=\"text-align: right;\">-0.0121153</td><td style=\"text-align: right;\">-0.0209348 </td><td style=\"text-align: right;\">-0.0787288</td><td style=\"text-align: right;\"> 0.0718464 </td><td style=\"text-align: right;\">-0.0989287 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">0.11096  </td><td style=\"text-align: right;\">0.0269754 </td><td style=\"text-align: right;\"> 0.0314723</td><td style=\"text-align: right;\"> 0.0169026 </td><td style=\"text-align: right;\">-0.119107 </td><td style=\"text-align: right;\">-0.110051 </td><td style=\"text-align: right;\"> 0.00543739</td><td style=\"text-align: right;\">-0.0236914 </td><td style=\"text-align: right;\">0.148065 </td><td style=\"text-align: right;\">-0.0229687 </td><td style=\"text-align: right;\"> 0.0214234</td><td style=\"text-align: right;\">-0.000942823</td><td style=\"text-align: right;\"> 0.0519763 </td><td style=\"text-align: right;\">-0.0930621 </td><td style=\"text-align: right;\">0.0727786</td><td style=\"text-align: right;\"> 0.0754202 </td><td style=\"text-align: right;\">-0.0392617</td><td style=\"text-align: right;\">-0.0871704</td><td style=\"text-align: right;\">-0.00644997</td><td style=\"text-align: right;\">0.0611376</td><td style=\"text-align: right;\">-0.0593794</td><td style=\"text-align: right;\">-0.0378668 </td><td style=\"text-align: right;\"> 0.0335982 </td><td style=\"text-align: right;\">-0.0554121 </td><td style=\"text-align: right;\"> 0.0744008</td><td style=\"text-align: right;\">-0.0052403 </td><td style=\"text-align: right;\"> 0.0291106 </td><td style=\"text-align: right;\">-0.0684366</td><td style=\"text-align: right;\"> 0.0238582 </td><td style=\"text-align: right;\"> 0.0336541</td><td style=\"text-align: right;\"> 0.0135028 </td><td style=\"text-align: right;\">0.129114 </td><td style=\"text-align: right;\">0.145406 </td><td style=\"text-align: right;\">-0.0552978</td><td style=\"text-align: right;\">-0.119813 </td><td style=\"text-align: right;\"> 0.0545994 </td><td style=\"text-align: right;\"> 0.0128623 </td><td style=\"text-align: right;\">-0.0321464</td><td style=\"text-align: right;\">-0.179699  </td><td style=\"text-align: right;\"> 0.00823251</td><td style=\"text-align: right;\"> 0.0443223 </td><td style=\"text-align: right;\">-0.108829 </td><td style=\"text-align: right;\"> 0.0220633</td><td style=\"text-align: right;\">-0.0703954</td><td style=\"text-align: right;\">-0.140441</td><td style=\"text-align: right;\"> 0.0579873 </td><td style=\"text-align: right;\">-0.0624533</td><td style=\"text-align: right;\">0.112263 </td><td style=\"text-align: right;\">-0.0398564</td><td style=\"text-align: right;\">0.0683535 </td><td style=\"text-align: right;\">-0.0257905</td><td style=\"text-align: right;\">0.12592  </td><td style=\"text-align: right;\">-0.216648 </td><td style=\"text-align: right;\">-0.109139 </td><td style=\"text-align: right;\">0.006607 </td><td style=\"text-align: right;\">-0.000961631</td><td style=\"text-align: right;\"> 0.0359094 </td><td style=\"text-align: right;\">0.204555 </td><td style=\"text-align: right;\"> 0.0166902</td><td style=\"text-align: right;\"> 0.0371054</td><td style=\"text-align: right;\">0.144113 </td><td style=\"text-align: right;\">0.0619747</td><td style=\"text-align: right;\"> 0.0439654 </td><td style=\"text-align: right;\">-0.140398 </td><td style=\"text-align: right;\">-0.146774 </td><td style=\"text-align: right;\"> 0.0376146 </td><td style=\"text-align: right;\">-0.239099</td><td style=\"text-align: right;\">0.0503702</td><td style=\"text-align: right;\">0.179952</td><td style=\"text-align: right;\">-0.145114  </td><td style=\"text-align: right;\"> 0.00386914</td><td style=\"text-align: right;\"> 0.116913 </td><td style=\"text-align: right;\">0.0900974</td><td style=\"text-align: right;\"> 0.0740236</td><td style=\"text-align: right;\">-0.0330306</td><td style=\"text-align: right;\">-0.121164  </td><td style=\"text-align: right;\"> 0.056515  </td><td style=\"text-align: right;\">-0.0244835  </td><td style=\"text-align: right;\">0.12974  </td><td style=\"text-align: right;\"> 0.0740637 </td><td style=\"text-align: right;\">0.0568007 </td><td style=\"text-align: right;\">-0.0459099 </td><td style=\"text-align: right;\">-0.131586 </td><td style=\"text-align: right;\"> 0.00395853</td><td style=\"text-align: right;\"> 0.0193199</td><td style=\"text-align: right;\">-0.0183367 </td><td style=\"text-align: right;\">-0.0395769</td><td style=\"text-align: right;\">0.204975</td><td style=\"text-align: right;\">0.0869113</td><td style=\"text-align: right;\">0.0371199 </td><td style=\"text-align: right;\">-0.00185321</td><td style=\"text-align: right;\">-0.0971317</td><td style=\"text-align: right;\">0.216949   </td><td style=\"text-align: right;\"> 0.0208666  </td><td style=\"text-align: right;\">-0.0121789  </td><td style=\"text-align: right;\">-0.0200151</td><td style=\"text-align: right;\"> 0.017135  </td><td style=\"text-align: right;\">-0.107263 </td><td style=\"text-align: right;\"> 0.00398034</td><td style=\"text-align: right;\">-0.0366697 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">0.179362 </td><td style=\"text-align: right;\">0.0166569 </td><td style=\"text-align: right;\"> 0.0487936</td><td style=\"text-align: right;\"> 0.0261438 </td><td style=\"text-align: right;\">-0.137093 </td><td style=\"text-align: right;\">-0.06128  </td><td style=\"text-align: right;\"> 0.0501309 </td><td style=\"text-align: right;\">-0.00326038</td><td style=\"text-align: right;\">0.0660768</td><td style=\"text-align: right;\">-0.0876653 </td><td style=\"text-align: right;\"> 0.0438942</td><td style=\"text-align: right;\">-0.0708237  </td><td style=\"text-align: right;\"> 0.00100127</td><td style=\"text-align: right;\">-0.0816256 </td><td style=\"text-align: right;\">0.0655705</td><td style=\"text-align: right;\"> 0.126702  </td><td style=\"text-align: right;\">-0.0103504</td><td style=\"text-align: right;\">-0.117144 </td><td style=\"text-align: right;\">-0.0190522 </td><td style=\"text-align: right;\">0.0451916</td><td style=\"text-align: right;\">-0.0244176</td><td style=\"text-align: right;\"> 0.0118816 </td><td style=\"text-align: right;\"> 0.056436  </td><td style=\"text-align: right;\">-0.00128247</td><td style=\"text-align: right;\"> 0.0467346</td><td style=\"text-align: right;\"> 0.0599898 </td><td style=\"text-align: right;\"> 0.0174266 </td><td style=\"text-align: right;\">-0.0637329</td><td style=\"text-align: right;\"> 0.0776268 </td><td style=\"text-align: right;\">-0.0228409</td><td style=\"text-align: right;\"> 0.0150281 </td><td style=\"text-align: right;\">0.124778 </td><td style=\"text-align: right;\">0.126135 </td><td style=\"text-align: right;\">-0.0469556</td><td style=\"text-align: right;\">-0.116258 </td><td style=\"text-align: right;\"> 0.0174486 </td><td style=\"text-align: right;\">-0.00286139</td><td style=\"text-align: right;\">-0.0986674</td><td style=\"text-align: right;\">-0.152677  </td><td style=\"text-align: right;\"> 0.0263058 </td><td style=\"text-align: right;\">-0.0194443 </td><td style=\"text-align: right;\">-0.10124  </td><td style=\"text-align: right;\">-0.0532821</td><td style=\"text-align: right;\">-0.0962483</td><td style=\"text-align: right;\">-0.187323</td><td style=\"text-align: right;\">-0.00844572</td><td style=\"text-align: right;\">-0.14227  </td><td style=\"text-align: right;\">0.079189 </td><td style=\"text-align: right;\">-0.0400209</td><td style=\"text-align: right;\">0.14157   </td><td style=\"text-align: right;\">-0.0987567</td><td style=\"text-align: right;\">0.053002 </td><td style=\"text-align: right;\">-0.169577 </td><td style=\"text-align: right;\">-0.124934 </td><td style=\"text-align: right;\">0.0564315</td><td style=\"text-align: right;\"> 0.00484039 </td><td style=\"text-align: right;\"> 0.0512056 </td><td style=\"text-align: right;\">0.184934 </td><td style=\"text-align: right;\"> 0.0195397</td><td style=\"text-align: right;\"> 0.0104447</td><td style=\"text-align: right;\">0.160928 </td><td style=\"text-align: right;\">0.100412 </td><td style=\"text-align: right;\">-0.0171271 </td><td style=\"text-align: right;\">-0.0762092</td><td style=\"text-align: right;\">-0.244221 </td><td style=\"text-align: right;\"> 0.0102272 </td><td style=\"text-align: right;\">-0.26566 </td><td style=\"text-align: right;\">0.089239 </td><td style=\"text-align: right;\">0.176578</td><td style=\"text-align: right;\">-0.125507  </td><td style=\"text-align: right;\">-0.00985668</td><td style=\"text-align: right;\"> 0.130874 </td><td style=\"text-align: right;\">0.071509 </td><td style=\"text-align: right;\"> 0.0351043</td><td style=\"text-align: right;\">-0.0215538</td><td style=\"text-align: right;\">-0.080669  </td><td style=\"text-align: right;\"> 0.0752685 </td><td style=\"text-align: right;\">-0.076831   </td><td style=\"text-align: right;\">0.0933768</td><td style=\"text-align: right;\"> 0.0926386 </td><td style=\"text-align: right;\">0.0725937 </td><td style=\"text-align: right;\"> 0.0344896 </td><td style=\"text-align: right;\">-0.13544  </td><td style=\"text-align: right;\"> 0.00900042</td><td style=\"text-align: right;\">-0.0325185</td><td style=\"text-align: right;\"> 0.0217836 </td><td style=\"text-align: right;\"> 0.0303316</td><td style=\"text-align: right;\">0.195153</td><td style=\"text-align: right;\">0.0917376</td><td style=\"text-align: right;\">0.0282758 </td><td style=\"text-align: right;\"> 0.00403437</td><td style=\"text-align: right;\">-0.106737 </td><td style=\"text-align: right;\">0.153085   </td><td style=\"text-align: right;\">-0.028257   </td><td style=\"text-align: right;\">-0.0118401  </td><td style=\"text-align: right;\">-0.0600208</td><td style=\"text-align: right;\"> 0.0108766 </td><td style=\"text-align: right;\">-0.111438 </td><td style=\"text-align: right;\">-0.0211443 </td><td style=\"text-align: right;\">-0.0464383 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">0.0298028</td><td style=\"text-align: right;\">0.0772156 </td><td style=\"text-align: right;\">-0.0583802</td><td style=\"text-align: right;\">-0.00594493</td><td style=\"text-align: right;\">-0.111733 </td><td style=\"text-align: right;\">-0.128607 </td><td style=\"text-align: right;\">-0.0369452 </td><td style=\"text-align: right;\">-0.0575002 </td><td style=\"text-align: right;\">0.0484043</td><td style=\"text-align: right;\">-0.00205246</td><td style=\"text-align: right;\"> 0.0515233</td><td style=\"text-align: right;\"> 0.0245156  </td><td style=\"text-align: right;\"> 0.014516  </td><td style=\"text-align: right;\"> 0.011131  </td><td style=\"text-align: right;\">0.121881 </td><td style=\"text-align: right;\"> 0.104088  </td><td style=\"text-align: right;\">-0.0734877</td><td style=\"text-align: right;\">-0.0909364</td><td style=\"text-align: right;\">-0.0238354 </td><td style=\"text-align: right;\">0.0657104</td><td style=\"text-align: right;\">-0.152508 </td><td style=\"text-align: right;\"> 0.0194345 </td><td style=\"text-align: right;\"> 0.0774416 </td><td style=\"text-align: right;\">-0.00815421</td><td style=\"text-align: right;\"> 0.0448155</td><td style=\"text-align: right;\">-0.0750867 </td><td style=\"text-align: right;\"> 0.0072418 </td><td style=\"text-align: right;\">-0.0600739</td><td style=\"text-align: right;\">-0.0357427 </td><td style=\"text-align: right;\"> 0.0940223</td><td style=\"text-align: right;\"> 0.0221695 </td><td style=\"text-align: right;\">0.0971039</td><td style=\"text-align: right;\">0.126007 </td><td style=\"text-align: right;\">-0.0825836</td><td style=\"text-align: right;\">-0.203421 </td><td style=\"text-align: right;\"> 0.0638442 </td><td style=\"text-align: right;\"> 0.0617656 </td><td style=\"text-align: right;\">-0.0715409</td><td style=\"text-align: right;\">-0.154546  </td><td style=\"text-align: right;\"> 0.0349999 </td><td style=\"text-align: right;\"> 0.0304124 </td><td style=\"text-align: right;\">-0.0597691</td><td style=\"text-align: right;\"> 0.0293091</td><td style=\"text-align: right;\">-0.154211 </td><td style=\"text-align: right;\">-0.199031</td><td style=\"text-align: right;\">-0.00703568</td><td style=\"text-align: right;\">-0.141877 </td><td style=\"text-align: right;\">0.120893 </td><td style=\"text-align: right;\">-0.0293173</td><td style=\"text-align: right;\">0.0604666 </td><td style=\"text-align: right;\">-0.0733874</td><td style=\"text-align: right;\">0.0637554</td><td style=\"text-align: right;\">-0.161796 </td><td style=\"text-align: right;\">-0.0646782</td><td style=\"text-align: right;\">0.0225219</td><td style=\"text-align: right;\"> 0.0121584  </td><td style=\"text-align: right;\">-0.0257204 </td><td style=\"text-align: right;\">0.17959  </td><td style=\"text-align: right;\"> 0.0320336</td><td style=\"text-align: right;\"> 0.0288899</td><td style=\"text-align: right;\">0.0991695</td><td style=\"text-align: right;\">0.0730957</td><td style=\"text-align: right;\">-0.00398166</td><td style=\"text-align: right;\">-0.240272 </td><td style=\"text-align: right;\">-0.0902373</td><td style=\"text-align: right;\">-0.0183188 </td><td style=\"text-align: right;\">-0.262325</td><td style=\"text-align: right;\">0.0716147</td><td style=\"text-align: right;\">0.195793</td><td style=\"text-align: right;\">-0.163925  </td><td style=\"text-align: right;\">-0.0338761 </td><td style=\"text-align: right;\"> 0.141439 </td><td style=\"text-align: right;\">0.093149 </td><td style=\"text-align: right;\"> 0.0510137</td><td style=\"text-align: right;\">-0.0760811</td><td style=\"text-align: right;\">-0.16066   </td><td style=\"text-align: right;\"> 0.0523939 </td><td style=\"text-align: right;\">-0.0240737  </td><td style=\"text-align: right;\">0.108668 </td><td style=\"text-align: right;\"> 0.0565158 </td><td style=\"text-align: right;\">0.00289569</td><td style=\"text-align: right;\">-0.0193483 </td><td style=\"text-align: right;\">-0.153086 </td><td style=\"text-align: right;\"> 0.00038697</td><td style=\"text-align: right;\"> 0.070704 </td><td style=\"text-align: right;\"> 0.127937  </td><td style=\"text-align: right;\"> 0.0619199</td><td style=\"text-align: right;\">0.179882</td><td style=\"text-align: right;\">0.0196487</td><td style=\"text-align: right;\">0.0209424 </td><td style=\"text-align: right;\">-0.0440805 </td><td style=\"text-align: right;\">-0.102909 </td><td style=\"text-align: right;\">0.16173    </td><td style=\"text-align: right;\"> 0.103299   </td><td style=\"text-align: right;\">-0.048837   </td><td style=\"text-align: right;\">-0.0287144</td><td style=\"text-align: right;\"> 0.0335429 </td><td style=\"text-align: right;\">-0.0749376</td><td style=\"text-align: right;\"> 0.0431993 </td><td style=\"text-align: right;\"> 0.00222189</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 72,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_h2o_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6WPjs40Gi5Fv"
   },
   "outputs": [],
   "source": [
    "# Add aggregated word embeddings \n",
    "ext_df_h2o = df_h2o.cbind(df_h2o_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uiZxCEvajDn9"
   },
   "outputs": [],
   "source": [
    "ext_train = ext_df_h2o[ext_df_h2o[\"Train\"] == \"Yes\"]\n",
    "ext_test = ext_df_h2o[ext_df_h2o[\"Train\"] == \"No\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "AfRZxyrdjGvC",
    "outputId": "4e89c1cf-63c9-4b16-c509-4f8674d97e7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "predictors = predictors + df_h2o_vecs.names\n",
    "response = 'label'\n",
    "\n",
    "gbm_embeddings = H2OGradientBoostingEstimator(stopping_metric = \"AUC\", stopping_tolerance = 0.001,\n",
    "                                              score_tree_interval = 10,\n",
    "                                              model_id = \"gbm_embeddings.hex\"\n",
    "                                             )\n",
    "gbm_embeddings.train(x = predictors, y = response, \n",
    "                   training_frame = ext_train, validation_frame = ext_test\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "DCHOCuTojJjY",
    "outputId": "22da998c-91ff-4360-de0c-fd082bea76be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.29175487852247445: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9825.0</td>\n",
       "      <td>10443.0</td>\n",
       "      <td>0.5152</td>\n",
       "      <td>(10443.0/20268.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>837.0</td>\n",
       "      <td>10573.0</td>\n",
       "      <td>0.0734</td>\n",
       "      <td>(837.0/11410.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>10662.0</td>\n",
       "      <td>21016.0</td>\n",
       "      <td>0.3561</td>\n",
       "      <td>(11280.0/31678.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0        1   Error                Rate\n",
       "0      0   9825.0  10443.0  0.5152   (10443.0/20268.0)\n",
       "1      1    837.0  10573.0  0.0734     (837.0/11410.0)\n",
       "2  Total  10662.0  21016.0  0.3561   (11280.0/31678.0)"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 76,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_embeddings.confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OMNoQwmPjMEk",
    "outputId": "17cd59c6-8efe-4bec-bbdf-3824ec37f433"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7489235718151529"
      ]
     },
     "execution_count": 77,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_embeddings.auc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>After cleaning the text and performing word2vec we see a decent improve in the auc score by 20%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameter tuning\n",
    "\n",
    "We used the <b>grid search</b> for tuning the hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "h8_iuX_JjN_O",
    "outputId": "a4a1fb58-ed79-436f-e154-0fa682652a48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Grid Build progress: |████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "from h2o.grid.grid_search import H2OGridSearch\n",
    "\n",
    "#hyper_params = {'max_depth' : range(1,30,2)}\n",
    "hyper_params = {'max_depth' : [8,12,20]} ##faster for larger datasets\n",
    "\n",
    "#Build initial GBM Model\n",
    "gbm_grid1 = H2OGradientBoostingEstimator(\n",
    "        ## more trees is better if the learning rate is small enough \n",
    "        ## here, use \"more than enough\" trees - we have early stopping\n",
    "        ntrees=10000,\n",
    "        ## smaller learning rate is better\n",
    "        ## since we have learning_rate_annealing, we can afford to start with a \n",
    "        #bigger learning rate\n",
    "        learn_rate=0.05,\n",
    "        ## learning rate annealing: learning_rate shrinks by 1% after every tree \n",
    "        ## (use 1.00 to disable, but then lower the learning_rate)\n",
    "        learn_rate_annealing = 0.99,\n",
    "        ## sample 80% of rows per tree\n",
    "        sample_rate = 0.8,\n",
    "        ## sample 80% of columns per split\n",
    "        col_sample_rate = 0.8,\n",
    "        ## fix a random number generator seed for reproducibility\n",
    "        seed = 1234,\n",
    "        ## score every 10 trees to make early stopping reproducible \n",
    "        #(it depends on the scoring interval)\n",
    "        score_tree_interval = 10, \n",
    "        ## early stopping once the validation AUC doesn't improve by at least 0.01% for \n",
    "        #5 consecutive scoring events\n",
    "        stopping_rounds = 5,\n",
    "        stopping_metric = \"AUC\",\n",
    "        stopping_tolerance = 1e-4,\n",
    "        model_id = \"gbm_grid.hex\"    )\n",
    "\n",
    "#Build grid search with previously made GBM and hyper parameters\n",
    "gbm_gridSearch = H2OGridSearch(gbm_grid1,hyper_params,\n",
    "                         grid_id = 'depth_grid1',\n",
    "                         search_criteria = {'strategy': \"Cartesian\"})\n",
    "\n",
    "\n",
    "#Train grid search\n",
    "gbm_gridSearch.train(x=predictors, \n",
    "           y=response,\n",
    "           training_frame = ext_train, validation_frame = ext_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "nQll_SDwjO91",
    "outputId": "2561e183-b016-4437-f8c7-5c088e873361"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OGradientBoostingEstimator :  Gradient Boosting Machine\n",
      "Model Key:  gbm_baseline.hex\n",
      "\n",
      "\n",
      "Model Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>number_of_trees</th>\n",
       "      <th>number_of_internal_trees</th>\n",
       "      <th>model_size_in_bytes</th>\n",
       "      <th>min_depth</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>mean_depth</th>\n",
       "      <th>min_leaves</th>\n",
       "      <th>max_leaves</th>\n",
       "      <th>mean_leaves</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>16741.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>21.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     number_of_trees  ...  max_leaves  mean_leaves\n",
       "0               50.0  ...        32.0        21.92\n",
       "\n",
       "[1 rows x 10 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.2236626016035098\n",
      "RMSE: 0.4729298062117779\n",
      "LogLoss: 0.6384174096410937\n",
      "Mean Per-Class Error: 0.4247633291458004\n",
      "AUC: 0.603069951605541\n",
      "AUCPR: 0.44222898854891607\n",
      "Gini: 0.206139903211082\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.2731903208880132: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4079.0</td>\n",
       "      <td>16189.0</td>\n",
       "      <td>0.7987</td>\n",
       "      <td>(16189.0/20268.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1191.0</td>\n",
       "      <td>10219.0</td>\n",
       "      <td>0.1044</td>\n",
       "      <td>(1191.0/11410.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>5270.0</td>\n",
       "      <td>26408.0</td>\n",
       "      <td>0.5486</td>\n",
       "      <td>(17380.0/31678.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0        1   Error                Rate\n",
       "0      0  4079.0  16189.0  0.7987   (16189.0/20268.0)\n",
       "1      1  1191.0  10219.0  0.1044    (1191.0/11410.0)\n",
       "2  Total  5270.0  26408.0  0.5486   (17380.0/31678.0)"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.273190</td>\n",
       "      <td>0.540430</td>\n",
       "      <td>314.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.207624</td>\n",
       "      <td>0.738919</td>\n",
       "      <td>394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.361684</td>\n",
       "      <td>0.455178</td>\n",
       "      <td>170.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.473079</td>\n",
       "      <td>0.640950</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.595283</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.177975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.595283</td>\n",
       "      <td>0.999556</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.361684</td>\n",
       "      <td>0.144623</td>\n",
       "      <td>170.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.361684</td>\n",
       "      <td>0.573357</td>\n",
       "      <td>170.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.361684</td>\n",
       "      <td>0.575237</td>\n",
       "      <td>170.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.595283</td>\n",
       "      <td>20259.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.595283</td>\n",
       "      <td>11382.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.177975</td>\n",
       "      <td>20268.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.177975</td>\n",
       "      <td>11410.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.595283</td>\n",
       "      <td>0.999556</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.595283</td>\n",
       "      <td>0.997546</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.177975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.177975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold         value    idx\n",
       "0                        max f1   0.273190      0.540430  314.0\n",
       "1                        max f2   0.207624      0.738919  394.0\n",
       "2                  max f0point5   0.361684      0.455178  170.0\n",
       "3                  max accuracy   0.473079      0.640950    7.0\n",
       "4                 max precision   0.595283      0.756757    0.0\n",
       "5                    max recall   0.177975      1.000000  399.0\n",
       "6               max specificity   0.595283      0.999556    0.0\n",
       "7              max absolute_mcc   0.361684      0.144623  170.0\n",
       "8    max min_per_class_accuracy   0.361684      0.573357  170.0\n",
       "9   max mean_per_class_accuracy   0.361684      0.575237  170.0\n",
       "10                      max tns   0.595283  20259.000000    0.0\n",
       "11                      max fns   0.595283  11382.000000    0.0\n",
       "12                      max fps   0.177975  20268.000000  399.0\n",
       "13                      max tps   0.177975  11410.000000  399.0\n",
       "14                      max tnr   0.595283      0.999556    0.0\n",
       "15                      max fnr   0.595283      0.997546    0.0\n",
       "16                      max fpr   0.177975      1.000000  399.0\n",
       "17                      max tpr   0.177975      1.000000  399.0"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 36.02 %, avg score: 36.02 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.010196</td>\n",
       "      <td>0.478894</td>\n",
       "      <td>1.512803</td>\n",
       "      <td>1.512803</td>\n",
       "      <td>0.544892</td>\n",
       "      <td>0.498051</td>\n",
       "      <td>0.544892</td>\n",
       "      <td>0.498051</td>\n",
       "      <td>0.015425</td>\n",
       "      <td>0.015425</td>\n",
       "      <td>51.280258</td>\n",
       "      <td>51.280258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0.023865</td>\n",
       "      <td>0.473574</td>\n",
       "      <td>1.397786</td>\n",
       "      <td>1.446927</td>\n",
       "      <td>0.503464</td>\n",
       "      <td>0.473667</td>\n",
       "      <td>0.521164</td>\n",
       "      <td>0.484085</td>\n",
       "      <td>0.019106</td>\n",
       "      <td>0.034531</td>\n",
       "      <td>39.778607</td>\n",
       "      <td>44.692672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>0.035924</td>\n",
       "      <td>0.471905</td>\n",
       "      <td>1.366365</td>\n",
       "      <td>1.419884</td>\n",
       "      <td>0.492147</td>\n",
       "      <td>0.471984</td>\n",
       "      <td>0.511424</td>\n",
       "      <td>0.480023</td>\n",
       "      <td>0.016477</td>\n",
       "      <td>0.051008</td>\n",
       "      <td>36.636458</td>\n",
       "      <td>41.988389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.069291</td>\n",
       "      <td>0.470181</td>\n",
       "      <td>1.308056</td>\n",
       "      <td>1.366033</td>\n",
       "      <td>0.471145</td>\n",
       "      <td>0.470225</td>\n",
       "      <td>0.492027</td>\n",
       "      <td>0.475305</td>\n",
       "      <td>0.043646</td>\n",
       "      <td>0.094654</td>\n",
       "      <td>30.805639</td>\n",
       "      <td>36.603347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>0.102753</td>\n",
       "      <td>0.453663</td>\n",
       "      <td>1.293878</td>\n",
       "      <td>1.342536</td>\n",
       "      <td>0.466038</td>\n",
       "      <td>0.461053</td>\n",
       "      <td>0.483564</td>\n",
       "      <td>0.470664</td>\n",
       "      <td>0.043295</td>\n",
       "      <td>0.137949</td>\n",
       "      <td>29.387760</td>\n",
       "      <td>34.253571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>0.158059</td>\n",
       "      <td>0.433082</td>\n",
       "      <td>1.316858</td>\n",
       "      <td>1.333551</td>\n",
       "      <td>0.474315</td>\n",
       "      <td>0.441630</td>\n",
       "      <td>0.480328</td>\n",
       "      <td>0.460505</td>\n",
       "      <td>0.072831</td>\n",
       "      <td>0.210780</td>\n",
       "      <td>31.685826</td>\n",
       "      <td>33.355091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "      <td>0.200897</td>\n",
       "      <td>0.429838</td>\n",
       "      <td>1.196873</td>\n",
       "      <td>1.304407</td>\n",
       "      <td>0.431098</td>\n",
       "      <td>0.430009</td>\n",
       "      <td>0.469830</td>\n",
       "      <td>0.454002</td>\n",
       "      <td>0.051271</td>\n",
       "      <td>0.262051</td>\n",
       "      <td>19.687316</td>\n",
       "      <td>30.440702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "      <td>0.302513</td>\n",
       "      <td>0.416108</td>\n",
       "      <td>1.158316</td>\n",
       "      <td>1.255334</td>\n",
       "      <td>0.417210</td>\n",
       "      <td>0.424685</td>\n",
       "      <td>0.452155</td>\n",
       "      <td>0.444154</td>\n",
       "      <td>0.117704</td>\n",
       "      <td>0.379755</td>\n",
       "      <td>15.831624</td>\n",
       "      <td>25.533406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>0.400152</td>\n",
       "      <td>0.373427</td>\n",
       "      <td>1.158827</td>\n",
       "      <td>1.231786</td>\n",
       "      <td>0.417394</td>\n",
       "      <td>0.395211</td>\n",
       "      <td>0.443673</td>\n",
       "      <td>0.432212</td>\n",
       "      <td>0.113146</td>\n",
       "      <td>0.492901</td>\n",
       "      <td>15.882654</td>\n",
       "      <td>23.178580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>0.500032</td>\n",
       "      <td>0.361413</td>\n",
       "      <td>1.033668</td>\n",
       "      <td>1.192212</td>\n",
       "      <td>0.372314</td>\n",
       "      <td>0.366556</td>\n",
       "      <td>0.429419</td>\n",
       "      <td>0.419097</td>\n",
       "      <td>0.103243</td>\n",
       "      <td>0.596144</td>\n",
       "      <td>3.366765</td>\n",
       "      <td>19.221220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>0.601679</td>\n",
       "      <td>0.344293</td>\n",
       "      <td>0.977753</td>\n",
       "      <td>1.155981</td>\n",
       "      <td>0.352174</td>\n",
       "      <td>0.354868</td>\n",
       "      <td>0.416369</td>\n",
       "      <td>0.408246</td>\n",
       "      <td>0.099387</td>\n",
       "      <td>0.695530</td>\n",
       "      <td>-2.224669</td>\n",
       "      <td>15.598147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.713239</td>\n",
       "      <td>0.325407</td>\n",
       "      <td>0.900306</td>\n",
       "      <td>1.115990</td>\n",
       "      <td>0.324278</td>\n",
       "      <td>0.331742</td>\n",
       "      <td>0.401965</td>\n",
       "      <td>0.396280</td>\n",
       "      <td>0.100438</td>\n",
       "      <td>0.795968</td>\n",
       "      <td>-9.969392</td>\n",
       "      <td>11.599046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.799987</td>\n",
       "      <td>0.295505</td>\n",
       "      <td>0.822394</td>\n",
       "      <td>1.084154</td>\n",
       "      <td>0.296215</td>\n",
       "      <td>0.311924</td>\n",
       "      <td>0.390498</td>\n",
       "      <td>0.387133</td>\n",
       "      <td>0.071341</td>\n",
       "      <td>0.867309</td>\n",
       "      <td>-17.760628</td>\n",
       "      <td>8.415383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0.900183</td>\n",
       "      <td>0.255819</td>\n",
       "      <td>0.760125</td>\n",
       "      <td>1.048087</td>\n",
       "      <td>0.273787</td>\n",
       "      <td>0.268586</td>\n",
       "      <td>0.377507</td>\n",
       "      <td>0.373938</td>\n",
       "      <td>0.076161</td>\n",
       "      <td>0.943471</td>\n",
       "      <td>-23.987509</td>\n",
       "      <td>4.808749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td>15</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.177975</td>\n",
       "      <td>0.566331</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.203985</td>\n",
       "      <td>0.236338</td>\n",
       "      <td>0.360187</td>\n",
       "      <td>0.360203</td>\n",
       "      <td>0.056529</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-43.366949</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      group  ...       gain  cumulative_gain\n",
       "0         1  ...  51.280258        51.280258\n",
       "1         2  ...  39.778607        44.692672\n",
       "2         3  ...  36.636458        41.988389\n",
       "3         4  ...  30.805639        36.603347\n",
       "4         5  ...  29.387760        34.253571\n",
       "5         6  ...  31.685826        33.355091\n",
       "6         7  ...  19.687316        30.440702\n",
       "7         8  ...  15.831624        25.533406\n",
       "8         9  ...  15.882654        23.178580\n",
       "9        10  ...   3.366765        19.221220\n",
       "10       11  ...  -2.224669        15.598147\n",
       "11       12  ...  -9.969392        11.599046\n",
       "12       13  ... -17.760628         8.415383\n",
       "13       14  ... -23.987509         4.808749\n",
       "14       15  ... -43.366949         0.000000\n",
       "\n",
       "[15 rows x 14 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 0.2091282310026076\n",
      "RMSE: 0.4573054023326289\n",
      "LogLoss: 0.6175758898574257\n",
      "Mean Per-Class Error: 0.5\n",
      "AUC: 0.5\n",
      "AUCPR: 0.2755269468635618\n",
      "Gini: 0.0\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.17797499871796357: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5740.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(5740.0/5740.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2183.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0.0/2183.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7923.0</td>\n",
       "      <td>0.7245</td>\n",
       "      <td>(5740.0/7923.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       1   Error              Rate\n",
       "0      0  0.0  5740.0     1.0   (5740.0/5740.0)\n",
       "1      1  0.0  2183.0     0.0      (0.0/2183.0)\n",
       "2  Total  0.0  7923.0  0.7245   (5740.0/7923.0)"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.177975</td>\n",
       "      <td>0.432021</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.177975</td>\n",
       "      <td>0.655359</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.177975</td>\n",
       "      <td>0.322214</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.177975</td>\n",
       "      <td>0.275527</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.177975</td>\n",
       "      <td>0.275527</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.177975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.177975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.177975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.177975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.177975</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.177975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.177975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.177975</td>\n",
       "      <td>5740.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.177975</td>\n",
       "      <td>2183.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.177975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.177975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.177975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.177975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold        value  idx\n",
       "0                        max f1   0.177975     0.432021  0.0\n",
       "1                        max f2   0.177975     0.655359  0.0\n",
       "2                  max f0point5   0.177975     0.322214  0.0\n",
       "3                  max accuracy   0.177975     0.275527  0.0\n",
       "4                 max precision   0.177975     0.275527  0.0\n",
       "5                    max recall   0.177975     1.000000  0.0\n",
       "6               max specificity   0.177975     0.000000  0.0\n",
       "7              max absolute_mcc   0.177975     0.000000  0.0\n",
       "8    max min_per_class_accuracy   0.177975     0.000000  0.0\n",
       "9   max mean_per_class_accuracy   0.177975     0.500000  0.0\n",
       "10                      max tns   0.177975     0.000000  0.0\n",
       "11                      max fns   0.177975     0.000000  0.0\n",
       "12                      max fps   0.177975  5740.000000  0.0\n",
       "13                      max tps   0.177975  2183.000000  0.0\n",
       "14                      max tnr   0.177975     0.000000  0.0\n",
       "15                      max fnr   0.177975     0.000000  0.0\n",
       "16                      max fpr   0.177975     1.000000  0.0\n",
       "17                      max tpr   0.177975     1.000000  0.0"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 27.55 %, avg score: 17.80 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.177975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.275527</td>\n",
       "      <td>0.177975</td>\n",
       "      <td>0.275527</td>\n",
       "      <td>0.177975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     group  ...  gain  cumulative_gain\n",
       "0        1  ...   0.0              0.0\n",
       "\n",
       "[1 rows x 14 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>duration</th>\n",
       "      <th>number_of_trees</th>\n",
       "      <th>training_rmse</th>\n",
       "      <th>training_logloss</th>\n",
       "      <th>training_auc</th>\n",
       "      <th>training_pr_auc</th>\n",
       "      <th>training_lift</th>\n",
       "      <th>training_classification_error</th>\n",
       "      <th>validation_rmse</th>\n",
       "      <th>validation_logloss</th>\n",
       "      <th>validation_auc</th>\n",
       "      <th>validation_pr_auc</th>\n",
       "      <th>validation_lift</th>\n",
       "      <th>validation_classification_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>2020-04-24 04:55:18</td>\n",
       "      <td>0.012 sec</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.480054</td>\n",
       "      <td>0.653526</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.360187</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.639813</td>\n",
       "      <td>0.454730</td>\n",
       "      <td>0.604884</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.275527</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.724473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2020-04-24 04:55:18</td>\n",
       "      <td>0.458 sec</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.474669</td>\n",
       "      <td>0.642221</td>\n",
       "      <td>0.595972</td>\n",
       "      <td>0.436661</td>\n",
       "      <td>1.519128</td>\n",
       "      <td>0.555938</td>\n",
       "      <td>0.446846</td>\n",
       "      <td>0.588827</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.275527</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.724473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>2020-04-24 04:55:19</td>\n",
       "      <td>0.857 sec</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.473629</td>\n",
       "      <td>0.639947</td>\n",
       "      <td>0.599032</td>\n",
       "      <td>0.439335</td>\n",
       "      <td>1.512803</td>\n",
       "      <td>0.566450</td>\n",
       "      <td>0.447117</td>\n",
       "      <td>0.589455</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.275527</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.724473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>2020-04-24 04:55:19</td>\n",
       "      <td>1.259 sec</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.473234</td>\n",
       "      <td>0.639077</td>\n",
       "      <td>0.601057</td>\n",
       "      <td>0.440920</td>\n",
       "      <td>1.512803</td>\n",
       "      <td>0.566040</td>\n",
       "      <td>0.450060</td>\n",
       "      <td>0.596778</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.275527</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.724473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>2020-04-24 04:55:19</td>\n",
       "      <td>1.655 sec</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.472967</td>\n",
       "      <td>0.638504</td>\n",
       "      <td>0.602847</td>\n",
       "      <td>0.442144</td>\n",
       "      <td>1.512803</td>\n",
       "      <td>0.549435</td>\n",
       "      <td>0.457254</td>\n",
       "      <td>0.617416</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.275527</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.724473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>2020-04-24 04:55:20</td>\n",
       "      <td>1.925 sec</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.472930</td>\n",
       "      <td>0.638417</td>\n",
       "      <td>0.603070</td>\n",
       "      <td>0.442229</td>\n",
       "      <td>1.512803</td>\n",
       "      <td>0.548646</td>\n",
       "      <td>0.457305</td>\n",
       "      <td>0.617576</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.275527</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.724473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               timestamp  ... validation_lift  validation_classification_error\n",
       "0    2020-04-24 04:55:18  ...             1.0                         0.724473\n",
       "1    2020-04-24 04:55:18  ...             1.0                         0.724473\n",
       "2    2020-04-24 04:55:19  ...             1.0                         0.724473\n",
       "3    2020-04-24 04:55:19  ...             1.0                         0.724473\n",
       "4    2020-04-24 04:55:19  ...             1.0                         0.724473\n",
       "5    2020-04-24 04:55:20  ...             1.0                         0.724473\n",
       "\n",
       "[6 rows x 16 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>relative_importance</th>\n",
       "      <th>scaled_importance</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>length</td>\n",
       "      <td>1137.999146</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  variable  relative_importance  scaled_importance  percentage\n",
       "0   length          1137.999146                1.0         1.0"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print (gbm_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ZcV2T-BujR4t",
    "outputId": "9c11f61f-fc0b-48db-bfaa-2aaa7a290128"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OGradientBoostingEstimator :  Gradient Boosting Machine\n",
      "Model Key:  gbm_embeddings.hex\n",
      "\n",
      "\n",
      "Model Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>number_of_trees</th>\n",
       "      <th>number_of_internal_trees</th>\n",
       "      <th>model_size_in_bytes</th>\n",
       "      <th>min_depth</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>mean_depth</th>\n",
       "      <th>min_leaves</th>\n",
       "      <th>max_leaves</th>\n",
       "      <th>mean_leaves</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>22887.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     number_of_trees  ...  max_leaves  mean_leaves\n",
       "0               50.0  ...        32.0        31.76\n",
       "\n",
       "[1 rows x 10 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.18794495840172346\n",
      "RMSE: 0.433526191136964\n",
      "LogLoss: 0.5450862926028768\n",
      "Mean Per-Class Error: 0.29302730786946585\n",
      "AUC: 0.7489235718151529\n",
      "AUCPR: 0.5571414202829504\n",
      "Gini: 0.4978471436303058\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.29175487852247445: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9825.0</td>\n",
       "      <td>10443.0</td>\n",
       "      <td>0.5152</td>\n",
       "      <td>(10443.0/20268.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>837.0</td>\n",
       "      <td>10573.0</td>\n",
       "      <td>0.0734</td>\n",
       "      <td>(837.0/11410.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>10662.0</td>\n",
       "      <td>21016.0</td>\n",
       "      <td>0.3561</td>\n",
       "      <td>(11280.0/31678.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0        1   Error                Rate\n",
       "0      0   9825.0  10443.0  0.5152   (10443.0/20268.0)\n",
       "1      1    837.0  10573.0  0.0734     (837.0/11410.0)\n",
       "2  Total  10662.0  21016.0  0.3561   (11280.0/31678.0)"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.291755</td>\n",
       "      <td>0.652131</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.218414</td>\n",
       "      <td>0.804193</td>\n",
       "      <td>281.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.388921</td>\n",
       "      <td>0.563527</td>\n",
       "      <td>183.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.465247</td>\n",
       "      <td>0.672612</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.886300</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.054929</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>385.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.886300</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.281728</td>\n",
       "      <td>0.418463</td>\n",
       "      <td>245.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.432771</td>\n",
       "      <td>0.668838</td>\n",
       "      <td>152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.317195</td>\n",
       "      <td>0.706973</td>\n",
       "      <td>226.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.886300</td>\n",
       "      <td>20268.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.886300</td>\n",
       "      <td>11405.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.034487</td>\n",
       "      <td>20268.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.054929</td>\n",
       "      <td>11410.000000</td>\n",
       "      <td>385.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.886300</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.886300</td>\n",
       "      <td>0.999562</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.034487</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.054929</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>385.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold         value    idx\n",
       "0                        max f1   0.291755      0.652131  240.0\n",
       "1                        max f2   0.218414      0.804193  281.0\n",
       "2                  max f0point5   0.388921      0.563527  183.0\n",
       "3                  max accuracy   0.465247      0.672612  128.0\n",
       "4                 max precision   0.886300      1.000000    0.0\n",
       "5                    max recall   0.054929      1.000000  385.0\n",
       "6               max specificity   0.886300      1.000000    0.0\n",
       "7              max absolute_mcc   0.281728      0.418463  245.0\n",
       "8    max min_per_class_accuracy   0.432771      0.668838  152.0\n",
       "9   max mean_per_class_accuracy   0.317195      0.706973  226.0\n",
       "10                      max tns   0.886300  20268.000000    0.0\n",
       "11                      max fns   0.886300  11405.000000    0.0\n",
       "12                      max fps   0.034487  20268.000000  399.0\n",
       "13                      max tps   0.054929  11410.000000  385.0\n",
       "14                      max tnr   0.886300      1.000000    0.0\n",
       "15                      max fnr   0.886300      0.999562    0.0\n",
       "16                      max fpr   0.034487      1.000000  399.0\n",
       "17                      max tpr   0.054929      1.000000  385.0"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 36.02 %, avg score: 36.03 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.010007</td>\n",
       "      <td>0.606088</td>\n",
       "      <td>1.900521</td>\n",
       "      <td>1.900521</td>\n",
       "      <td>0.684543</td>\n",
       "      <td>0.653820</td>\n",
       "      <td>0.684543</td>\n",
       "      <td>0.653820</td>\n",
       "      <td>0.019018</td>\n",
       "      <td>0.019018</td>\n",
       "      <td>90.052060</td>\n",
       "      <td>90.052060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0.020014</td>\n",
       "      <td>0.591565</td>\n",
       "      <td>1.760390</td>\n",
       "      <td>1.830455</td>\n",
       "      <td>0.634069</td>\n",
       "      <td>0.598256</td>\n",
       "      <td>0.659306</td>\n",
       "      <td>0.626038</td>\n",
       "      <td>0.017616</td>\n",
       "      <td>0.036635</td>\n",
       "      <td>76.039005</td>\n",
       "      <td>83.045533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>0.030084</td>\n",
       "      <td>0.582684</td>\n",
       "      <td>1.662321</td>\n",
       "      <td>1.774175</td>\n",
       "      <td>0.598746</td>\n",
       "      <td>0.586592</td>\n",
       "      <td>0.639035</td>\n",
       "      <td>0.612834</td>\n",
       "      <td>0.016740</td>\n",
       "      <td>0.053374</td>\n",
       "      <td>66.232063</td>\n",
       "      <td>77.417519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.040059</td>\n",
       "      <td>0.575660</td>\n",
       "      <td>1.669316</td>\n",
       "      <td>1.748064</td>\n",
       "      <td>0.601266</td>\n",
       "      <td>0.579501</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.604534</td>\n",
       "      <td>0.016652</td>\n",
       "      <td>0.070026</td>\n",
       "      <td>66.931628</td>\n",
       "      <td>74.806375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>0.050066</td>\n",
       "      <td>0.570660</td>\n",
       "      <td>1.576469</td>\n",
       "      <td>1.713766</td>\n",
       "      <td>0.567823</td>\n",
       "      <td>0.573113</td>\n",
       "      <td>0.617276</td>\n",
       "      <td>0.598254</td>\n",
       "      <td>0.015776</td>\n",
       "      <td>0.085802</td>\n",
       "      <td>57.646870</td>\n",
       "      <td>71.376638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>0.100006</td>\n",
       "      <td>0.550323</td>\n",
       "      <td>1.582968</td>\n",
       "      <td>1.648450</td>\n",
       "      <td>0.570164</td>\n",
       "      <td>0.560053</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.579177</td>\n",
       "      <td>0.079053</td>\n",
       "      <td>0.164855</td>\n",
       "      <td>58.296812</td>\n",
       "      <td>64.844982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "      <td>0.150041</td>\n",
       "      <td>0.534121</td>\n",
       "      <td>1.522168</td>\n",
       "      <td>1.606338</td>\n",
       "      <td>0.548265</td>\n",
       "      <td>0.542360</td>\n",
       "      <td>0.578582</td>\n",
       "      <td>0.566900</td>\n",
       "      <td>0.076161</td>\n",
       "      <td>0.241017</td>\n",
       "      <td>52.216811</td>\n",
       "      <td>60.633821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "      <td>0.200044</td>\n",
       "      <td>0.519207</td>\n",
       "      <td>1.479311</td>\n",
       "      <td>1.574586</td>\n",
       "      <td>0.532828</td>\n",
       "      <td>0.526690</td>\n",
       "      <td>0.567145</td>\n",
       "      <td>0.556849</td>\n",
       "      <td>0.073970</td>\n",
       "      <td>0.314987</td>\n",
       "      <td>47.931063</td>\n",
       "      <td>57.458633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>0.300019</td>\n",
       "      <td>0.489741</td>\n",
       "      <td>1.439452</td>\n",
       "      <td>1.529556</td>\n",
       "      <td>0.518472</td>\n",
       "      <td>0.504251</td>\n",
       "      <td>0.550926</td>\n",
       "      <td>0.539322</td>\n",
       "      <td>0.143909</td>\n",
       "      <td>0.458896</td>\n",
       "      <td>43.945204</td>\n",
       "      <td>52.955578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>0.399994</td>\n",
       "      <td>0.452950</td>\n",
       "      <td>1.398250</td>\n",
       "      <td>1.496737</td>\n",
       "      <td>0.503631</td>\n",
       "      <td>0.472106</td>\n",
       "      <td>0.539105</td>\n",
       "      <td>0.522522</td>\n",
       "      <td>0.139790</td>\n",
       "      <td>0.598685</td>\n",
       "      <td>39.824970</td>\n",
       "      <td>49.673703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.412370</td>\n",
       "      <td>1.370641</td>\n",
       "      <td>1.471516</td>\n",
       "      <td>0.493687</td>\n",
       "      <td>0.433288</td>\n",
       "      <td>0.530021</td>\n",
       "      <td>0.504674</td>\n",
       "      <td>0.137073</td>\n",
       "      <td>0.735758</td>\n",
       "      <td>37.064090</td>\n",
       "      <td>47.151621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.600006</td>\n",
       "      <td>0.347824</td>\n",
       "      <td>1.266353</td>\n",
       "      <td>1.437321</td>\n",
       "      <td>0.456124</td>\n",
       "      <td>0.382613</td>\n",
       "      <td>0.517704</td>\n",
       "      <td>0.484329</td>\n",
       "      <td>0.126643</td>\n",
       "      <td>0.862401</td>\n",
       "      <td>26.635300</td>\n",
       "      <td>43.732055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.699981</td>\n",
       "      <td>0.253392</td>\n",
       "      <td>0.895055</td>\n",
       "      <td>1.359872</td>\n",
       "      <td>0.322387</td>\n",
       "      <td>0.302579</td>\n",
       "      <td>0.489808</td>\n",
       "      <td>0.458371</td>\n",
       "      <td>0.089483</td>\n",
       "      <td>0.951884</td>\n",
       "      <td>-10.494486</td>\n",
       "      <td>35.987153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0.799987</td>\n",
       "      <td>0.159438</td>\n",
       "      <td>0.393490</td>\n",
       "      <td>1.239064</td>\n",
       "      <td>0.141730</td>\n",
       "      <td>0.204684</td>\n",
       "      <td>0.446295</td>\n",
       "      <td>0.426657</td>\n",
       "      <td>0.039351</td>\n",
       "      <td>0.991236</td>\n",
       "      <td>-60.651038</td>\n",
       "      <td>23.906425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td>15</td>\n",
       "      <td>0.899994</td>\n",
       "      <td>0.091346</td>\n",
       "      <td>0.079750</td>\n",
       "      <td>1.110242</td>\n",
       "      <td>0.028725</td>\n",
       "      <td>0.123371</td>\n",
       "      <td>0.399895</td>\n",
       "      <td>0.392957</td>\n",
       "      <td>0.007975</td>\n",
       "      <td>0.999211</td>\n",
       "      <td>-92.025043</td>\n",
       "      <td>11.024248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td></td>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.030807</td>\n",
       "      <td>0.007887</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002841</td>\n",
       "      <td>0.066677</td>\n",
       "      <td>0.360187</td>\n",
       "      <td>0.360327</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-99.211268</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      group  ...       gain  cumulative_gain\n",
       "0         1  ...  90.052060        90.052060\n",
       "1         2  ...  76.039005        83.045533\n",
       "2         3  ...  66.232063        77.417519\n",
       "3         4  ...  66.931628        74.806375\n",
       "4         5  ...  57.646870        71.376638\n",
       "5         6  ...  58.296812        64.844982\n",
       "6         7  ...  52.216811        60.633821\n",
       "7         8  ...  47.931063        57.458633\n",
       "8         9  ...  43.945204        52.955578\n",
       "9        10  ...  39.824970        49.673703\n",
       "10       11  ...  37.064090        47.151621\n",
       "11       12  ...  26.635300        43.732055\n",
       "12       13  ... -10.494486        35.987153\n",
       "13       14  ... -60.651038        23.906425\n",
       "14       15  ... -92.025043        11.024248\n",
       "15       16  ... -99.211268         0.000000\n",
       "\n",
       "[16 rows x 14 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 0.1556226311275332\n",
      "RMSE: 0.3944903435162047\n",
      "LogLoss: 0.4614273542675275\n",
      "Mean Per-Class Error: 0.2353883588898058\n",
      "AUC: 0.8056954595296886\n",
      "AUCPR: 0.5107063370522074\n",
      "Gini: 0.6113909190593771\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.24458352780794373: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3633.0</td>\n",
       "      <td>2107.0</td>\n",
       "      <td>0.3671</td>\n",
       "      <td>(2107.0/5740.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>0.1067</td>\n",
       "      <td>(233.0/2183.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>3866.0</td>\n",
       "      <td>4057.0</td>\n",
       "      <td>0.2953</td>\n",
       "      <td>(2340.0/7923.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0       1   Error              Rate\n",
       "0      0  3633.0  2107.0  0.3671   (2107.0/5740.0)\n",
       "1      1   233.0  1950.0  0.1067    (233.0/2183.0)\n",
       "2  Total  3866.0  4057.0  0.2953   (2340.0/7923.0)"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.244584</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>227.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.183173</td>\n",
       "      <td>0.778774</td>\n",
       "      <td>265.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.333698</td>\n",
       "      <td>0.542898</td>\n",
       "      <td>173.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.458108</td>\n",
       "      <td>0.736211</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.601245</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.060956</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>370.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.601245</td>\n",
       "      <td>0.999652</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.221788</td>\n",
       "      <td>0.474249</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.333698</td>\n",
       "      <td>0.730662</td>\n",
       "      <td>173.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.221788</td>\n",
       "      <td>0.764612</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.601245</td>\n",
       "      <td>5738.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.601245</td>\n",
       "      <td>2180.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.031010</td>\n",
       "      <td>5740.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.060956</td>\n",
       "      <td>2183.000000</td>\n",
       "      <td>370.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.601245</td>\n",
       "      <td>0.999652</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.601245</td>\n",
       "      <td>0.998626</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.031010</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.060956</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>370.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold        value    idx\n",
       "0                        max f1   0.244584     0.625000  227.0\n",
       "1                        max f2   0.183173     0.778774  265.0\n",
       "2                  max f0point5   0.333698     0.542898  173.0\n",
       "3                  max accuracy   0.458108     0.736211   86.0\n",
       "4                 max precision   0.601245     0.600000    0.0\n",
       "5                    max recall   0.060956     1.000000  370.0\n",
       "6               max specificity   0.601245     0.999652    0.0\n",
       "7              max absolute_mcc   0.221788     0.474249  240.0\n",
       "8    max min_per_class_accuracy   0.333698     0.730662  173.0\n",
       "9   max mean_per_class_accuracy   0.221788     0.764612  240.0\n",
       "10                      max tns   0.601245  5738.000000    0.0\n",
       "11                      max fns   0.601245  2180.000000    0.0\n",
       "12                      max fps   0.031010  5740.000000  399.0\n",
       "13                      max tps   0.060956  2183.000000  370.0\n",
       "14                      max tnr   0.601245     0.999652    0.0\n",
       "15                      max fnr   0.601245     0.998626    0.0\n",
       "16                      max fpr   0.031010     1.000000  399.0\n",
       "17                      max tpr   0.060956     1.000000  370.0"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 27.55 %, avg score: 26.57 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.010223</td>\n",
       "      <td>0.568417</td>\n",
       "      <td>1.837108</td>\n",
       "      <td>1.837108</td>\n",
       "      <td>0.506173</td>\n",
       "      <td>0.581432</td>\n",
       "      <td>0.506173</td>\n",
       "      <td>0.581432</td>\n",
       "      <td>0.018781</td>\n",
       "      <td>0.018781</td>\n",
       "      <td>83.710829</td>\n",
       "      <td>83.710829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0.020194</td>\n",
       "      <td>0.555021</td>\n",
       "      <td>1.975501</td>\n",
       "      <td>1.905440</td>\n",
       "      <td>0.544304</td>\n",
       "      <td>0.561236</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.571460</td>\n",
       "      <td>0.019698</td>\n",
       "      <td>0.038479</td>\n",
       "      <td>97.550114</td>\n",
       "      <td>90.543976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>0.030292</td>\n",
       "      <td>0.546399</td>\n",
       "      <td>1.950807</td>\n",
       "      <td>1.920562</td>\n",
       "      <td>0.537500</td>\n",
       "      <td>0.550110</td>\n",
       "      <td>0.529167</td>\n",
       "      <td>0.564343</td>\n",
       "      <td>0.019698</td>\n",
       "      <td>0.058177</td>\n",
       "      <td>95.080738</td>\n",
       "      <td>92.056230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.040136</td>\n",
       "      <td>0.538352</td>\n",
       "      <td>1.861235</td>\n",
       "      <td>1.906010</td>\n",
       "      <td>0.512821</td>\n",
       "      <td>0.542736</td>\n",
       "      <td>0.525157</td>\n",
       "      <td>0.559043</td>\n",
       "      <td>0.018323</td>\n",
       "      <td>0.076500</td>\n",
       "      <td>86.123542</td>\n",
       "      <td>90.601042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>0.050107</td>\n",
       "      <td>0.532358</td>\n",
       "      <td>1.883617</td>\n",
       "      <td>1.901554</td>\n",
       "      <td>0.518987</td>\n",
       "      <td>0.534902</td>\n",
       "      <td>0.523929</td>\n",
       "      <td>0.554239</td>\n",
       "      <td>0.018781</td>\n",
       "      <td>0.095282</td>\n",
       "      <td>88.361737</td>\n",
       "      <td>90.155437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>0.100088</td>\n",
       "      <td>0.503536</td>\n",
       "      <td>1.952182</td>\n",
       "      <td>1.926836</td>\n",
       "      <td>0.537879</td>\n",
       "      <td>0.517529</td>\n",
       "      <td>0.530895</td>\n",
       "      <td>0.535907</td>\n",
       "      <td>0.097572</td>\n",
       "      <td>0.192854</td>\n",
       "      <td>95.218215</td>\n",
       "      <td>92.683634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "      <td>0.150196</td>\n",
       "      <td>0.479980</td>\n",
       "      <td>1.938123</td>\n",
       "      <td>1.930602</td>\n",
       "      <td>0.534005</td>\n",
       "      <td>0.492136</td>\n",
       "      <td>0.531933</td>\n",
       "      <td>0.521304</td>\n",
       "      <td>0.097114</td>\n",
       "      <td>0.289968</td>\n",
       "      <td>93.812273</td>\n",
       "      <td>93.060163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "      <td>0.200177</td>\n",
       "      <td>0.452803</td>\n",
       "      <td>1.878861</td>\n",
       "      <td>1.917683</td>\n",
       "      <td>0.517677</td>\n",
       "      <td>0.466077</td>\n",
       "      <td>0.528373</td>\n",
       "      <td>0.507515</td>\n",
       "      <td>0.093907</td>\n",
       "      <td>0.383875</td>\n",
       "      <td>87.886076</td>\n",
       "      <td>91.768272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>0.300013</td>\n",
       "      <td>0.396486</td>\n",
       "      <td>1.812410</td>\n",
       "      <td>1.882651</td>\n",
       "      <td>0.499368</td>\n",
       "      <td>0.424985</td>\n",
       "      <td>0.518721</td>\n",
       "      <td>0.480052</td>\n",
       "      <td>0.180944</td>\n",
       "      <td>0.564819</td>\n",
       "      <td>81.241034</td>\n",
       "      <td>88.265098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>0.399975</td>\n",
       "      <td>0.330840</td>\n",
       "      <td>1.741383</td>\n",
       "      <td>1.847345</td>\n",
       "      <td>0.479798</td>\n",
       "      <td>0.365220</td>\n",
       "      <td>0.508993</td>\n",
       "      <td>0.451353</td>\n",
       "      <td>0.174072</td>\n",
       "      <td>0.738891</td>\n",
       "      <td>74.138314</td>\n",
       "      <td>84.734517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>0.500063</td>\n",
       "      <td>0.250650</td>\n",
       "      <td>1.368466</td>\n",
       "      <td>1.751497</td>\n",
       "      <td>0.377049</td>\n",
       "      <td>0.288307</td>\n",
       "      <td>0.482585</td>\n",
       "      <td>0.418719</td>\n",
       "      <td>0.136967</td>\n",
       "      <td>0.875859</td>\n",
       "      <td>36.846571</td>\n",
       "      <td>75.149675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>0.600025</td>\n",
       "      <td>0.170805</td>\n",
       "      <td>0.838613</td>\n",
       "      <td>1.599414</td>\n",
       "      <td>0.231061</td>\n",
       "      <td>0.212152</td>\n",
       "      <td>0.440682</td>\n",
       "      <td>0.384305</td>\n",
       "      <td>0.083830</td>\n",
       "      <td>0.959689</td>\n",
       "      <td>-16.138654</td>\n",
       "      <td>59.941355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>0.699987</td>\n",
       "      <td>0.115376</td>\n",
       "      <td>0.297868</td>\n",
       "      <td>1.413546</td>\n",
       "      <td>0.082071</td>\n",
       "      <td>0.139453</td>\n",
       "      <td>0.389470</td>\n",
       "      <td>0.349339</td>\n",
       "      <td>0.029776</td>\n",
       "      <td>0.989464</td>\n",
       "      <td>-70.213183</td>\n",
       "      <td>41.354554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>0.799950</td>\n",
       "      <td>0.079902</td>\n",
       "      <td>0.077904</td>\n",
       "      <td>1.246643</td>\n",
       "      <td>0.021465</td>\n",
       "      <td>0.096372</td>\n",
       "      <td>0.343484</td>\n",
       "      <td>0.317728</td>\n",
       "      <td>0.007787</td>\n",
       "      <td>0.997251</td>\n",
       "      <td>-92.209602</td>\n",
       "      <td>24.664303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td>15</td>\n",
       "      <td>0.899912</td>\n",
       "      <td>0.057341</td>\n",
       "      <td>0.027496</td>\n",
       "      <td>1.111220</td>\n",
       "      <td>0.007576</td>\n",
       "      <td>0.068137</td>\n",
       "      <td>0.306171</td>\n",
       "      <td>0.290004</td>\n",
       "      <td>0.002749</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-97.250448</td>\n",
       "      <td>11.122020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td></td>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.030180</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047542</td>\n",
       "      <td>0.275527</td>\n",
       "      <td>0.265736</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      group  ...        gain  cumulative_gain\n",
       "0         1  ...   83.710829        83.710829\n",
       "1         2  ...   97.550114        90.543976\n",
       "2         3  ...   95.080738        92.056230\n",
       "3         4  ...   86.123542        90.601042\n",
       "4         5  ...   88.361737        90.155437\n",
       "5         6  ...   95.218215        92.683634\n",
       "6         7  ...   93.812273        93.060163\n",
       "7         8  ...   87.886076        91.768272\n",
       "8         9  ...   81.241034        88.265098\n",
       "9        10  ...   74.138314        84.734517\n",
       "10       11  ...   36.846571        75.149675\n",
       "11       12  ...  -16.138654        59.941355\n",
       "12       13  ...  -70.213183        41.354554\n",
       "13       14  ...  -92.209602        24.664303\n",
       "14       15  ...  -97.250448        11.122020\n",
       "15       16  ... -100.000000         0.000000\n",
       "\n",
       "[16 rows x 14 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>duration</th>\n",
       "      <th>number_of_trees</th>\n",
       "      <th>training_rmse</th>\n",
       "      <th>training_logloss</th>\n",
       "      <th>training_auc</th>\n",
       "      <th>training_pr_auc</th>\n",
       "      <th>training_lift</th>\n",
       "      <th>training_classification_error</th>\n",
       "      <th>validation_rmse</th>\n",
       "      <th>validation_logloss</th>\n",
       "      <th>validation_auc</th>\n",
       "      <th>validation_pr_auc</th>\n",
       "      <th>validation_lift</th>\n",
       "      <th>validation_classification_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>2020-04-24 05:35:03</td>\n",
       "      <td>0.007 sec</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.480054</td>\n",
       "      <td>0.653526</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.360187</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.639813</td>\n",
       "      <td>0.454730</td>\n",
       "      <td>0.604884</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.275527</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.724473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2020-04-24 05:35:06</td>\n",
       "      <td>3.125 sec</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.454202</td>\n",
       "      <td>0.597713</td>\n",
       "      <td>0.713974</td>\n",
       "      <td>0.521875</td>\n",
       "      <td>1.795423</td>\n",
       "      <td>0.397026</td>\n",
       "      <td>0.414759</td>\n",
       "      <td>0.520652</td>\n",
       "      <td>0.784132</td>\n",
       "      <td>0.491549</td>\n",
       "      <td>1.903227</td>\n",
       "      <td>0.325256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>2020-04-24 05:35:08</td>\n",
       "      <td>5.377 sec</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.444676</td>\n",
       "      <td>0.574642</td>\n",
       "      <td>0.728163</td>\n",
       "      <td>0.534705</td>\n",
       "      <td>1.842160</td>\n",
       "      <td>0.372972</td>\n",
       "      <td>0.403317</td>\n",
       "      <td>0.490751</td>\n",
       "      <td>0.795387</td>\n",
       "      <td>0.500121</td>\n",
       "      <td>1.792301</td>\n",
       "      <td>0.312634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>2020-04-24 05:35:10</td>\n",
       "      <td>7.397 sec</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.439395</td>\n",
       "      <td>0.560813</td>\n",
       "      <td>0.736994</td>\n",
       "      <td>0.543719</td>\n",
       "      <td>1.900521</td>\n",
       "      <td>0.368552</td>\n",
       "      <td>0.398169</td>\n",
       "      <td>0.475275</td>\n",
       "      <td>0.801198</td>\n",
       "      <td>0.505035</td>\n",
       "      <td>1.792301</td>\n",
       "      <td>0.307964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>2020-04-24 05:35:12</td>\n",
       "      <td>9.388 sec</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.436069</td>\n",
       "      <td>0.551927</td>\n",
       "      <td>0.743624</td>\n",
       "      <td>0.551252</td>\n",
       "      <td>1.923418</td>\n",
       "      <td>0.360945</td>\n",
       "      <td>0.395796</td>\n",
       "      <td>0.466743</td>\n",
       "      <td>0.803721</td>\n",
       "      <td>0.508060</td>\n",
       "      <td>1.881916</td>\n",
       "      <td>0.305566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>2020-04-24 05:35:14</td>\n",
       "      <td>11.373 sec</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.433526</td>\n",
       "      <td>0.545086</td>\n",
       "      <td>0.748924</td>\n",
       "      <td>0.557141</td>\n",
       "      <td>1.900521</td>\n",
       "      <td>0.356083</td>\n",
       "      <td>0.394490</td>\n",
       "      <td>0.461427</td>\n",
       "      <td>0.805695</td>\n",
       "      <td>0.510706</td>\n",
       "      <td>1.837108</td>\n",
       "      <td>0.295343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               timestamp  ... validation_lift  validation_classification_error\n",
       "0    2020-04-24 05:35:03  ...        1.000000                         0.724473\n",
       "1    2020-04-24 05:35:06  ...        1.903227                         0.325256\n",
       "2    2020-04-24 05:35:08  ...        1.792301                         0.312634\n",
       "3    2020-04-24 05:35:10  ...        1.792301                         0.307964\n",
       "4    2020-04-24 05:35:12  ...        1.881916                         0.305566\n",
       "5    2020-04-24 05:35:14  ...        1.837108                         0.295343\n",
       "\n",
       "[6 rows x 16 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>relative_importance</th>\n",
       "      <th>scaled_importance</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C43</td>\n",
       "      <td>1579.112061</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.211560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C63</td>\n",
       "      <td>884.661438</td>\n",
       "      <td>0.560227</td>\n",
       "      <td>0.118521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>length</td>\n",
       "      <td>528.383606</td>\n",
       "      <td>0.334608</td>\n",
       "      <td>0.070790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C29</td>\n",
       "      <td>386.287628</td>\n",
       "      <td>0.244623</td>\n",
       "      <td>0.051752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C90</td>\n",
       "      <td>281.323212</td>\n",
       "      <td>0.178153</td>\n",
       "      <td>0.037690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C84</td>\n",
       "      <td>242.946411</td>\n",
       "      <td>0.153850</td>\n",
       "      <td>0.032548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C67</td>\n",
       "      <td>192.592499</td>\n",
       "      <td>0.121963</td>\n",
       "      <td>0.025802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C26</td>\n",
       "      <td>186.795578</td>\n",
       "      <td>0.118292</td>\n",
       "      <td>0.025026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>C7</td>\n",
       "      <td>162.731033</td>\n",
       "      <td>0.103052</td>\n",
       "      <td>0.021802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C69</td>\n",
       "      <td>161.308594</td>\n",
       "      <td>0.102151</td>\n",
       "      <td>0.021611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>C51</td>\n",
       "      <td>138.016830</td>\n",
       "      <td>0.087402</td>\n",
       "      <td>0.018491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>C76</td>\n",
       "      <td>135.729706</td>\n",
       "      <td>0.085953</td>\n",
       "      <td>0.018184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>C91</td>\n",
       "      <td>133.722321</td>\n",
       "      <td>0.084682</td>\n",
       "      <td>0.017915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>C78</td>\n",
       "      <td>122.684059</td>\n",
       "      <td>0.077692</td>\n",
       "      <td>0.016436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>C74</td>\n",
       "      <td>121.206757</td>\n",
       "      <td>0.076756</td>\n",
       "      <td>0.016239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>C48</td>\n",
       "      <td>121.076050</td>\n",
       "      <td>0.076674</td>\n",
       "      <td>0.016221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>C32</td>\n",
       "      <td>115.735138</td>\n",
       "      <td>0.073291</td>\n",
       "      <td>0.015505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>C18</td>\n",
       "      <td>113.220329</td>\n",
       "      <td>0.071699</td>\n",
       "      <td>0.015169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>C55</td>\n",
       "      <td>103.069733</td>\n",
       "      <td>0.065271</td>\n",
       "      <td>0.013809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>C66</td>\n",
       "      <td>100.155426</td>\n",
       "      <td>0.063425</td>\n",
       "      <td>0.013418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   variable  relative_importance  scaled_importance  percentage\n",
       "0       C43          1579.112061           1.000000    0.211560\n",
       "1       C63           884.661438           0.560227    0.118521\n",
       "2    length           528.383606           0.334608    0.070790\n",
       "3       C29           386.287628           0.244623    0.051752\n",
       "4       C90           281.323212           0.178153    0.037690\n",
       "5       C84           242.946411           0.153850    0.032548\n",
       "6       C67           192.592499           0.121963    0.025802\n",
       "7       C26           186.795578           0.118292    0.025026\n",
       "8        C7           162.731033           0.103052    0.021802\n",
       "9       C69           161.308594           0.102151    0.021611\n",
       "10      C51           138.016830           0.087402    0.018491\n",
       "11      C76           135.729706           0.085953    0.018184\n",
       "12      C91           133.722321           0.084682    0.017915\n",
       "13      C78           122.684059           0.077692    0.016436\n",
       "14      C74           121.206757           0.076756    0.016239\n",
       "15      C48           121.076050           0.076674    0.016221\n",
       "16      C32           115.735138           0.073291    0.015505\n",
       "17      C18           113.220329           0.071699    0.015169\n",
       "18      C55           103.069733           0.065271    0.013809\n",
       "19      C66           100.155426           0.063425    0.013418"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(gbm_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "TuniOq4HjXkC",
    "outputId": "79668d60-cf8b-41c3-fb44-53ed1664cab6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    max_depth            model_ids              logloss\n",
      "0           8  depth_grid1_model_1  0.45402084122317116\n",
      "1          12  depth_grid1_model_2  0.45918977078572054\n",
      "2          20  depth_grid1_model_3     0.48120246291119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(gbm_gridSearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "Vnc29GhnjZCI",
    "outputId": "e1f61e78-2f6b-4c24-8dea-77f1bd1784b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    max_depth            model_ids                 auc\n",
      "0          12  depth_grid1_model_2   0.811165826843793\n",
      "1          20  depth_grid1_model_3  0.8105167663972955\n",
      "2           8  depth_grid1_model_1  0.8099225724277398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sorted_grid = gbm_gridSearch.get_grid(sort_by='auc',decreasing=True)\n",
    "print(sorted_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>After tuning the hyper parameters the auc score increased by another 10%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "We are using AUC as our metric to evaluate how well the model is performing. In this case we achieve a <b>AUC score of 81.01. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions\n",
    "\n",
    "Now we have build our model, so let us try predicting by inputing new data\n",
    "\n",
    "To predict we will use some new tweets based on coronavirus and we can check if the model is predicting correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LxX2BrWWjbID"
   },
   "outputs": [],
   "source": [
    "def predict(df_h2o, w2v, gbm):\n",
    "    \n",
    "    words = tokenize(df_h2o[\"text\"].ascharacter())\n",
    "    df_h2o_vec = w2v.transform(words, aggregate_method=\"AVERAGE\")\n",
    "    \n",
    "    model_data = df_h2o.cbind(df_h2o_vec)\n",
    "    print(gbm.predict(model_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4-CA0Eaqjh0y",
    "outputId": "a964e281-9e42-4f4e-deff-799f2c10c54c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "Real_News = h2o.H2OFrame([[\" DHS Under Secretary for Science William Bryan on how the  Coronavirus dies fast when exposed to higher temperatures\",15],\n",
    "                          [\" New  Preliminary results of first large scale study of hydroxychloroquine   drug President Trump said would be a  game changer\",18]])\n",
    "\n",
    "Real_News.col_names = [\"text\",\"length\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 146
    },
    "colab_type": "code",
    "id": "vkl-3ltDj6mf",
    "outputId": "84e37b3f-d22e-4395-f6a1-d569627c8c61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real_news: \n",
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  predict</th><th style=\"text-align: right;\">      p0</th><th style=\"text-align: right;\">      p1</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.714128</td><td style=\"text-align: right;\">0.285872</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.79773 </td><td style=\"text-align: right;\">0.20227 </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Predict!\n",
    "print(\"Real_news: \")\n",
    "print(predict(Real_News, w2v_model, gbm_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 242
    },
    "colab_type": "code",
    "id": "U6xuvX4jkCAM",
    "outputId": "658328ff-dad8-4d18-e8ba-6b7c896b139f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real_news: \n",
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  predict</th><th style=\"text-align: right;\">      p0</th><th style=\"text-align: right;\">      p1</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.732803</td><td style=\"text-align: right;\">0.267197</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  predict</th><th style=\"text-align: right;\">     p0</th><th style=\"text-align: right;\">     p1</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.59683</td><td style=\"text-align: right;\">0.40317</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  predict</th><th style=\"text-align: right;\">     p0</th><th style=\"text-align: right;\">     p1</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.62396</td><td style=\"text-align: right;\">0.37604</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'depth_grid1_model_1': , 'depth_grid1_model_2': , 'depth_grid1_model_3': }\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Predict!\n",
    "print(\"Real_news: \")\n",
    "print(predict(Real_News, w2v_model, gbm_gridSearch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "colab_type": "code",
    "id": "TNyn-J0-wk_e",
    "outputId": "cf75d13b-9931-45f9-c1ef-a382e96af595"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  predict</th><th style=\"text-align: right;\">      p0</th><th style=\"text-align: right;\">      p1</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.714128</td><td style=\"text-align: right;\">0.285872</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pred = predict(Real_News, w2v_model, gbm_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Wow!! \n",
    "Looks like the model is predicting correctly. The <b>P0</b> score is the score for the Real news. If we remember, the label for real news was <b>0</b> and the fake news was <b>1</b>. SO the Model is predicting correctly. \n",
    "\n",
    "The two tweets that we passed were tweets and were real and the model was able to classify the tweets to be real\n",
    "\n",
    "We will be using pickel to store the model for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zYCvrKwh2D_X"
   },
   "outputs": [],
   "source": [
    "#Pickling\n",
    "gbm_embedd_pkl_filename = r'/content/drive/My Drive/Colab Notebooks/gbm_embeddings.pickel'\n",
    "gbm_embeddings_pkl = open(gbm_embedd_pkl_filename, 'wb')\n",
    "pickle.dump(gbm_embeddings, gbm_embeddings_pkl)\n",
    "gbm_embeddings_pkl.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rAvkHBPu2MwL"
   },
   "source": [
    "## Evaluation Metric:\n",
    "#### Confusion Matrix:\n",
    "A confusion matrix is a summary of prediction results on a classification problem.<br> The number of correct and incorrect predictions are summarized with count values and broken down by each class.<br> This is the key to the confusion matrix. <br>The confusion matrix shows the ways in which your classification model is confused when it makes predictions.<br> It gives us insight not only into the errors being made by a classifier but more importantly the types of errors that are being made.<br>\n",
    "\n",
    "<b>Definition of the Terms:</b>\n",
    "1. Positive (P) : Observation is positive (for example: is an apple).\n",
    "2. Negative (N) : Observation is not positive (for example: is not an apple).\n",
    "3. True Positive (TP) : Observation is positive, and is predicted to be positive.\n",
    "4. False Negative (FN) : Observation is positive, but is predicted negative.\n",
    "5. True Negative (TN) : Observation is negative, and is predicted to be negative.\n",
    "6. False Positive (FP) : Observation is negative, but is predicted positive.\n",
    "    Accuracy: (TP+ TN)/ (TP+TN+FP+FN)\n",
    "    Precision: (TP)/(TP+FP)\n",
    "    Recall: (TP)/(TP+FN)\n",
    "\n",
    "<br>\n",
    "<b>AUC</b>: AUC - ROC curve is a performance measurement for classification problem at various thresholds settings. <br>\n",
    "<b>ROC</b> is a probability curve and <b>AUC</b> represents degree or measure of separability. It tells how much model is capable of distinguishing between classes. Higher the AUC, better the model is at predicting 0s as 0s and 1s as 1s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "\n",
    "We have executed 4 models on the cleaned dataset that consists of tweets/articles from twitter as well.<br> <br>\n",
    "<b>The 4 models are :</b>\n",
    "1. Naive Bayes Classifier\n",
    "2. PassiveAgresiveClassifier\n",
    "3. Long Short Term Memory (LSTM)\n",
    "4. H2O AutoML\n",
    "\t\t\n",
    "<b>Naive Bayes Classifier</b> and <b>PassiveAggresiveClassifier </b> did not perform well on our dataset attaining an accuracy of <b>65-68%</b> on the confusion matrix even after vectorizing the words. Hence, we use <b>LSTM</b> to see how a Recurrent Neural Network model performs. After executing the model on the same dataset, we achieved an accuracy of <b>94%</b> on training data and <b>93%</b> on validation data. Hence, we run the LSTM model on twitter dataframe and store it as a csv to cross validate. LSTM model attains a good accuracy although it is quite expensive on the system. Takes up most of the system's resources to attain a good accuracy. Hence we use <b>H2O AutoML model</b> which is less expensive on the system and also helps us attain a <b>AUC of 81%</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## License\n",
    "Copyright 2020 <b>ANURAG DHAR & PRITHVIRAJ PATIL</b>\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:<br>\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.<br>\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citation\n",
    "\n",
    "1. https://machinelearningmastery.com/5-step-life-cycle-long-short-term-memory-models-keras/\n",
    "2. https://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "3. https://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "4. http://docs.h2o.ai/h2o/latest-stable/h2o-py/docs/intro.html\n",
    "5. https://www.kaggle.com/jsvishnuj/fakenews-detection-using-lstm-neural-network\n",
    "6. https://github.com/nikbearbrown/H2O_Workshop/blob/master/AmazonReviews.ipynb\n",
    "7. https://www.techopedia.com/definition/14650/data-preprocessing\n",
    "8. https://towardsdatascience.com/naive-bayes-document-classification-in-python-e33ff50f937e\n",
    "9. https://machinelearningmastery.com/5-step-life-cycle-long-short-term-memory-models-keras/\n",
    "10. https://towardsdatascience.com/https-medium-com-piercarlo-slavazza-what-is-the-best-method-for-automatic-text-classification-a01d4dfadd"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Final_Project_ADS_7390.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
